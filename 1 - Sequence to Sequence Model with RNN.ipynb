{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Sequence to Sequence Model with RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wEd7p3ARFcyr",
        "v2BPfwqcFk4h",
        "tazMbPR6Hnjg",
        "yT-6GZgfMXIu",
        "7cFeoEJpMYgE",
        "2ZwOJLkTMbCt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEd7p3ARFcyr",
        "colab_type": "text"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gttqmxRIFSUa",
        "colab_type": "code",
        "outputId": "931574db-c330-4ac3-ce7e-4acc8f3dd898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install torchtext --upgrade\n",
        "!python -m spacy download fr\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30kB 32.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 36.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 51kB 38.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 61kB 40.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71kB 40.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 850kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (45.2.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.28.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=7364025b28ffaebf181f693c9f5a8b86f78f8b7767a0acf76cdc058fee72df74\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ofqxw2bh/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.28.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-A0mVf7GNix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Example, Field, Dataset\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0iX1ZuNG0wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 781\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2BPfwqcFk4h",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc5EcEA1FnCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./data'):\n",
        "    !mkdir ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmajgrxCHwsw",
        "colab_type": "code",
        "outputId": "05ed7a3c-ddc3-4a2f-8bd9-68f3a1a8d85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
        "    -O ./data/fr-en.tgz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 19:12:12--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202718517 (193M) [application/x-gzip]\n",
            "Saving to: ‘./data/fr-en.tgz’\n",
            "\n",
            "./data/fr-en.tgz    100%[===================>] 193.33M  3.81MB/s    in 46s     \n",
            "\n",
            "2020-03-18 19:12:58 (4.21 MB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2r79GZZH7Ip",
        "colab_type": "code",
        "outputId": "856b46da-93ab-497c-e8fc-5732034f3a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!tar -xzvf ./data/fr-en.tgz -C ./data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "europarl-v7.fr-en.en\n",
            "europarl-v7.fr-en.fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tazMbPR6Hnjg",
        "colab_type": "text"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Q9N_zBHpTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
        "            content = file.readlines()\n",
        "        return content\n",
        "    except:\n",
        "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02KzJaPmIjI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    # NFD => Normal Form Decompose\n",
        "    # Mn => Non Marking Space\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
        "                    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.strip())\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJtKDpMJF-1",
        "colab_type": "code",
        "outputId": "a944abd7-9f8c-47f1-c20e-9672bef22ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%time\n",
        "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
        "              read_file('./data/europarl-v7.fr-en.en'))]\n",
        "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
        "print(f'Number of examples: {len(pairs)}')\n",
        "pairs = np.random.choice(pairs, size=3000, replace=False)\n",
        "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
        "              pairs)]\n",
        "print(f'Number of examples after sampling: {len(pairs)}')\n",
        "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 2007723\n",
            "Number of examples after sampling: 3000\n",
            "Example:\n",
            "\tFR => J’espere que l’on fera pression sur ces entreprises, qui parlent tres souvent de commerce equitable, pour veiller a ce que les travailleurs des usines qui les fournissent beneficient d’un traitement equitable.\n",
            "\tEN => I hope that people will put pressure on those companies, which talk very often about fair trade, to ensure that the workers at the factories that supply them get a fair deal.\n",
            "CPU times: user 4.03 s, sys: 1.02 s, total: 5.05 s\n",
            "Wall time: 5.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAq2uyDyJ6KD",
        "colab_type": "code",
        "outputId": "ed81fc30-afba-45c5-ecc3-3feab9340588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%time\n",
        "FR = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           preprocessing=lambda x: x[::-1],\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='fr')\n",
        "EN = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='en')\n",
        "\n",
        "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
        "                                                'en': ('dest', EN)})\n",
        "            for pair in tqdm.tqdm(pairs)]\n",
        "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
        "train_data, valid_data, test_data = data.split(split_ratio=[0.7, 0.2, 0.1])\n",
        "print(f'train size: {len(train_data.examples)}')\n",
        "print(f'valid size: {len(valid_data.examples)}')\n",
        "print(f'test size: {len(test_data.examples)}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:01<00:00, 2175.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train size: 2100\n",
            "valid size: 300\n",
            "test size: 600\n",
            "{'src': ['.', 'couts', 'des', 'reduction', 'la', 'sur', 'concentrer', 'nous', 'moins', 'et', ',', 'production', 'la', 'de', 'renouvellement', 'le', 'dans', 'davantage', 'investir', 'devons', 'nous'], 'dest': ['we', 'should', 'be', 'investing', 'more', 'in', 'product', 'renewal', 'and', 'lay', 'less', 'store', 'by', 'cost', 'effectiveness', '.']}\n",
            "CPU times: user 2.76 s, sys: 150 ms, total: 2.91 s\n",
            "Wall time: 2.93 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JycVMjsRLmoB",
        "colab_type": "code",
        "outputId": "1de0e777-f356-4f60-ed5b-d763bd2952b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "FR.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "EN.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "\n",
        "print(f'Length of FR vocabulary: {len(FR.vocab)}')\n",
        "print(f'Length of EN vocabulary: {len(EN.vocab)}')"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of FR vocabulary: 3461\n",
            "Length of EN vocabulary: 3111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKKRGB9cIbn8",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-6GZgfMXIu",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJL7MVwAMVtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0, bidirectional=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0),\n",
        "                            bidirectional=bidirectional)\n",
        "    \n",
        "    def forward(self, in_):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "\n",
        "        embedded = self.embedding(in_)\n",
        "        # embedded: (seq_len, batch_size, embed_size)\n",
        "        out, (hn, cn) = self.lstm(embedded)\n",
        "            out: (seq_len, batch_size, num_directions * hidden_size)\n",
        "            hn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "            cn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        outputs: out, hn, cn\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        out, (hn, cn) = self.lstm(embedded)\n",
        "        return out, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cFeoEJpMYgE",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deAfHkCcIdzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0))\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        \n",
        "    def forward(self, in_, h0, c0):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (1, batch_size) => seq_len = 1, a word\n",
        "            h0: (num_layers, batch_size, hidden_size)\n",
        "            c0: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        embed = self.embedding(_in) \n",
        "        # embedded: (1, batch_size, embed_size)\n",
        "        out, hn, cn = self.lstm(embedded)\n",
        "        # out: (1, batch_size, hidden_size)\n",
        "        # hn: (num_layers, batch_size, hidden_size)\n",
        "        # cn: (num_layers, batch_size, hidden_size)\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        # logit: (batch_size, vocab_size)\n",
        "\n",
        "        outputs: logit, hn, cn\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        out, (hn, cn) = self.lstm(embedded, (h0, c0))\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        return logit, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZwOJLkTMbCt",
        "colab_type": "text"
      },
      "source": [
        "## Sequence to sequence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Wd0iNaMgp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SeqToSeq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device=device):\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent layers'\n",
        "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent hidden units'\n",
        "\n",
        "        super(SeqToSeq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def encode(self, in_):\n",
        "        _, hn, cn = self.encoder(in_)\n",
        "        # Sum the two directional encoder hn state\n",
        "        if self.encoder.bidirectional:\n",
        "            hn = hn[:self.encoder.n_layers, :, :] + \\\n",
        "                    hn[self.encoder.n_layers:, :, :]\n",
        "            cn = cn[:self.encoder.n_layers, :, :] + \\\n",
        "                    cn[self.encoder.n_layers:, :, :]\n",
        "        return hn, cn\n",
        "\n",
        "    def decode(self, h_state, c_state, target, sos_index, teacher_forcing, ratio):\n",
        "        target_len, batch_size = target.size()\n",
        "        out = torch.zeros((target_len, batch_size, self.decoder.vocab_size),\n",
        "                           device=self.device)\n",
        "        in_ = target[0, :].unsqueeze(0)\n",
        "        for t in range(1, target_len):\n",
        "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
        "            out[t] = logit # (batch_size, vocab_size)\n",
        "            if teacher_forcing and random.random() < ratio:\n",
        "                in_ = logit.argmax(1).unsqueeze(0) # (1, batch_size)\n",
        "            else:\n",
        "                in_ = target[t, :].unsqueeze(0)\n",
        "        return out\n",
        "\n",
        "    def forward(self, in_, target, sos_index, teacher_forcing=True, ratio=.5):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            target: (seq_len, batch_size)\n",
        "            sos_index: int\n",
        "            eos_index: int\n",
        "\n",
        "        outputs\n",
        "            out: (seq_len, batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "        hn, cn = self.encode(in_)\n",
        "        out = self.decode(hn, cn, target, sos_index, teacher_forcing, ratio)\n",
        "        return out\n",
        "\n",
        "    def infer(self, h_state, c_state, sos_index, eos_index, max_len, sample):\n",
        "        \"\"\"\n",
        "        Infer a sequence. Not a batch.\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        in_ = torch.ones((1, 1), device=self.device,\n",
        "                         dtype=torch.int64) * sos_index\n",
        "        for _ in range(max_len):\n",
        "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
        "            if sample:\n",
        "                probs = F.softmax(logit, dim=1) # (1, vocab_size)\n",
        "                next_ = torch.multinomial(probs, 1) # (1, 1)\n",
        "            else:\n",
        "                in_, next_ = logit.topk(1, dim=1) # (batch_size=1, 1)\n",
        "            next_idx = next_.squeeze().cpu().item()\n",
        "            if next_idx == eos_index:\n",
        "                break\n",
        "            out.append(next_idx)\n",
        "            in_ = torch.ones((1, 1), device=self.device,\n",
        "                             dtype=torch.int64) * next_idx # (1, 1)\n",
        "        return out\n",
        "\n",
        "    def inference(self, in_, sos_index, eos_index, max_len, sample=True):\n",
        "        \"\"\"\n",
        "        Inferring a sentence or a batch of sentences.\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            sos_index: int\n",
        "            eos_index: int\n",
        "            max_len: int\n",
        "            sample: bool\n",
        "\n",
        "        outputs\n",
        "            out: list(seq_len*, batch_size)\n",
        "        \"\"\"\n",
        "        hn, cn = self.encode(in_)\n",
        "        # hn: (num_layers, batch_size, hidden_size)\n",
        "        # cn: (num_layers, batch_size, hidden_size)\n",
        "        _, batch_size = in_.size()\n",
        "        out = []\n",
        "        for i in range(batch_size):\n",
        "            out.append(\n",
        "                self.infer(hn[:, i, :].unsqueeze(1),\n",
        "                           cn[:, i, :].unsqueeze(1),\n",
        "                           sos_index, eos_index, max_len, sample))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCLUmCfFMjGV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_aldUUdZ5dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(model: nn.Module):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, a=-0.08, b=0.08)\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1teOdv5q7ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    grad_mean, layers = [], []\n",
        "    for name, param in named_parameters:\n",
        "        if param.requires_grad and 'bias' not in name:\n",
        "            layers.append(name)\n",
        "            grad_mean.append(param.grad.abs().mean())\n",
        "    plt.plot(grad_mean, alpha=0.3, color='b')\n",
        "    plt.hlines(0, 0, len(grad_mean) + 1, linewidth=1, color='k' )\n",
        "    plt.xticks(range(0, len(grad_mean), 1), layers, rotation='vertical')\n",
        "    plt.xlim(xmin=0, xmax=len(grad_mean))\n",
        "    # plt.ylim(bottom=-0.001, top=0.02) # Zoom on lower gradients\n",
        "    plt.xlabel('Layers')\n",
        "    plt.ylabel('Mean of gradients')\n",
        "    plt.title('Gradient Flow')\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8QgblulqoWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, opt, loss_func, data_it, grad_clip, sos_index,\n",
        "               epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.train()\n",
        "    for i, data in pbar:\n",
        "        opt.zero_grad()\n",
        "        logits = model(data.src, data.dest, sos_index)\n",
        "        loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                         data.dest[1:].view(-1))\n",
        "        loss.backward()\n",
        "        # plot_grad_flow(model.named_parameters())\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        opt.step()\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_description(epoch_text + f'Train Loss: {epoch_loss/(i+1):.3f}')\n",
        "    # plt.show() # Show the gradient flow\n",
        "    return epoch_loss / len(data_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYND0IGKrdJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valid_step(model, loss_func, data_it, sos_index, epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in pbar:\n",
        "            logits = model(data.src, data.dest, sos_index,\n",
        "                           teacher_forcing=False)\n",
        "            loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                             data.dest[1:].view(-1))\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_description(epoch_text + f'Valid Loss: {epoch_loss/(i+1):.3f}')\n",
        "    return epoch_loss / len(data_it)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECEXh0oHwSFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function, train_it, valid_it, n_epochs, sos_index,\n",
        "          grad_clip=None, save_to='./saved_models', filename='seq2seq.pt'):\n",
        "    assert callable(loss_function)\n",
        "    if not os.path.exists(save_to):\n",
        "        !mkdir {save_to}\n",
        "\n",
        "    history = {'loss': [], 'val_loss': []}\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_text = f'Epoch: {epoch + 1:02d} - '\n",
        "        loss = train_step(model, optimizer, loss_function, train_it, grad_clip,\n",
        "                          sos_index, epoch_text)\n",
        "        val_loss = valid_step(model, loss_function, valid_it, sos_index,\n",
        "                              epoch_text)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict()},\n",
        "                       f=os.path.join(save_to, filename))\n",
        "\n",
        "        history['loss'].append(loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZV_iUlh3CWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_SIZE = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 30\n",
        "MAX_LEN = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBekgFKP3C3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator =  \\\n",
        "        BucketIterator.splits((train_data, valid_data,\n",
        "                               test_data),\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              sort_key=lambda x: (len(x.src), len(x.dest)),\n",
        "                              device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCWVfRdAxY6N",
        "colab_type": "code",
        "outputId": "23b14f5d-7f0d-449e-d655-5034cae1338f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoder = Encoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(FR.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "decoder = Decoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(EN.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "seq2seq = SeqToSeq(encoder=encoder, decoder=decoder).to(device)\n",
        "seq2seq.apply(init_weights)\n",
        "optimizer = optim.Adam(seq2seq.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=EN.vocab.stoi[EN.pad_token])\n",
        "print(f'Number of parameters of the model: {count_parameters(seq2seq):,}')"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 16,969,655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22m0tls06BS",
        "colab_type": "code",
        "outputId": "b0519b99-8655-4e53-d4b5-9cf34b1154bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = train(seq2seq, optimizer, criterion, train_iterator, valid_iterator,\n",
        "                sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 - Train Loss: 6.399: 100%|██████████| 17/17 [00:11<00:00,  1.33it/s]\n",
            "Epoch: 01 - Valid Loss: 5.589: 100%|██████████| 3/3 [00:00<00:00, 11.85it/s]\n",
            "Epoch: 02 - Train Loss: 5.795: 100%|██████████| 17/17 [00:11<00:00,  1.66it/s]\n",
            "Epoch: 02 - Valid Loss: 5.524: 100%|██████████| 3/3 [00:00<00:00, 12.06it/s]\n",
            "Epoch: 03 - Train Loss: 5.744: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s]\n",
            "Epoch: 03 - Valid Loss: 5.508: 100%|██████████| 3/3 [00:00<00:00, 11.77it/s]\n",
            "Epoch: 04 - Train Loss: 5.722: 100%|██████████| 17/17 [00:12<00:00,  1.48it/s]\n",
            "Epoch: 04 - Valid Loss: 5.499: 100%|██████████| 3/3 [00:00<00:00, 11.53it/s]\n",
            "Epoch: 05 - Train Loss: 5.706: 100%|██████████| 17/17 [00:11<00:00,  1.45it/s]\n",
            "Epoch: 05 - Valid Loss: 5.474: 100%|██████████| 3/3 [00:00<00:00, 11.89it/s]\n",
            "Epoch: 06 - Train Loss: 5.676: 100%|██████████| 17/17 [00:11<00:00,  1.62it/s]\n",
            "Epoch: 06 - Valid Loss: 5.425: 100%|██████████| 3/3 [00:00<00:00, 11.51it/s]\n",
            "Epoch: 07 - Train Loss: 5.634: 100%|██████████| 17/17 [00:12<00:00,  1.34it/s]\n",
            "Epoch: 07 - Valid Loss: 5.363: 100%|██████████| 3/3 [00:00<00:00, 11.52it/s]\n",
            "Epoch: 08 - Train Loss: 5.582: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s]\n",
            "Epoch: 08 - Valid Loss: 5.308: 100%|██████████| 3/3 [00:00<00:00, 11.72it/s]\n",
            "Epoch: 09 - Train Loss: 5.524: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s]\n",
            "Epoch: 09 - Valid Loss: 5.202: 100%|██████████| 3/3 [00:00<00:00, 11.81it/s]\n",
            "Epoch: 10 - Train Loss: 5.462: 100%|██████████| 17/17 [00:12<00:00,  1.58it/s]\n",
            "Epoch: 10 - Valid Loss: 5.123: 100%|██████████| 3/3 [00:00<00:00, 11.52it/s]\n",
            "Epoch: 11 - Train Loss: 5.403: 100%|██████████| 17/17 [00:11<00:00,  1.26it/s]\n",
            "Epoch: 11 - Valid Loss: 5.085: 100%|██████████| 3/3 [00:00<00:00, 11.74it/s]\n",
            "Epoch: 12 - Train Loss: 5.356: 100%|██████████| 17/17 [00:12<00:00,  1.64it/s]\n",
            "Epoch: 12 - Valid Loss: 5.006: 100%|██████████| 3/3 [00:00<00:00, 11.76it/s]\n",
            "Epoch: 13 - Train Loss: 5.303: 100%|██████████| 17/17 [00:12<00:00,  1.33it/s]\n",
            "Epoch: 13 - Valid Loss: 4.978: 100%|██████████| 3/3 [00:00<00:00, 11.18it/s]\n",
            "Epoch: 14 - Train Loss: 5.249: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s]\n",
            "Epoch: 14 - Valid Loss: 4.939: 100%|██████████| 3/3 [00:00<00:00, 11.76it/s]\n",
            "Epoch: 15 - Train Loss: 5.240: 100%|██████████| 17/17 [00:12<00:00,  1.34it/s]\n",
            "Epoch: 15 - Valid Loss: 4.890: 100%|██████████| 3/3 [00:00<00:00, 11.15it/s]\n",
            "Epoch: 16 - Train Loss: 5.194: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s]\n",
            "Epoch: 16 - Valid Loss: 4.874: 100%|██████████| 3/3 [00:00<00:00, 11.49it/s]\n",
            "Epoch: 17 - Train Loss: 5.165: 100%|██████████| 17/17 [00:12<00:00,  1.36it/s]\n",
            "Epoch: 17 - Valid Loss: 4.859: 100%|██████████| 3/3 [00:00<00:00, 11.90it/s]\n",
            "Epoch: 18 - Train Loss: 5.116: 100%|██████████| 17/17 [00:12<00:00,  1.38it/s]\n",
            "Epoch: 18 - Valid Loss: 4.852: 100%|██████████| 3/3 [00:00<00:00, 11.70it/s]\n",
            "Epoch: 19 - Train Loss: 5.069: 100%|██████████| 17/17 [00:11<00:00,  1.45it/s]\n",
            "Epoch: 19 - Valid Loss: 4.828: 100%|██████████| 3/3 [00:00<00:00, 11.65it/s]\n",
            "Epoch: 20 - Train Loss: 5.044: 100%|██████████| 17/17 [00:12<00:00,  1.33it/s]\n",
            "Epoch: 20 - Valid Loss: 4.838: 100%|██████████| 3/3 [00:00<00:00, 11.56it/s]\n",
            "Epoch: 21 - Train Loss: 5.065: 100%|██████████| 17/17 [00:12<00:00,  1.46it/s]\n",
            "Epoch: 21 - Valid Loss: 4.797: 100%|██████████| 3/3 [00:00<00:00, 11.42it/s]\n",
            "Epoch: 22 - Train Loss: 5.020: 100%|██████████| 17/17 [00:12<00:00,  1.38it/s]\n",
            "Epoch: 22 - Valid Loss: 4.809: 100%|██████████| 3/3 [00:00<00:00, 11.31it/s]\n",
            "Epoch: 23 - Train Loss: 4.960: 100%|██████████| 17/17 [00:12<00:00,  1.33it/s]\n",
            "Epoch: 23 - Valid Loss: 4.788: 100%|██████████| 3/3 [00:00<00:00, 11.57it/s]\n",
            "Epoch: 24 - Train Loss: 4.932: 100%|██████████| 17/17 [00:12<00:00,  1.52it/s]\n",
            "Epoch: 24 - Valid Loss: 4.768: 100%|██████████| 3/3 [00:00<00:00, 11.46it/s]\n",
            "Epoch: 25 - Train Loss: 4.921: 100%|██████████| 17/17 [00:12<00:00,  1.38it/s]\n",
            "Epoch: 25 - Valid Loss: 4.794: 100%|██████████| 3/3 [00:00<00:00, 11.56it/s]\n",
            "Epoch: 26 - Train Loss: 4.924: 100%|██████████| 17/17 [00:12<00:00,  1.26it/s]\n",
            "Epoch: 26 - Valid Loss: 4.782: 100%|██████████| 3/3 [00:00<00:00, 11.39it/s]\n",
            "Epoch: 27 - Train Loss: 4.877: 100%|██████████| 17/17 [00:12<00:00,  1.45it/s]\n",
            "Epoch: 27 - Valid Loss: 4.757: 100%|██████████| 3/3 [00:00<00:00, 10.96it/s]\n",
            "Epoch: 28 - Train Loss: 4.851: 100%|██████████| 17/17 [00:12<00:00,  1.25it/s]\n",
            "Epoch: 28 - Valid Loss: 4.764: 100%|██████████| 3/3 [00:00<00:00, 11.46it/s]\n",
            "Epoch: 29 - Train Loss: 4.840: 100%|██████████| 17/17 [00:12<00:00,  1.54it/s]\n",
            "Epoch: 29 - Valid Loss: 4.780: 100%|██████████| 3/3 [00:00<00:00, 11.52it/s]\n",
            "Epoch: 30 - Train Loss: 4.810: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s]\n",
            "Epoch: 30 - Valid Loss: 4.779: 100%|██████████| 3/3 [00:00<00:00, 11.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ_klP1-6XyF",
        "colab_type": "code",
        "outputId": "88c0ffb2-55ac-4593-ec4f-4fa97d282e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='valid')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxDV_RX866Hp",
        "colab_type": "code",
        "outputId": "af350215-80b5-42d4-d4d7-2a2dbb5e67a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq2seq.load_state_dict(torch.load('./saved_models/seq2seq.pt').get('model'))\n",
        "test_loss = valid_step(seq2seq, criterion, test_iterator,\n",
        "                       sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                       epoch_text='Test loss => ')"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss => Valid Loss: 4.761: 100%|██████████| 5/5 [00:00<00:00, 11.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8tYcPCLgz5",
        "colab_type": "text"
      },
      "source": [
        "# Inference & BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRIlUJjLeDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "cf02f850-575f-42fc-e47d-e44e4630c8d8"
      },
      "source": [
        "%%time\n",
        "references = []\n",
        "targets_with_sample = []\n",
        "targets_without_sample  = []\n",
        "seq2seq.eval()\n",
        "with torch.no_grad():\n",
        "    for i, example in enumerate(test_data.examples):\n",
        "        in_ = torch.tensor([FR.vocab.stoi[token]\n",
        "                            for token in example.src],\n",
        "                        dtype=torch.int64, device=device).unsqueeze(1)\n",
        "        if in_.size(0) == 0:\n",
        "            print(f'skipped example {i}!')\n",
        "            continue\n",
        "        with_ = seq2seq.inference(in_, EN.vocab.stoi[EN.init_token],\n",
        "                                  EN.vocab.stoi[EN.eos_token], 50)\n",
        "        without = seq2seq.inference(in_, EN.vocab.stoi[EN.init_token],\n",
        "                                    EN.vocab.stoi[EN.eos_token], 50, False)\n",
        "        targets_with_sample.append([EN.vocab.itos[int(idx)] for idx in with_[0]])\n",
        "        targets_without_sample.append([EN.vocab.itos[int(idx)] for idx in without[0]])\n",
        "        references.append([example.dest])"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skipped example 48!\n",
            "CPU times: user 22.7 s, sys: 2.31 s, total: 25.1 s\n",
            "Wall time: 25.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTolzzQaoAGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bca2ce6c-5f50-4652-f054-7129db7a4e95"
      },
      "source": [
        "print(f'BLEU score with sampling: {bleu_score(targets_with_sample, references)}')\n",
        "print(f'BLEU score without sampling: {bleu_score(targets_without_sample, references)}')"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score with sampling: 0.0023650433868169785\n",
            "BLEU score without sampling: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-mzrtbp_mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6fccdcfe-5f75-4500-dd59-56a0245d70df"
      },
      "source": [
        "idx = 125\n",
        "print(' '.join(references[idx][0]))\n",
        "print(' '.join(targets_with_sample[idx]))\n",
        "print(' '.join(targets_without_sample[idx]))"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "on the one hand , the provisions of agenda 2000 will probably lead farmers to reduce their production of oleaginous protein crops in favour of cereals unless , of course , wise steps are taken to promote crops in the non - food agricultural production sector . on the other hand , production capacities for amino acids , particularly synthetic lysine , are decreasing in europe .\n",
            "and a president , i have followed my rule various press , the is against other beginning and ones in the outermost a certain level , maritime mechanism of <unk> unfortunately , the really be to comments out and so everyone to august referred to play for this sources of\n",
            "i <unk> , <unk> the <unk> of the <unk> , , the <unk> of the <unk> , , the <unk> , , the <unk> , , , , , , , the <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> , <unk> ,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hzyFn-Vqn3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}