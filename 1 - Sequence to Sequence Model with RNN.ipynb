{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Sequence to Sequence Model with RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wEd7p3ARFcyr",
        "v2BPfwqcFk4h",
        "tazMbPR6Hnjg",
        "yT-6GZgfMXIu",
        "7cFeoEJpMYgE",
        "2ZwOJLkTMbCt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEd7p3ARFcyr",
        "colab_type": "text"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gttqmxRIFSUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11482fd1-7a8b-444a-9bdf-8114051e16df"
      },
      "source": [
        "!pip install torchtext --upgrade\n",
        "!python -m spacy download fr\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext) (0.1.85)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: fr_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz#egg=fr_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (45.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.28.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-A0mVf7GNix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Example, Field, Dataset\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0iX1ZuNG0wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 781\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2BPfwqcFk4h",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc5EcEA1FnCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./data'):\n",
        "    !mkdir ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmajgrxCHwsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a5561781-a693-4227-b028-51aaab5a41ce"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
        "    -O ./data/fr-en.tgz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 05:07:11--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202718517 (193M) [application/x-gzip]\n",
            "Saving to: ‘./data/fr-en.tgz’\n",
            "\n",
            "./data/fr-en.tgz    100%[===================>] 193.33M   975KB/s    in 3m 53s  \n",
            "\n",
            "2020-03-18 05:11:05 (849 KB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2r79GZZH7Ip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f775f797-981b-4215-bcf3-1ad2285d2b7e"
      },
      "source": [
        "!tar -xzvf ./data/fr-en.tgz -C ./data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "europarl-v7.fr-en.en\n",
            "europarl-v7.fr-en.fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tazMbPR6Hnjg",
        "colab_type": "text"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Q9N_zBHpTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
        "            content = file.readlines()\n",
        "        return content\n",
        "    except:\n",
        "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02KzJaPmIjI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    # NFD => Normal Form Decompose\n",
        "    # Mn => Non Marking Space\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
        "                    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.strip())\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJtKDpMJF-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04534101-488a-4179-a045-6cd054b5fad9"
      },
      "source": [
        "%%time\n",
        "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
        "              read_file('./data/europarl-v7.fr-en.en'))]\n",
        "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
        "print(f'Number of examples: {len(pairs)}')\n",
        "pairs = np.random.choice(pairs, size=3000, replace=False)\n",
        "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
        "              pairs)]\n",
        "print(f'Number of examples after sampling: {len(pairs)}')\n",
        "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 2007723\n",
            "Number of examples after sampling: 3000\n",
            "Example:\n",
            "\tFR => Les procedures par le biais desquelles de tels produits entrent et sortent de l'Union europeenne doivent etre ouvertes, transparentes et, par dessus tout, sures.\n",
            "\tEN => The procedures whereby such products come in and out of the European Union have to be open, transparent and, above all, safe.\n",
            "CPU times: user 3.73 s, sys: 1.03 s, total: 4.76 s\n",
            "Wall time: 16.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAq2uyDyJ6KD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "51bdb4a4-10ae-478a-b1e5-7bc19c978eba"
      },
      "source": [
        "%%time\n",
        "FR = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           preprocessing=lambda x: x[::-1],\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='fr')\n",
        "EN = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           preprocessing=lambda x: x[::-1],\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='en')\n",
        "\n",
        "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
        "                                                'en': ('dest', EN)})\n",
        "            for pair in tqdm.tqdm(pairs)]\n",
        "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
        "train_data, valid_data, test_data = data.split(split_ratio=[0.7, 0.2, 0.1])\n",
        "print(f'train size: {len(train_data.examples)}')\n",
        "print(f'valid size: {len(valid_data.examples)}')\n",
        "print(f'test size: {len(test_data.examples)}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:01<00:00, 2383.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train size: 2100\n",
            "valid size: 300\n",
            "test size: 600\n",
            "{'src': ['.', 'rester', 'de', 'permettant', 'leur', 'integration', \"'\", 'd', 'politique', 'une', 'prioritairement', 'place', 'en', 'mettre', 'faut', 'il', \"'\", 'qu', 'et', ',', '\"', 'union', \"'\", 'l', 'de', 'citoyens', 'des', 'ceux', 'de', 'possible', 'que', 'proches', 'aussi', 'uniformes', 'droits', 'de', 'ensemble', 'un', '\"', ':', 'cite', 'je', ',', 'legaux', 'immigres', 'aux', 'donner', 'faut', 'il', \"'\", 'qu', ',', 'reprises', 'plusieurs', 'a', ',', 'fortement', 'proclame', 'il', ',', 'temps', 'meme', 'en', 'mais', ',', 'source', 'la', 'a', 'clandestine', 'immigration', \"'\", 'l', 'combattre', 'de', 'et', 'migratoires', 'flux', 'les', 'gerer', 'de', 'platonique', 'volonte', 'la', 'affiche', 'tampere', 'de', 'conseil', 'le', ':', 'contradiction', 'seconde'], 'dest': ['.', 'stay', 'to', 'them', 'enable', 'to', 'up', 'set', 'be', 'must', 'integration', 'of', 'policy', 'a', 'priority', 'a', 'as', 'that', 'and', ',', '\"', 'citizens', 'eu', 'by', 'enjoyed', 'those', 'to', 'possible', 'as', 'near', 'as', 'are', 'which', 'rights', 'uniform', 'of', 'set', 'a', '\"', ',', 'quote', 'i', ',', 'given', 'be', 'must', 'immigrants', 'legal', 'that', ',', 'occasions', 'several', 'on', ',', 'proclaims', 'staunchly', ',', 'time', 'same', 'the', 'at', ',', 'but', ',', 'source', 'at', 'immigration', 'illegal', 'combat', 'to', 'and', 'migrants', 'of', 'flows', 'the', 'control', 'to', 'intention', 'formal', 'purely', 'its', 'propounds', 'council', 'tampere', 'the', ':', 'contradiction', 'second', 'the']}\n",
            "CPU times: user 6.34 s, sys: 138 ms, total: 6.48 s\n",
            "Wall time: 6.47 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JycVMjsRLmoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d9c9cb80-4496-42cb-b549-2af5bafadb71"
      },
      "source": [
        "FR.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "EN.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "\n",
        "print(f'Length of FR vocabulary: {len(FR.vocab)}')\n",
        "print(f'Length of EN vocabulary: {len(EN.vocab)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of FR vocabulary: 3472\n",
            "Length of EN vocabulary: 3110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKKRGB9cIbn8",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-6GZgfMXIu",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJL7MVwAMVtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0, bidirectional=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0),\n",
        "                            bidirectional=bidirectional)\n",
        "    \n",
        "    def forward(self, in_):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "\n",
        "        embedded = self.embedding(in_)\n",
        "        # embedded: (seq_len, batch_size, embed_size)\n",
        "        out, (hn, cn) = self.lstm(embedded)\n",
        "            out: (seq_len, batch_size, num_directions * hidden_size)\n",
        "            hn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "            cn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "\n",
        "        outputs: out, hn, cn\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        out, (hn, cn) = self.lstm(embedded)\n",
        "        return out, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cFeoEJpMYgE",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deAfHkCcIdzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0))\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        \n",
        "    def forward(self, in_, h0, c0):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (1, batch_size) => seq_len = 1, a word\n",
        "            h0: (num_layers, batch_size, hidden_size)\n",
        "            c0: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        embed = self.embedding(_in) \n",
        "        # embedded: (1, batch_size, embed_size)\n",
        "        out, hn, cn = self.lstm(embedded)\n",
        "        # out: (1, batch_size, hidden_size)\n",
        "        # hn: (num_layers, batch_size, hidden_size)\n",
        "        # cn: (num_layers, batch_size, hidden_size)\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        # logit: (batch_size, vocab_size)\n",
        "\n",
        "        outputs: logit, hn, cn\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        out, (hn, cn) = self.lstm(embedded, (h0, c0))\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        return logit, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZwOJLkTMbCt",
        "colab_type": "text"
      },
      "source": [
        "## Sequence to sequence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Wd0iNaMgp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SeqToSeq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device=device):\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent layers'\n",
        "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent hidden units'\n",
        "\n",
        "        super(SeqToSeq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def encode(self, in_):\n",
        "        _, hn, cn = self.encoder(in_)\n",
        "        # Sum the two directional encoder hn state\n",
        "        if self.encoder.bidirectional:\n",
        "            hn = hn[:self.encoder.n_layers, :, :] + \\\n",
        "                    hn[self.encoder.n_layers:, :, :]\n",
        "            cn = cn[:self.encoder.n_layers, :, :] + \\\n",
        "                    cn[self.encoder.n_layers:, :, :]\n",
        "        return hn, cn\n",
        "\n",
        "    def decode(self, h_state, c_state, target, sos_index, teacher_forcing, ratio):\n",
        "        target_len, batch_size = target.size()\n",
        "        out = torch.zeros((target_len, batch_size, self.decoder.vocab_size),\n",
        "                           device=self.device)\n",
        "        in_ = target[0, :].unsqueeze(0)\n",
        "        for t in range(1, target_len):\n",
        "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
        "            out[t] = logit # (batch_size, vocab_size)\n",
        "            if teacher_forcing and random.random() < ratio:\n",
        "                in_ = logit.argmax(1).unsqueeze(0) # (1, batch_size)\n",
        "            else:\n",
        "                in_ = target[t, :].unsqueeze(0)\n",
        "        return out\n",
        "\n",
        "    def forward(self, in_, target, sos_index, teacher_forcing=True, ratio=.5):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            target: (seq_len, batch_size)\n",
        "            sos_index: int\n",
        "            eos_index: int\n",
        "\n",
        "        outputs\n",
        "            out: (seq_len, batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "        hn, cn = self.encode(in_)\n",
        "        out = self.decode(hn, cn, target, sos_index, teacher_forcing, ratio)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCLUmCfFMjGV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_aldUUdZ5dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(model: nn.Module):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, a=-0.08, b=0.08)\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1teOdv5q7ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    grad_mean, layers = [], []\n",
        "    for name, param in named_parameters:\n",
        "        if param.requires_grad and 'bias' not in name:\n",
        "            layers.append(name)\n",
        "            grad_mean.append(param.grad.abs().mean())\n",
        "    plt.plot(grad_mean, alpha=0.3, color='b')\n",
        "    plt.hlines(0, 0, len(grad_mean) + 1, linewidth=1, color='k' )\n",
        "    plt.xticks(range(0, len(grad_mean), 1), layers, rotation='vertical')\n",
        "    plt.xlim(xmin=0, xmax=len(grad_mean))\n",
        "    # plt.ylim(bottom=-0.001, top=0.02) # Zoom on lower gradients\n",
        "    plt.xlabel('Layers')\n",
        "    plt.ylabel('Mean of gradients')\n",
        "    plt.title('Gradient Flow')\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8QgblulqoWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, opt, loss_func, data_it, grad_clip, sos_index,\n",
        "               epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.train()\n",
        "    for i, data in pbar:\n",
        "        opt.zero_grad()\n",
        "        logits = model(data.src, data.dest, sos_index)\n",
        "        loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                         data.dest[1:].view(-1))\n",
        "        loss.backward()\n",
        "        # plot_grad_flow(model.named_parameters())\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        opt.step()\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_description(epoch_text + f'Train Loss: {epoch_loss/(i+1):.3f}')\n",
        "    # plt.show() # Show the gradient flow\n",
        "    return epoch_loss / len(data_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYND0IGKrdJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valid_step(model, loss_func, data_it, sos_index, epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in pbar:\n",
        "            logits = model(data.src, data.dest, sos_index,\n",
        "                           teacher_forcing=False)\n",
        "            loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                             data.dest[1:].view(-1))\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_description(epoch_text + f'Valid Loss: {epoch_loss/(i+1):.3f}')\n",
        "    return epoch_loss / len(data_it)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECEXh0oHwSFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function, train_it, valid_it, n_epochs, sos_index,\n",
        "          grad_clip=None, save_to='./saved_models', filename='seq2seq.pt'):\n",
        "    assert callable(loss_function)\n",
        "    if not os.path.exists(save_to):\n",
        "        !mkdir {save_to}\n",
        "\n",
        "    history = {'loss': [], 'val_loss': []}\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_text = f'Epoch: {epoch + 1:02d} - '\n",
        "        loss = train_step(model, optimizer, loss_function, train_it, grad_clip,\n",
        "                          sos_index, epoch_text)\n",
        "        val_loss = valid_step(model, loss_function, valid_it, sos_index,\n",
        "                              epoch_text)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict()},\n",
        "                       f=os.path.join(save_to, filename))\n",
        "\n",
        "        history['loss'].append(loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZV_iUlh3CWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_SIZE = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 30\n",
        "MAX_LEN = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBekgFKP3C3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator =  \\\n",
        "        BucketIterator.splits((train_data, valid_data,\n",
        "                               test_data),\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              sort_key=lambda x: (len(x.src), len(x.dest)),\n",
        "                              device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCWVfRdAxY6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6d360e5-2136-45c6-fbce-5db580f79bab"
      },
      "source": [
        "encoder = Encoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(FR.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "decoder = Decoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(EN.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "seq2seq = SeqToSeq(encoder=encoder, decoder=decoder).to(device)\n",
        "seq2seq.apply(init_weights)\n",
        "optimizer = optim.Adam(seq2seq.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=EN.vocab.stoi[EN.pad_token])\n",
        "print(f'Number of parameters of the model: {count_parameters(seq2seq):,}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 16,972,142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22m0tls06BS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87b148c7-f4b8-4fd9-fa3f-759d4c6479ec"
      },
      "source": [
        "history = train(seq2seq, optimizer, criterion, train_iterator, valid_iterator,\n",
        "                sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 - Train Loss: 6.354: 100%|██████████| 17/17 [00:12<00:00,  1.43it/s]\n",
            "Epoch: 01 - Valid Loss: 5.474: 100%|██████████| 3/3 [00:00<00:00, 12.74it/s]\n",
            "Epoch: 02 - Train Loss: 5.687: 100%|██████████| 17/17 [00:12<00:00,  1.19it/s]\n",
            "Epoch: 02 - Valid Loss: 5.430: 100%|██████████| 3/3 [00:00<00:00, 13.32it/s]\n",
            "Epoch: 03 - Train Loss: 5.641: 100%|██████████| 17/17 [00:11<00:00,  1.22it/s]\n",
            "Epoch: 03 - Valid Loss: 5.414: 100%|██████████| 3/3 [00:00<00:00, 12.96it/s]\n",
            "Epoch: 04 - Train Loss: 5.614: 100%|██████████| 17/17 [00:12<00:00,  1.30it/s]\n",
            "Epoch: 04 - Valid Loss: 5.391: 100%|██████████| 3/3 [00:00<00:00, 13.13it/s]\n",
            "Epoch: 05 - Train Loss: 5.584: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s]\n",
            "Epoch: 05 - Valid Loss: 5.370: 100%|██████████| 3/3 [00:00<00:00, 12.79it/s]\n",
            "Epoch: 06 - Train Loss: 5.551: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s]\n",
            "Epoch: 06 - Valid Loss: 5.333: 100%|██████████| 3/3 [00:00<00:00, 12.78it/s]\n",
            "Epoch: 07 - Train Loss: 5.510: 100%|██████████| 17/17 [00:12<00:00,  1.28it/s]\n",
            "Epoch: 07 - Valid Loss: 5.302: 100%|██████████| 3/3 [00:00<00:00, 13.24it/s]\n",
            "Epoch: 08 - Train Loss: 5.462: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s]\n",
            "Epoch: 08 - Valid Loss: 5.234: 100%|██████████| 3/3 [00:00<00:00, 12.78it/s]\n",
            "Epoch: 09 - Train Loss: 5.415: 100%|██████████| 17/17 [00:12<00:00,  1.29it/s]\n",
            "Epoch: 09 - Valid Loss: 5.148: 100%|██████████| 3/3 [00:00<00:00, 13.27it/s]\n",
            "Epoch: 10 - Train Loss: 5.354: 100%|██████████| 17/17 [00:12<00:00,  1.46it/s]\n",
            "Epoch: 10 - Valid Loss: 5.090: 100%|██████████| 3/3 [00:00<00:00, 13.18it/s]\n",
            "Epoch: 11 - Train Loss: 5.303: 100%|██████████| 17/17 [00:12<00:00,  1.44it/s]\n",
            "Epoch: 11 - Valid Loss: 5.029: 100%|██████████| 3/3 [00:00<00:00, 13.32it/s]\n",
            "Epoch: 12 - Train Loss: 5.277: 100%|██████████| 17/17 [00:12<00:00,  1.62it/s]\n",
            "Epoch: 12 - Valid Loss: 5.001: 100%|██████████| 3/3 [00:00<00:00, 12.96it/s]\n",
            "Epoch: 13 - Train Loss: 5.237: 100%|██████████| 17/17 [00:12<00:00,  1.16it/s]\n",
            "Epoch: 13 - Valid Loss: 4.948: 100%|██████████| 3/3 [00:00<00:00, 13.35it/s]\n",
            "Epoch: 14 - Train Loss: 5.191: 100%|██████████| 17/17 [00:12<00:00,  1.29it/s]\n",
            "Epoch: 14 - Valid Loss: 4.916: 100%|██████████| 3/3 [00:00<00:00, 12.57it/s]\n",
            "Epoch: 15 - Train Loss: 5.138: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s]\n",
            "Epoch: 15 - Valid Loss: 4.866: 100%|██████████| 3/3 [00:00<00:00, 12.52it/s]\n",
            "Epoch: 16 - Train Loss: 5.093: 100%|██████████| 17/17 [00:12<00:00,  1.50it/s]\n",
            "Epoch: 16 - Valid Loss: 4.816: 100%|██████████| 3/3 [00:00<00:00, 13.09it/s]\n",
            "Epoch: 17 - Train Loss: 5.039: 100%|██████████| 17/17 [00:12<00:00,  1.61it/s]\n",
            "Epoch: 17 - Valid Loss: 4.782: 100%|██████████| 3/3 [00:00<00:00, 13.41it/s]\n",
            "Epoch: 18 - Train Loss: 5.016: 100%|██████████| 17/17 [00:12<00:00,  1.20it/s]\n",
            "Epoch: 18 - Valid Loss: 4.760: 100%|██████████| 3/3 [00:00<00:00, 13.03it/s]\n",
            "Epoch: 19 - Train Loss: 4.993: 100%|██████████| 17/17 [00:12<00:00,  1.11it/s]\n",
            "Epoch: 19 - Valid Loss: 4.742: 100%|██████████| 3/3 [00:00<00:00, 12.89it/s]\n",
            "Epoch: 20 - Train Loss: 4.952: 100%|██████████| 17/17 [00:12<00:00,  1.45it/s]\n",
            "Epoch: 20 - Valid Loss: 4.720: 100%|██████████| 3/3 [00:00<00:00, 13.14it/s]\n",
            "Epoch: 21 - Train Loss: 4.889: 100%|██████████| 17/17 [00:12<00:00,  1.55it/s]\n",
            "Epoch: 21 - Valid Loss: 4.695: 100%|██████████| 3/3 [00:00<00:00, 12.82it/s]\n",
            "Epoch: 22 - Train Loss: 4.863: 100%|██████████| 17/17 [00:12<00:00,  1.56it/s]\n",
            "Epoch: 22 - Valid Loss: 4.685: 100%|██████████| 3/3 [00:00<00:00, 13.31it/s]\n",
            "Epoch: 23 - Train Loss: 4.797: 100%|██████████| 17/17 [00:12<00:00,  1.38it/s]\n",
            "Epoch: 23 - Valid Loss: 4.661: 100%|██████████| 3/3 [00:00<00:00, 13.26it/s]\n",
            "Epoch: 24 - Train Loss: 4.807: 100%|██████████| 17/17 [00:12<00:00,  1.53it/s]\n",
            "Epoch: 24 - Valid Loss: 4.669: 100%|██████████| 3/3 [00:00<00:00, 12.61it/s]\n",
            "Epoch: 25 - Train Loss: 4.762: 100%|██████████| 17/17 [00:13<00:00,  1.18it/s]\n",
            "Epoch: 25 - Valid Loss: 4.649: 100%|██████████| 3/3 [00:00<00:00, 12.48it/s]\n",
            "Epoch: 26 - Train Loss: 4.725: 100%|██████████| 17/17 [00:12<00:00,  1.49it/s]\n",
            "Epoch: 26 - Valid Loss: 4.647: 100%|██████████| 3/3 [00:00<00:00, 13.02it/s]\n",
            "Epoch: 27 - Train Loss: 4.704: 100%|██████████| 17/17 [00:12<00:00,  1.12it/s]\n",
            "Epoch: 27 - Valid Loss: 4.648: 100%|██████████| 3/3 [00:00<00:00, 13.03it/s]\n",
            "Epoch: 28 - Train Loss: 4.638: 100%|██████████| 17/17 [00:12<00:00,  1.29it/s]\n",
            "Epoch: 28 - Valid Loss: 4.638: 100%|██████████| 3/3 [00:00<00:00, 12.92it/s]\n",
            "Epoch: 29 - Train Loss: 4.606: 100%|██████████| 17/17 [00:12<00:00,  1.45it/s]\n",
            "Epoch: 29 - Valid Loss: 4.631: 100%|██████████| 3/3 [00:00<00:00, 13.11it/s]\n",
            "Epoch: 30 - Train Loss: 4.526: 100%|██████████| 17/17 [00:12<00:00,  1.23it/s]\n",
            "Epoch: 30 - Valid Loss: 4.631: 100%|██████████| 3/3 [00:00<00:00, 12.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ_klP1-6XyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7cd29037-0450-48a2-f8f5-a672fa4a1b13"
      },
      "source": [
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='valid')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxDV_RX866Hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f0e0e112-282f-426f-a73b-4ff65672bb11"
      },
      "source": [
        "seq2seq.load_state_dict(torch.load('./saved_models/seq2seq.pt').get('model'))\n",
        "test_loss = valid_step(seq2seq, criterion, test_iterator,\n",
        "                       sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                       epoch_text='Test loss => ')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss => Valid Loss: 4.641: 100%|██████████| 5/5 [00:00<00:00, 10.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8tYcPCLgz5",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRIlUJjLeDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}