{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 - Sequence to Sequence Model with RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wEd7p3ARFcyr",
        "v2BPfwqcFk4h",
        "tazMbPR6Hnjg",
        "yT-6GZgfMXIu",
        "7cFeoEJpMYgE",
        "2ZwOJLkTMbCt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEd7p3ARFcyr",
        "colab_type": "text"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gttqmxRIFSUa",
        "colab_type": "code",
        "outputId": "a57491fa-3286-4201-9bc3-22e222adc11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torchtext --upgrade\n",
        "!python -m spacy download fr\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 25.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n",
            "Collecting fr_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-cp36-none-any.whl size=14727027 sha256=cb243078567d7aa87f216318136cc92fe7319af6942c80dbfc11095b16b6305d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ztzj45pv/wheels/46/1b/e6/29b020e3f9420a24c3f463343afe5136aaaf955dbc9e46dfc5\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-A0mVf7GNix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Example, Field, Dataset\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0iX1ZuNG0wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 781\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2BPfwqcFk4h",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc5EcEA1FnCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./data'):\n",
        "    !mkdir ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmajgrxCHwsw",
        "colab_type": "code",
        "outputId": "abcd63e9-f6f2-4eab-bb4e-72616f57de64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
        "    -O ./data/fr-en.tgz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-19 20:07:56--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202718517 (193M) [application/x-gzip]\n",
            "Saving to: ‘./data/fr-en.tgz’\n",
            "\n",
            "./data/fr-en.tgz    100%[===================>] 193.33M   980KB/s    in 4m 10s  \n",
            "\n",
            "2020-03-19 20:12:06 (792 KB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2r79GZZH7Ip",
        "colab_type": "code",
        "outputId": "838d4e4c-217d-4c93-afaf-1d4e2a22335d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!tar -xzvf ./data/fr-en.tgz -C ./data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "europarl-v7.fr-en.en\n",
            "europarl-v7.fr-en.fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tazMbPR6Hnjg",
        "colab_type": "text"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Q9N_zBHpTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
        "            content = file.readlines()\n",
        "        return content\n",
        "    except:\n",
        "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02KzJaPmIjI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    # NFD => Normal Form Decompose\n",
        "    # Mn => Non Marking Space\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
        "                    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.strip())\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJtKDpMJF-1",
        "colab_type": "code",
        "outputId": "27290cb2-4a77-4200-b790-819142f587c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%time\n",
        "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
        "              read_file('./data/europarl-v7.fr-en.en'))]\n",
        "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
        "print(f'Number of examples: {len(pairs)}')\n",
        "pairs = np.random.choice(pairs, size=3000, replace=False)\n",
        "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
        "              pairs)]\n",
        "print(f'Number of examples after sampling: {len(pairs)}')\n",
        "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 2007723\n",
            "Number of examples after sampling: 3000\n",
            "Example:\n",
            "\tFR => Les procedures par le biais desquelles de tels produits entrent et sortent de l'Union europeenne doivent etre ouvertes, transparentes et, par dessus tout, sures.\n",
            "\tEN => The procedures whereby such products come in and out of the European Union have to be open, transparent and, above all, safe.\n",
            "CPU times: user 3.84 s, sys: 930 ms, total: 4.77 s\n",
            "Wall time: 4.78 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAq2uyDyJ6KD",
        "colab_type": "code",
        "outputId": "64369eb2-8c31-44bf-ecbb-abb0de8122d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "%%time\n",
        "FR = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           preprocessing=lambda x: x[::-1],\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='fr',\n",
        "           include_lengths=True) # For pack_padded_sequence\n",
        "EN = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='en')\n",
        "\n",
        "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
        "                                                'en': ('dest', EN)})\n",
        "            for pair in tqdm.tqdm(pairs)]\n",
        "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
        "train_data, valid_data, test_data = data.split(split_ratio=[0.7, 0.2, 0.1])\n",
        "print(f'train size: {len(train_data.examples)}')\n",
        "print(f'valid size: {len(valid_data.examples)}')\n",
        "print(f'test size: {len(test_data.examples)}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:01<00:00, 2232.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train size: 2100\n",
            "valid size: 300\n",
            "test size: 600\n",
            "{'src': ['.', 'rester', 'de', 'permettant', 'leur', 'integration', \"'\", 'd', 'politique', 'une', 'prioritairement', 'place', 'en', 'mettre', 'faut', 'il', \"'\", 'qu', 'et', ',', '\"', 'union', \"'\", 'l', 'de', 'citoyens', 'des', 'ceux', 'de', 'possible', 'que', 'proches', 'aussi', 'uniformes', 'droits', 'de', 'ensemble', 'un', '\"', ':', 'cite', 'je', ',', 'legaux', 'immigres', 'aux', 'donner', 'faut', 'il', \"'\", 'qu', ',', 'reprises', 'plusieurs', 'a', ',', 'fortement', 'proclame', 'il', ',', 'temps', 'meme', 'en', 'mais', ',', 'source', 'la', 'a', 'clandestine', 'immigration', \"'\", 'l', 'combattre', 'de', 'et', 'migratoires', 'flux', 'les', 'gerer', 'de', 'platonique', 'volonte', 'la', 'affiche', 'tampere', 'de', 'conseil', 'le', ':', 'contradiction', 'seconde'], 'dest': ['the', 'second', 'contradiction', ':', 'the', 'tampere', 'council', 'propounds', 'its', 'purely', 'formal', 'intention', 'to', 'control', 'the', 'flows', 'of', 'migrants', 'and', 'to', 'combat', 'illegal', 'immigration', 'at', 'source', ',', 'but', ',', 'at', 'the', 'same', 'time', ',', 'staunchly', 'proclaims', ',', 'on', 'several', 'occasions', ',', 'that', 'legal', 'immigrants', 'must', 'be', 'given', ',', 'i', 'quote', ',', '\"', 'a', 'set', 'of', 'uniform', 'rights', 'which', 'are', 'as', 'near', 'as', 'possible', 'to', 'those', 'enjoyed', 'by', 'eu', 'citizens', '\"', ',', 'and', 'that', 'as', 'a', 'priority', 'a', 'policy', 'of', 'integration', 'must', 'be', 'set', 'up', 'to', 'enable', 'them', 'to', 'stay', '.']}\n",
            "CPU times: user 10.8 s, sys: 160 ms, total: 10.9 s\n",
            "Wall time: 10.9 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JycVMjsRLmoB",
        "colab_type": "code",
        "outputId": "1e833ee2-cf9e-47e2-fc21-1b06f9be07f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "FR.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "EN.build_vocab(train_data,\n",
        "               min_freq=2,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "\n",
        "print(f'Length of FR vocabulary: {len(FR.vocab)}')\n",
        "print(f'Length of EN vocabulary: {len(EN.vocab)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of FR vocabulary: 3472\n",
            "Length of EN vocabulary: 3110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKKRGB9cIbn8",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-6GZgfMXIu",
        "colab_type": "text"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJL7MVwAMVtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0, bidirectional=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0),\n",
        "                            bidirectional=bidirectional)\n",
        "    \n",
        "    def forward(self, in_, seq_len):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            seq_len: (batch_size)\n",
        "\n",
        "        outputs\n",
        "            out: (seq_len, batch_size, num_directions * hidden_size)\n",
        "            hn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "            cn: (num_layers * num_directions, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, seq_len)\n",
        "        out, (hn, cn) = self.lstm(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(out)\n",
        "        return out, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cFeoEJpMYgE",
        "colab_type": "text"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deAfHkCcIdzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
        "                 n_layers=1, dropout=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=(dropout if n_layers > 1 else 0))\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "        \n",
        "    def forward(self, in_, h0, c0):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (1, batch_size) => seq_len = 1, a word\n",
        "            h0: (num_layers, batch_size, hidden_size)\n",
        "            c0: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "        embed = self.embedding(_in) \n",
        "        # embedded: (1, batch_size, embed_size)\n",
        "        out, hn, cn = self.lstm(embedded)\n",
        "        # out: (1, batch_size, hidden_size)\n",
        "        # hn: (num_layers, batch_size, hidden_size)\n",
        "        # cn: (num_layers, batch_size, hidden_size)\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        # logit: (batch_size, vocab_size)\n",
        "\n",
        "        outputs: logit, hn, cn\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(in_)\n",
        "        embedded = self.dropout(embedded)\n",
        "        out, (hn, cn) = self.lstm(embedded, (h0, c0))\n",
        "        logit = self.fc(out.squeeze(0))\n",
        "        return logit, hn, cn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZwOJLkTMbCt",
        "colab_type": "text"
      },
      "source": [
        "## Sequence to sequence model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Wd0iNaMgp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SeqToSeqNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device=device):\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent layers'\n",
        "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
        "        'Encoder and Decoder have to have the same number of reccurent hidden units'\n",
        "\n",
        "        super(SeqToSeqNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def encode(self, in_, seq_len):\n",
        "        _, hn, cn = self.encoder(in_, seq_len)\n",
        "        # Sum the two directional encoder hn state\n",
        "        if self.encoder.bidirectional:\n",
        "            hn = hn[:self.encoder.n_layers, :, :] + \\\n",
        "                    hn[self.encoder.n_layers:, :, :]\n",
        "            cn = cn[:self.encoder.n_layers, :, :] + \\\n",
        "                    cn[self.encoder.n_layers:, :, :]\n",
        "        return hn, cn\n",
        "\n",
        "    def decode(self, h_state, c_state, target, sos_index, teacher_forcing, ratio):\n",
        "        target_len, batch_size = target.size()\n",
        "        out = torch.zeros((target_len, batch_size, self.decoder.vocab_size),\n",
        "                           device=self.device)\n",
        "        in_ = target[0, :].unsqueeze(0)\n",
        "        for t in range(1, target_len):\n",
        "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
        "            out[t] = logit # (batch_size, vocab_size)\n",
        "            if teacher_forcing and random.random() < ratio:\n",
        "                in_ = logit.argmax(1).unsqueeze(0) # (1, batch_size)\n",
        "            else:\n",
        "                in_ = target[t, :].unsqueeze(0)\n",
        "        return out\n",
        "\n",
        "    def forward(self, in_, seq_len, target, sos_index,\n",
        "                teacher_forcing=True, ratio=.5):\n",
        "        \"\"\"\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            seq_len: (batch_size)\n",
        "            target: (seq_len, batch_size)\n",
        "            sos_index: int\n",
        "            eos_index: int\n",
        "\n",
        "        outputs\n",
        "            out: (seq_len, batch_size, vocab_size)\n",
        "        \"\"\"\n",
        "        hn, cn = self.encode(in_, seq_len)\n",
        "        out = self.decode(hn, cn, target, sos_index, teacher_forcing, ratio)\n",
        "        return out\n",
        "\n",
        "    def infer(self, h_state, c_state, sos_index, eos_index, max_len, sample):\n",
        "        \"\"\"\n",
        "        Infer a sequence. Not a batch.\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        in_ = torch.ones((1, 1), device=self.device,\n",
        "                         dtype=torch.int64) * sos_index\n",
        "        for _ in range(max_len):\n",
        "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
        "            if sample:\n",
        "                probs = F.softmax(logit, dim=1) # (1, vocab_size)\n",
        "                next_ = torch.multinomial(probs, 1) # (1, 1)\n",
        "            else:\n",
        "                in_, next_ = logit.topk(1, dim=1) # (batch_size=1, 1)\n",
        "            next_idx = next_.squeeze().cpu().item()\n",
        "            if next_idx == eos_index:\n",
        "                break\n",
        "            out.append(next_idx)\n",
        "            in_ = torch.ones((1, 1), device=self.device,\n",
        "                             dtype=torch.int64) * next_idx # (1, 1)\n",
        "        return out\n",
        "\n",
        "    def inference(self, in_, seq_len, sos_index, eos_index, max_len, sample=True):\n",
        "        \"\"\"\n",
        "        Inferring a sentence or a batch of sentences.\n",
        "        inputs\n",
        "            in_: (seq_len, batch_size)\n",
        "            seq_len: (batch_size)\n",
        "            sos_index: int\n",
        "            eos_index: int\n",
        "            max_len: int\n",
        "            sample: bool\n",
        "\n",
        "        outputs\n",
        "            out: list(seq_len*, batch_size)\n",
        "        \"\"\"\n",
        "        hn, cn = self.encode(in_, seq_len)\n",
        "        # hn: (num_layers, batch_size, hidden_size)\n",
        "        # cn: (num_layers, batch_size, hidden_size)\n",
        "        _, batch_size = in_.size()\n",
        "        out = []\n",
        "        for i in range(batch_size):\n",
        "            out.append(\n",
        "                self.infer(hn[:, i, :].unsqueeze(1),\n",
        "                           cn[:, i, :].unsqueeze(1),\n",
        "                           sos_index, eos_index, max_len, sample))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCLUmCfFMjGV",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_aldUUdZ5dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(model: nn.Module):\n",
        "    for name, param in model.named_parameters():\n",
        "        nn.init.uniform_(param.data, a=-0.08, b=0.08)\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1teOdv5q7ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    grad_mean, layers = [], []\n",
        "    for name, param in named_parameters:\n",
        "        if param.requires_grad and 'bias' not in name:\n",
        "            layers.append(name)\n",
        "            grad_mean.append(param.grad.abs().mean())\n",
        "    plt.plot(grad_mean, alpha=0.3, color='b')\n",
        "    plt.hlines(0, 0, len(grad_mean) + 1, linewidth=1, color='k' )\n",
        "    plt.xticks(range(0, len(grad_mean), 1), layers, rotation='vertical')\n",
        "    plt.xlim(xmin=0, xmax=len(grad_mean))\n",
        "    # plt.ylim(bottom=-0.001, top=0.02) # Zoom on lower gradients\n",
        "    plt.xlabel('Layers')\n",
        "    plt.ylabel('Mean of gradients')\n",
        "    plt.title('Gradient Flow')\n",
        "    plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8QgblulqoWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, opt, loss_func, data_it, grad_clip, sos_index,\n",
        "               epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.train()\n",
        "    for i, data in pbar:\n",
        "        opt.zero_grad()\n",
        "        logits = model(*data.src, data.dest, sos_index)\n",
        "        # *data.src: unpack in_ and seq_len\n",
        "        loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                         data.dest[1:].view(-1))\n",
        "        loss.backward()\n",
        "        # plot_grad_flow(model.named_parameters())\n",
        "        if grad_clip:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        opt.step()\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_description(epoch_text + f'Train Loss: {epoch_loss/(i+1):.3f}')\n",
        "    # plt.show() # Show the gradient flow\n",
        "    return epoch_loss / len(data_it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYND0IGKrdJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def valid_step(model, loss_func, data_it, sos_index, epoch_text=''):\n",
        "    epoch_loss = 0.\n",
        "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in pbar:\n",
        "            logits = model(*data.src, data.dest, sos_index,\n",
        "                           teacher_forcing=False)\n",
        "            loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
        "                             data.dest[1:].view(-1))\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_description(epoch_text + f'Valid Loss: {epoch_loss/(i+1):.3f}')\n",
        "    return epoch_loss / len(data_it)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECEXh0oHwSFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, loss_function, train_it, valid_it, n_epochs, sos_index,\n",
        "          grad_clip=None, save_to='./saved_models', filename='seq2seq.pt'):\n",
        "    assert callable(loss_function)\n",
        "    if not os.path.exists(save_to):\n",
        "        !mkdir {save_to}\n",
        "\n",
        "    history = {'loss': [], 'val_loss': []}\n",
        "    best_loss = float('inf')\n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_text = f'Epoch: {epoch + 1:02d} - '\n",
        "        loss = train_step(model, optimizer, loss_function, train_it, grad_clip,\n",
        "                          sos_index, epoch_text)\n",
        "        val_loss = valid_step(model, loss_function, valid_it, sos_index,\n",
        "                              epoch_text)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'optimizer': optimizer.state_dict()},\n",
        "                       f=os.path.join(save_to, filename))\n",
        "\n",
        "        history['loss'].append(loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZV_iUlh3CWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_SIZE = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LR = 1e-3\n",
        "GRAD_CLIP = 1.0\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 30\n",
        "MAX_LEN = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBekgFKP3C3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator =  \\\n",
        "        BucketIterator.splits((train_data, valid_data,\n",
        "                               test_data),\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              # sort_key=lambda x: (len(x.src), len(x.dest)),\n",
        "                              sort_key=lambda x: len(x.src),\n",
        "                              sort_within_batch=True, # For pack_padded_sequence\n",
        "                              device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCWVfRdAxY6N",
        "colab_type": "code",
        "outputId": "1d3a0be8-26c7-404c-ba6c-b1722e7d871d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoder = Encoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(FR.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "decoder = Decoder(embed_size=EMBEDDING_DIM,\n",
        "                  vocab_size=len(EN.vocab),\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  n_layers=N_LAYERS,\n",
        "                  dropout=DROPOUT).to(device)\n",
        "seq2seq = SeqToSeqNet(encoder=encoder, decoder=decoder).to(device)\n",
        "seq2seq.apply(init_weights)\n",
        "optimizer = optim.Adam(seq2seq.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=EN.vocab.stoi[EN.pad_token])\n",
        "print(f'Number of parameters of the model: {count_parameters(seq2seq):,}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 16,972,142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22m0tls06BS",
        "colab_type": "code",
        "outputId": "d6f9779c-82ff-4e0b-9a4b-e8fdffe98111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = train(seq2seq, optimizer, criterion, train_iterator, valid_iterator,\n",
        "                sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 - Train Loss: 6.429: 100%|██████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "Epoch: 01 - Valid Loss: 5.570: 100%|██████████| 3/3 [00:00<00:00, 16.49it/s]\n",
            "Epoch: 02 - Train Loss: 5.724: 100%|██████████| 17/17 [00:03<00:00,  4.36it/s]\n",
            "Epoch: 02 - Valid Loss: 5.486: 100%|██████████| 3/3 [00:00<00:00, 17.01it/s]\n",
            "Epoch: 03 - Train Loss: 5.628: 100%|██████████| 17/17 [00:03<00:00,  4.32it/s]\n",
            "Epoch: 03 - Valid Loss: 5.453: 100%|██████████| 3/3 [00:00<00:00, 16.81it/s]\n",
            "Epoch: 04 - Train Loss: 5.579: 100%|██████████| 17/17 [00:03<00:00,  4.29it/s]\n",
            "Epoch: 04 - Valid Loss: 5.430: 100%|██████████| 3/3 [00:00<00:00, 16.63it/s]\n",
            "Epoch: 05 - Train Loss: 5.540: 100%|██████████| 17/17 [00:03<00:00,  4.26it/s]\n",
            "Epoch: 05 - Valid Loss: 5.421: 100%|██████████| 3/3 [00:00<00:00, 15.89it/s]\n",
            "Epoch: 06 - Train Loss: 5.513: 100%|██████████| 17/17 [00:04<00:00,  4.24it/s]\n",
            "Epoch: 06 - Valid Loss: 5.404: 100%|██████████| 3/3 [00:00<00:00, 16.22it/s]\n",
            "Epoch: 07 - Train Loss: 5.484: 100%|██████████| 17/17 [00:04<00:00,  4.20it/s]\n",
            "Epoch: 07 - Valid Loss: 5.385: 100%|██████████| 3/3 [00:00<00:00, 16.05it/s]\n",
            "Epoch: 08 - Train Loss: 5.446: 100%|██████████| 17/17 [00:04<00:00,  4.18it/s]\n",
            "Epoch: 08 - Valid Loss: 5.349: 100%|██████████| 3/3 [00:00<00:00, 15.41it/s]\n",
            "Epoch: 09 - Train Loss: 5.406: 100%|██████████| 17/17 [00:04<00:00,  4.19it/s]\n",
            "Epoch: 09 - Valid Loss: 5.275: 100%|██████████| 3/3 [00:00<00:00, 15.80it/s]\n",
            "Epoch: 10 - Train Loss: 5.351: 100%|██████████| 17/17 [00:04<00:00,  4.22it/s]\n",
            "Epoch: 10 - Valid Loss: 5.210: 100%|██████████| 3/3 [00:00<00:00, 15.81it/s]\n",
            "Epoch: 11 - Train Loss: 5.317: 100%|██████████| 17/17 [00:04<00:00,  4.21it/s]\n",
            "Epoch: 11 - Valid Loss: 5.165: 100%|██████████| 3/3 [00:00<00:00, 16.10it/s]\n",
            "Epoch: 12 - Train Loss: 5.266: 100%|██████████| 17/17 [00:03<00:00,  4.29it/s]\n",
            "Epoch: 12 - Valid Loss: 5.109: 100%|██████████| 3/3 [00:00<00:00, 16.36it/s]\n",
            "Epoch: 13 - Train Loss: 5.236: 100%|██████████| 17/17 [00:04<00:00,  4.23it/s]\n",
            "Epoch: 13 - Valid Loss: 5.077: 100%|██████████| 3/3 [00:00<00:00, 16.61it/s]\n",
            "Epoch: 14 - Train Loss: 5.200: 100%|██████████| 17/17 [00:03<00:00,  4.26it/s]\n",
            "Epoch: 14 - Valid Loss: 5.053: 100%|██████████| 3/3 [00:00<00:00, 16.18it/s]\n",
            "Epoch: 15 - Train Loss: 5.168: 100%|██████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "Epoch: 15 - Valid Loss: 5.014: 100%|██████████| 3/3 [00:00<00:00, 16.51it/s]\n",
            "Epoch: 16 - Train Loss: 5.106: 100%|██████████| 17/17 [00:03<00:00,  4.33it/s]\n",
            "Epoch: 16 - Valid Loss: 4.978: 100%|██████████| 3/3 [00:00<00:00, 16.78it/s]\n",
            "Epoch: 17 - Train Loss: 5.081: 100%|██████████| 17/17 [00:03<00:00,  4.32it/s]\n",
            "Epoch: 17 - Valid Loss: 4.988: 100%|██████████| 3/3 [00:00<00:00, 16.48it/s]\n",
            "Epoch: 18 - Train Loss: 5.027: 100%|██████████| 17/17 [00:03<00:00,  4.34it/s]\n",
            "Epoch: 18 - Valid Loss: 4.948: 100%|██████████| 3/3 [00:00<00:00, 16.52it/s]\n",
            "Epoch: 19 - Train Loss: 5.053: 100%|██████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "Epoch: 19 - Valid Loss: 4.936: 100%|██████████| 3/3 [00:00<00:00, 16.52it/s]\n",
            "Epoch: 20 - Train Loss: 4.983: 100%|██████████| 17/17 [00:03<00:00,  4.30it/s]\n",
            "Epoch: 20 - Valid Loss: 4.911: 100%|██████████| 3/3 [00:00<00:00, 15.65it/s]\n",
            "Epoch: 21 - Train Loss: 4.939: 100%|██████████| 17/17 [00:03<00:00,  4.27it/s]\n",
            "Epoch: 21 - Valid Loss: 4.892: 100%|██████████| 3/3 [00:00<00:00, 16.46it/s]\n",
            "Epoch: 22 - Train Loss: 4.937: 100%|██████████| 17/17 [00:03<00:00,  4.28it/s]\n",
            "Epoch: 22 - Valid Loss: 4.887: 100%|██████████| 3/3 [00:00<00:00, 16.23it/s]\n",
            "Epoch: 23 - Train Loss: 4.880: 100%|██████████| 17/17 [00:03<00:00,  4.27it/s]\n",
            "Epoch: 23 - Valid Loss: 4.874: 100%|██████████| 3/3 [00:00<00:00, 16.44it/s]\n",
            "Epoch: 24 - Train Loss: 4.860: 100%|██████████| 17/17 [00:03<00:00,  4.31it/s]\n",
            "Epoch: 24 - Valid Loss: 4.850: 100%|██████████| 3/3 [00:00<00:00, 15.98it/s]\n",
            "Epoch: 25 - Train Loss: 4.817: 100%|██████████| 17/17 [00:03<00:00,  4.25it/s]\n",
            "Epoch: 25 - Valid Loss: 4.836: 100%|██████████| 3/3 [00:00<00:00, 15.68it/s]\n",
            "Epoch: 26 - Train Loss: 4.801: 100%|██████████| 17/17 [00:03<00:00,  4.26it/s]\n",
            "Epoch: 26 - Valid Loss: 4.808: 100%|██████████| 3/3 [00:00<00:00, 16.11it/s]\n",
            "Epoch: 27 - Train Loss: 4.782: 100%|██████████| 17/17 [00:04<00:00,  4.23it/s]\n",
            "Epoch: 27 - Valid Loss: 4.817: 100%|██████████| 3/3 [00:00<00:00, 16.38it/s]\n",
            "Epoch: 28 - Train Loss: 4.651: 100%|██████████| 17/17 [00:03<00:00,  4.27it/s]\n",
            "Epoch: 28 - Valid Loss: 4.777: 100%|██████████| 3/3 [00:00<00:00, 16.15it/s]\n",
            "Epoch: 29 - Train Loss: 4.655: 100%|██████████| 17/17 [00:03<00:00,  4.26it/s]\n",
            "Epoch: 29 - Valid Loss: 4.793: 100%|██████████| 3/3 [00:00<00:00, 16.48it/s]\n",
            "Epoch: 30 - Train Loss: 4.664: 100%|██████████| 17/17 [00:03<00:00,  4.25it/s]\n",
            "Epoch: 30 - Valid Loss: 4.793: 100%|██████████| 3/3 [00:00<00:00, 15.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ_klP1-6XyF",
        "colab_type": "code",
        "outputId": "594ec77b-331d-4a6e-87eb-3da5088583a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(history['loss'], label='train')\n",
        "plt.plot(history['val_loss'], label='valid')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd3xUZdbA8d9J770A6fQSaiCACCYW\nRFSQtRd0XRV1bavr7ur7rq66uuu7q66uDbHtWgBd1LVhQU0EFJDeO6EklNAh9CTn/eMOEiAkQwiZ\nZOZ8P5/7mZlbZs5x8MzNc5/7PKKqGGOM8X5+ng7AGGNMw7CCb4wxPsIKvjHG+Agr+MYY4yOs4Btj\njI+wgm+MMT7CCr4xxvgIK/jGp4nIahE519NxGNMQrOAbY4yPsIJvzDFEJFhEnhWR9a7lWREJdm1L\nEJHPRGSHiGwTkUki4ufa9gcRKRGR3SKyVETO8WwmxhwtwNMBGNMI/S/QB+gGKPAx8EfgIeC3QDGQ\n6Nq3D6Ai0g64E+ilqutFJBPwb9iwjamZneEbc7xrgcdUtVRVNwOPAsNd2w4BzYEMVT2kqpPUGZCq\nAggGOopIoKquVtWVHonemBOwgm/M8VoAa6q8XuNaB/B3YAXwtYisEpEHAFR1BfAb4BGgVETGikgL\njGlErOAbc7z1QEaV1+mudajqblX9raq2BIYA9x1uq1fV0ap6putYBf6vYcM2pmZW8I2BQBEJObwA\nY4A/ikiiiCQADwPvAIjIRSLSWkQE2InTlFMpIu1E5GzXxd39wD6g0jPpGFM9K/jGwHicAn14CQFm\nAPOA+cAs4HHXvm2Ab4AyYArwkqoW4LTfPwlsATYCScCDDZeCMbUTmwDFGGN8g53hG2OMj7CCb4wx\nPsIKvjHG+Ai3Cr6IxIjIOBFZIiKLRaTvMdvzRGSniMxxLQ9X2TbIdZv5isN9lo0xxjQ8d4dWeA74\nUlUvE5EgIKyafSap6kVVV4iIP/AicB7O7ejTReQTVV1U04clJCRoZmamm6Edbc+ePYSHh9fp2MbI\n2/IB78vJ2/IB78vJ2/KB43OaOXPmFlVNrOGQ2gu+iEQDA4BfAqjqQeCgmzHlAitUdZXrvcYCQ4Ea\nC35mZiYzZsxw8yOOVlhYSF5eXp2ObYy8LR/wvpy8LR/wvpy8LR84PicRWXPivV371NYtU0S6AaNw\ninRXYCZwj6ruqbJPHvABzln8euB+VV0oIpcBg1T1Ztd+w4HeqnpnNZ8zAhgBkJycnDN27NjaYq9W\nWVkZERERdTq2MfK2fMD7cvK2fMD7cvK2fOD4nPLz82eqas8aD1LVGhegJ1COU6jBad758zH7RAER\nrueDgeWu55cBr1XZbzjwQm2fmZOTo3VVUFBQ52MbI2/LR9X7cvK2fFS9Lydvy0f1+JyAGVpLbXXn\nom0xUKyq01yvxwE9jvnR2KWqZa7n43FuVU8ASoC0KrumutYZY4xpYLW24avqRhFZJyLtVHUpcA7H\ntMGLSDNgk6qqiOTi9P7ZCuwA2ohIFk6hvwq4pr6TMMb4tkOHDlFcXMz+/fur3R4dHc3ixYsbOKrT\nIyQkhNTU1Dod624vnbuAd109dFYBN4rIbQCqOhKn6eZ2ESnHGYvkKtefGOUicifwFc5kEG+o6sI6\nRWqMMSdQXFxMZGQkmZmZOOPaHW337t1ERkZ6ILL6paps3bqV4uLiOh3vVsFX1Tk4bflVjayy/QXg\nhRMcOx5ncCpjjDkt9u/ff8Ji701EhPj4eDZv3lyn4+1OW2OMV/D2Yn/YqeTpNQW/olJ5sWAFC7aU\nezoUY4xplLym4Pv7Ca98v5JZpRWeDsUY42N27NjBSy+9dNLHDR48mB07dpyGiKrnNQUfID0+jNK9\nNr6/MaZhnajgl5fX3OIwfvx4YmJiTldYx/Gqgp8RF87mvTarnDGmYT3wwAOsXLmSbt260atXL/r3\n78+QIUPo2LEjAJdccgk5OTl06tSJUaNG/XxcZmYmW7ZsYfXq1XTo0IFbbrmFTp06MXDgQPbt21fv\ncbrbLbNJSIsL48sFSkWl4u/nGxdwjDFHe/TThSxav+uodRUVFfj7+9f5PTu2iOJPF3c64fYnn3yS\nBQsWMGfOHAoLC7nwwgtZsGABWVlZALzxxhvExcWxb98+evXqxaWXXkp8fPxR77F8+XLGjBnDq6++\nyhVXXMEHH3zAddddV+eYq+NVZ/jpcWFUKGzcVf3NF8YY0xByc3N/LvYA//znP+natSt9+vRh3bp1\nLF++/LhjsrKy6NatGwA5OTmsXr263uPyqjP89Dhn1OY1W/eQEhPq4WiMMZ5Q3Zl4Q994VXXY4sLC\nQr755humTJlCWFgYeXl51d4RHBwc/PNzf3//09Kk41Vn+BnxTsFft22vhyMxxviSyMhIdu/eXe22\nnTt3EhsbS1hYGEuWLGHq1KkNHN0RXnWG3zw6BD+BtVbwjTENKD4+nn79+pGdnU1oaCjJyck/bxs0\naBAjR46kQ4cOtGvXjj59+ngsTq8q+AH+fsSHCGu31f+fQsYYU5PRo0dXuz44OJgvvvii2m2H2+kT\nEhJYsGDBz+vvv//+eo8PvKxJByApTFi7dU/tOxpjjI/xuoKfGOZnTTrGGFMNryv4SaHC9r2H2LX/\nkKdDMcaYRsXrCn5imJOS9dQxxpijeV3BTwpz7rBdu9UKvjHGVOV1BT8x1EnJ2vGNMeZoXlfwwwKF\nmLBAK/jGmEYtIiICgPXr13PZZZdVu09eXh4zZsyot8/0uoIPzhALVvCNMU1BixYtGDduXIN8llsF\nX0RiRGSciCwRkcUi0veY7deKyDwRmS8iP4pI1yrbVrvWzxGR+vupqoEVfGNMQ3vggQd48cUXf379\nyCOP8Pjjj3POOefQo0cPOnfuzMcff3zccatXryY7OxuAffv2cdVVV9GhQweGDRtW7+PpuHun7XPA\nl6p6mYgEAWHHbC8CzlLV7SJyATAK6F1le76qbjn1cN2THhfGlws2Ul5RSYC/V/4RY4w5kS8egI3z\nj1oVWlEO/qcwsECzznDBkzXucuWVV/Kb3/yGO+64A4D333+fr776irvvvpuoqCi2bNlCnz59GDJk\nyAnnpX355ZcJCwtj8eLFzJs3jx49etQ95mrU+l9ARKKBAcAvAVT1IHCw6j6q+mOVl1OB1PoL8eSl\nx4VRXqls2LmftLhjf5uMMab+de/endLSUtavX8/mzZuJjY2lWbNm3HvvvUycOBE/Pz9KSkrYtGkT\nzZo1q/Y9Jk6cyN133w1Aly5d6NKlS73G6M5PXhawGXjT1VQzE7hHVU80fsFNQNWBIxT4WkQUeEVV\nR1V3kIiMAEYAJCcnU1hY6F4GxygrK2P7Vmes6U8LptAxvu6THjQGZWVldf5v0Vh5W07elg80vZyi\no6OPjFZ55v8et/1UJ0AB4ASjYVY1ZMgQ3nnnHUpLSxk6dCivv/46GzZsoLCwkMDAQLKzs9myZcvP\nwyfv3r2bsrIyKisr2b17N+Xl5ezdu/fnXCorK9mzZ89xI3Hu37+/bt+Rqta4AD2BcqC36/VzwJ9P\nsG8+sBiIr7IuxfWYBMwFBtT2mTk5OVpXBQUFum7bHs34w2c6etqaOr9PY1FQUODpEOqdt+Xkbfmo\nNr2cFi1aVOP2Xbt2NUgcCxYs0L59+2qbNm10/fr1+uyzz+qdd96pqqrfffedAlpUVKSqquHh4aqq\nWlRUpJ06dVJV1aefflpvuukmVVWdP3+++vv76/Tp04/7nEWLFh33HQEztJba6k4DdzFQrKrTXK/H\nAcc1LIlIF+A1YKiqbq3yg1LieiwFPgJyT+oXqQ6aR4cS4Cd24dYY06A6derE7t27SUlJoXnz5lx7\n7bXMmDGDzp0789Zbb9G+ffsaj7/99tspKyujQ4cOPPzww+Tk5NRrfLU26ajqRhFZJyLtVHUpcA6w\nqOo+IpIOfAgMV9VlVdaHA36qutv1fCDwWL1mUA1/PyE1NtQKvjGmwc2ff+SCcUJCAlOmTKl2v7Ky\nMsCZyPzw0MihoaGMHTv2tMXm7mXru4B3XT10VgE3ishtAKo6EngYiAdecl19LlfVnkAy8JFrXQAw\nWlW/rN8UqpceH27DKxhjTBVuFXxVnYPTll/VyCrbbwZurua4VUDXY9c3hPS4UOau2+GJjzbGmEbJ\nazupp8eFsXPfIXbutWGSjfEFznVL73cqeXp1wQdYt92adYzxdiEhIWzdutXri76qsnXrVkJCQup0\nvFfNaVtVepzTz3XN1r1kp0R7OBpjzOmUmppKcXExmzdvrnb7/v3761wkG5uQkBBSU1NZs2bNSR/r\ntQU/LS4UsGGSjfEFgYGBZGVlnXB7YWEh3bt3b8CIGievbdKJDAkkLjzICr4xxrh4bcEHSIsLs6kO\njTHGxasLfkZcGGu2nWjIH2OM8S1eXfDT48JYv2M/hyoqPR2KMcZ4nNcX/IpKZcOO/Z4OxRhjPM67\nC3680xffLtwaY4y3F3zXzVfWjm+MMV5e8JOjQgjy97MzfGOMwcsL/uFhkq1rpjHGeHnBB6cd387w\njTHGFwp+XBhrtu71+kGVjDGmNj5R8HfvL2fnPhsm2Rjj27y+4KfFWddMY4wBHyj4GdYX3xhjAB8o\n+Gmxrr74Nr+tMcbHuVXwRSRGRMaJyBIRWSwifY/ZLiLyTxFZISLzRKRHlW03iMhy13JDfSdQm/Dg\nABIigqxrpjHG57k7AcpzwJeqepmIBAFhx2y/AGjjWnoDLwO9RSQO+BPOBOgKzBSRT1R1e71E76b0\nOOuaaYwxtZ7hi0g0MAB4HUBVD6rqjmN2Gwq8pY6pQIyINAfOByao6jZXkZ8ADKrXDNxwuGumMcb4\nMnfO8LOAzcCbItIVmAnco6pVB6hJAdZVeV3sWnei9ccRkRHACIDk5GQKCwvdTOFoZWVlxx1bufsg\n63cc4pvvCgjwkzq9r6dUl09T5205eVs+4H05eVs+ULec3Cn4AUAP4C5VnSYizwEPAA+ddIQ1UNVR\nwCiAnj17al5eXp3ep7CwkGOP3Ryxjk9WzqN1l1wyE8JPMdKGVV0+TZ235eRt+YD35eRt+UDdcnLn\nom0xUKyq01yvx+H8AFRVAqRVeZ3qWnei9Q0qI94p8taOb4zxZbUWfFXdCKwTkXauVecAi47Z7RPg\neldvnT7ATlXdAHwFDBSRWBGJBQa61jWoI8MkW8E3xvgud3vp3AW86+qhswq4UURuA1DVkcB4YDCw\nAtgL3Ojatk1E/gxMd73PY6q6rR7jd0tSZDBBAX7WNdMY49PcKviqOgena2VVI6tsV+COExz7BvBG\nXQOsD35+QlpsKGutp44xxod5/Z22h2XEh1sbvjHGp/lMwT9885UNk2yM8VU+U/DT4sIoO1DO9r02\nTLIxxjf5TMFPt2GSjTE+zmcKvg2TbIzxdT5T8A8Pk7x2655a9jTGGO/kMwU/NMifxMhgO8M3xvgs\nnyn4ABk2TLIxxof5VMFPjwtj3bZ9ng7DGGM8wqcKflpcGOt37uNAeYWnQzHGmAbnUwU/PS4MVSjZ\nbmf5xhjf41MF37pmGmN8mU8VfLv5yhjjy3yq4CdGBhMc4GejZhpjfJJPFXwR+XkQNWOM8TU+VfDB\nace3gm+M8UU+V/DTbJhkY4yP8rmCnx4Xxt6DFWzdc9DToRhjTIPyuYJvXTONMb7KrTltRWQ1sBuo\nAMpVtecx238HXFvlPTsAia5JzGs8tqEd7pq5btteeqTHejIUY4xpUG4VfJd8Vd1S3QZV/TvwdwAR\nuRi4V1W3uXNsQ0t1DZO8xrpmGmN8zOlo0rkaGHMa3rdehAT6kxxlwyQbY3yPuNNbRUSKgO2AAq+o\n6qgT7BcGFAOtD5/hn8SxI4ARAMnJyTljx449+WyAsrIyIiIiatznL9P2IcCDvUPr9BkNyZ18mhpv\ny8nb8gHvy8nb8oHjc8rPz59Za5O5qta6ACmuxyRgLjDgBPtdCXxal2OrLjk5OVpXBQUFte5z33tz\ntM9fvqnzZzQkd/JparwtJ2/LR9X7cvK2fFSPzwmYobXUVreadFS1xPVYCnwE5J5g16s4pjnnJI5t\nMJnxYWzYuZ+Za7bVvrMxxniJWgu+iISLSOTh58BAYEE1+0UDZwEfn+yxDe2q3HSyEsK54Y3pzF67\n3dPhGGNMg3DnDD8ZmCwic4GfgM9V9UsRuU1Ebquy3zDga1XdU9ux9RV8XSVGBjP6lt7EhQdx/Rs/\nMa94h6dDMsaY067WbpmqugroWs36kce8/hfwL3eObQyaR4cyZkQfrnxlCsNf/4l3b+5Ndkq0p8My\nxpjTxufutK0qJSaUMbf0ISI4gOGvT2Pxhl2eDskYY04bny744AymNvqW3gQH+HPta9NYtmm3p0My\nxpjTwucLPkBGfDhjRvQhwE+45tVprCgt83RIxhhT76zgu2QlhDP6lj4AXPPqVIq27KnlCGOMaVqs\n4FfROimCMbf0pqJSuXrUVNZstaJvjPEeVvCP0SY5kndv6c2B8gquHjWVdTbmjjHGS1jBr0b7ZlG8\nc3Nv9hys4OpXp7Jqs7XpG2OaPiv4J9CpRTTv3tybXfsOMfAfE3ngg3mU7Njn6bCMMabOrODXIDsl\nmm/uO4vr+mTw4awS8v9eyMMfL2DTrv2eDs0YY06aFfxaJEWF8MiQThT+Lo9Lc1IZPW0tA/5WwOOf\nLWJL2QFPh2eMMW6zgu+mFjGh/PUXnfnut3lc3LUFb/xQxIC/FfB/Xy5hx16bEN0Y0/hZwT9J6fFh\nPHV5Vybcdxbndkhm5Pcr6f9/BfxjwjJ27T/k6fCMMeaEvKvg790GbszgVR9aJUbwz6u78+U9A+jX\nOoHnvl1Ovye/49FPF1qvHmNMo3Qyk5g3bvu2w6tn0zqsI5w1APz8G+Rj2zWLZOTwHBaU7GTUxFW8\nM3UNb/6wmv5tEhjeJ4NzOiTj7ycNEosxxtTEe87wg6Oh/YWklnwO718Phxq2C2V2SjT/vLo7Pzxw\nNr89ry3LN5Ux4u2ZDPhbAS8WrGCrXeA1xniY9xR8Pz84/wlWtLoJlnwObw11mngaWFJkCHed04bJ\nf8hn5HU9yIgP4+9fLaXvX7/j3vfmMGvt9sNz/RpjTIPyniYdl+K0IbTu0R8+vBVeHwjXfQCxGQ0e\nR4C/H4OymzMouzkrSnfz9pQ1fDCrhI9ml9CpRRTDuqeQ1y6RVokRiFiTjzHm9POeM/yqOg2D4R/B\nnlJ4/TzYMNej4bROiuTRodlM/Z9z+PMl2VQqPP75Ys59ZiL9/1bAQ/9dwLeLN7H3YLlH4zTGeDe3\nzvBFZDWwG6gAylW15zHb83AmLy9yrfpQVR9zbRsEPAf4A6+p6pP1EnltMvvBr76Cdy6DNwfDFW9B\n63Ma5KNPJCI4gOF9MhjeJ4OSHfsoXFpKwZLNjJtZzNtT1xAU4EeflvHkt0skr10SWQnhHo3XGONd\nTqZJJ19Vt9SwfZKqXlR1hYj4Ay8C5wHFwHQR+URVF518qHWQ1AFu/gbevQxGXwFDnodu1zTIR9cm\nJSaUa3tncG3vDA6UVzC9aDsFS0spWFrKo58u4tFPF5EZH0abiIP4p2ymd1Y8QQHe+QeZMaZhnO42\n/FxghWsyc0RkLDAUaJiCDxDVHG4cD+8Nh//eDrvWQ//fQiNqNw8O8OfMNgmc2SaBhy7qyNqteylc\nVkrBklIKl+9lwus/EREcQP82CZzdPon89kkkRAR7OmxjTBPjbsFX4GsRUeAVVR1VzT59RWQusB64\nX1UXAinAuir7FAO9TyXgOgmJhmvHwcd3wHd/hl0lcMHfwb9xXrNOjw/j+r6ZXN83k6++LSCgRUe+\nWVzKd0s28cWCjYhAt7QYzu2QzNntk2jfLNIu/BpjaiXudBEUkRRVLRGRJGACcJeqTqyyPQqoVNUy\nERkMPKeqbUTkMmCQqt7s2m840FtV76zmM0YAIwCSk5Nzxo4dW6eEysrKiIiIqH6jVpJV9A4Zaz9g\nW2w31qb/gh0x2SANc5NWXVTNR1VZs6uSuZsrmFNaQdGuSgDiQ4SuSf70bR5A6xi/Rl/8a/yOmiBv\nywe8LydvyweOzyk/P3/msddXj+VWwT/qAJFHgDJVfaqGfVYDPYE2wCOqer5r/YMAqvrXmj6jZ8+e\nOmPGjJOK67DCwkLy8vJq3mn6azDhT3CwDCKSnV49nS+HlJxG1dQDNedTums/3y0p5dslpUxevoV9\nhypo3yyS6/pkcEn3FCKCG+dfMG59R02It+UD3peTt+UDx+ckIrUW/ForgoiEA36qutv1fCDw2DH7\nNAM2qaqKSC5Od8+twA6gjYhkASXAVYDnr5r2uhm6XQvLvoL5/4EZb8K0kRCbCdmXQvZlkNzR01HW\nKikqhKty07kqN509B8r5eM563pm6hj/+dwFPfrGEYd1TuK5PBu2aRXo6VGNMI+DOKWAy8JGrmSAA\nGK2qX4rIbQCqOhK4DLhdRMqBfcBV6vzpUC4idwJf4XTLfMPVtu95gaHQ6RJn2b8TFn8GC8bB5H/A\npKchqRN0vtT5AYjN9HS0tQoPDuCa3ulcnZvG7HU7eGfKGt6bsY63p66hV2Ys1/XJYFB2M4IDGm/z\nlTHm9Kq14Lt62HStZv3IKs9fAF44wfHjgfGnEOPpFxIN3a91lrJSWPhfp/h/+5izJLaHjDMgox+k\n94XoFE9HfEIiQo/0WHqkx/LHizoybuY63p22lnvGziE+PIgreqVxTW46aXFhng7VGNPAGmcjrydF\nJEHvEc6yfQ0s/AiKJsK8/8CMN5x9YjKc4p9xhrPEtWx0bf8AceFBjBjQipvPbMmkFVt4Z+oaXvl+\nJSO/X8nZ7ZIY3jeDAW0S8bPRPI3xCVbwaxKbAWf+xlkqymHTfFjzo7Ms+xLmjnb2i0h2Cn9KT6ff\nf0QyRDRzfjyCIz3+Y+DnJ5zVNpGz2iayfsc+xvy0ljE/rePbN6eTER/Gdb0zuLxnKjFhQR6N0xhz\nelnBd5d/ALTo7ix973AmWtm8FNb+eORHYOFHxx8XGOYU/ohk12Mz53lCa0ju7Px14Ndwd9C2iAnl\ntwPbcdfZbfhiwQbembqGJ8Yv5qmvlzK0WwuG98mkc2p0g8VjjGk4VvDrSgSS2jtLz185PwD7tkPZ\nJti90bkWULbp6GXzMiiaBPt3HHmfwDBI7gTJ2dCss7MkdYTg09tnOCjAj6HdUhjaLYVF63fx9tQ1\n/Hd2Ce/PKKZbWgzX981gcOfmhATaRV5jvIUV/PoiAmFxzpLUoeZ9D+1z/jrYtAA2zoeNC2DBhzDz\nzcNv5pz5N8smfV8ErCiHFj2c9z4NOraI4q+/6MwDF7Tng5nFvDN1Dfe9P5fHP1/MiAEt+VW/LBvH\nxxgvYAXfEwJDoUU3ZzlMFXauc4r/xvnO9YIN82i5vQiK3nX2ick40qzUortzfEj9Nb9EhwbyqzOz\nuLFfJj+s2Mprk1fx5BdLeH/6Oh66uCP57ZLq7bOMMQ3PCn5jIQIx6c7SfvDPqyd98zn9W0XC+tlQ\nMst5XPTfI8fFtz7yA9BmICS0qYdQ5OfB3AqWlvLYp4u48c3pnNshiYcu6khGvA3bbExTZAW/kasI\nCIesAc5y2N5tTuE/vKyZ4twx/NX/QGoudLsaOv0CQmNO+fPz2yXRr1UCb/xQxPPfLue8ZyZyy4As\n7shvTViQ/fMxpimx/2OborA4ZzKXqhO67CyBBR/AnNHw2b3wxQPQ4SJn/P+W+eBX94uvQQF+3HZW\nK4Z1T+HJL5bwYsFKPpxVwv8M7sBFXZo3+sHajDEOuxLnLaJToN/d8OspcEsB5NwAK7+Ddy6Ff3Ry\nBovbvPSUPiI5KoR/XNmNcbf1JTYsiLvGzOaqUVNZvGFXPSVhjDmdrOB7GxFI6QGD/w6/XepM7di8\nK/z4PLyYC6+eDbPfcS4S11HPzDg+vetMnhiWzbJNu7nwn5N48MP5zC/eycmOvmqMaTjWpOPNAoKh\n41Bn2b3Jaeef864zEcyyL2HoSxASVae39vcTru2dwYWdm/PMhGWM/WkdY35aS+ukCIZ1T2FI1xY2\nXo8xjYyd4fuKyGQ44064/UcY+AQsGe+c7ZcuOaW3jQkL4rGh2Uz/33P56y86ExcWxN+/Wkr/vxVw\nxcgpjPlpLTv3HqqnJIwxp8IKvq8RcQr/DZ84d/y+erZz09cpig4L5OrcdN6/rS+Tfp/P785vx9Y9\nB3jww/n0euIbbnt7Jl8u2MiB8op6SMIYUxfWpOOrMs+EWyfC+zfAuBuhZCac+wj4B57yW6fFhXFH\nfmt+ndeKhet38eGsEj6Zu54vF24kOjSQ/s2hR59DRIWc+mcZY9xnZ/i+LKoF/PJzyL0VprwAb7na\n+uuJiJCdEs3DF3dk6oNn8+9f5dKvdTyfrTrEgL8V8OrEVew/ZGf8xjQUK/i+LiAIBv8Nho1y7uQd\ndRasnVb/H+Pvx1ltE3np2hwePSOELqkxPDF+MWc/Vcj7M9ZRUWm9e4w53azgG0fXK+HmbyAgBP41\nGKaNOqWumzXJiPLnrV/lMvqW3iRGBvP7cfMY9OxEvl640bp1GnMaWcE3RzTLhhGF0Po8+OJ38OEI\nOLjntH3cGa0S+O8d/Xj52h5UVCoj3p7JpS//yLRVW0/bZxrjy9wq+CKyWkTmi8gcEZlRzfZrRWSe\na58fRaSru8eaRiY0Bq4aDWf/0em3/8oAKJ552j5ORLigc3O+vncAf/1FZ0p27OPKUVP51b+ms6DE\nbuQypj6dTC+dfFXdcoJtRcBZqrpdRC4ARgG93TzWNDZ+fjDgd5DWGz66HV4/D876PfT/bb304qlO\ngL8fV+emc0m3FP7142peLlzBRc9PpmVCOAM7NWNQdjO6pETb/LvGnIJ66Zapqj9WeTkVSK2P9zUe\nljUAbv8Bvvg9FP4Vln/tXNxNaH3aPjI0yJ/b81pxTW46n8xbz9cLN/LapFWM/H4lzaJCGNgpmfM7\nNSM3K45Af2uRNOZkiDt/MotIEbAdUOAVVR1Vw773A+1V9eaTOVZERgAjAJKTk3PGjh17kqk4ysrK\niIg4vdMDNqTGkk9i6Q+0XfYyfpUHWNnqV6xvMajOk7OfbE57DilzSsuZVVrB/M0VHKyE8EDolhhA\nj2R/shP8Cfb33Jl/Y/mO6u5UzCoAABpuSURBVJO35eRt+cDxOeXn589U1Z41HqSqtS5AiusxCZgL\nDDjBfvnAYiD+ZI+tuuTk5GhdFRQU1PnYxqhR5bNzvepbw1T/FKX69i9Ud22o09ucSk57D5Trlws2\n6L3vzdYuj3ylGX/4TNv/8Qu9e8ws/WH5Zq2oqKzze9dVo/qO6om35eRt+agenxMwQ2uprW416ahq\nieuxVEQ+AnKBiVX3EZEuwGvABaq69WSONU1EVHO47gOY/hp8/RC81AcuehY6XdJgIYQG+XN+p2ac\n36kZhyoq+aloG+Pnb+DTuev5eM560uPCuDwnlct6ptI8OrTB4jKmKai1EVREwkUk8vBzYCCw4Jh9\n0oEPgeGquuxkjjVNjAjk3gK3TYLYLPjPDfDhrbB/Z4OHEujvR7/WCTwxrDM//e+5PHdVN1JjQ3l6\nwjL6Pfkdv3zzJ8bP38DB8soGj82YxsidM/xk4CPXrEYBwGhV/VJEbgNQ1ZHAw0A88JJrv3J12pKq\nPbbeszANL6EN3PQ1THwKJv4dir6HfvdAjxsgqOGHRQ4J9GdotxSGdkth7da9/GfmOv4zo5hfvzuL\nuPAghnVP4cpeabRNjmzw2IxpLGot+Kq6CuhazfqRVZ7fDNzs7rHGS/gHQv6DzuTpEx6CLx9wfgD6\n/hp63Qwh0R4JKz0+jN8ObMdvzm3LxOWbeX/6Ot6asprXJxfRNTWai7q0YHCX5qTEWJOP8S02WqY5\ndak5cON4ZzL1SU/Dt4/B5Oecpp8+v4bweI+E5e8n5LdLIr9dElvLDvDR7BI+ml3CE+MX88T4xXRL\ni+GiLs25oLMVf+MbrOCb+pPRFzLGwYa5TuGf9DRMfQlyfgln3OWMzukh8RHB3Ny/JTf3b8nqLXv4\nfP4Gxs/fwOOfL+bxzxfTPT2GCztb8TfezQq+qX/Nuzpz6W5eCpOfhWmvOD17ul3jtPN7WGZCOHfk\nt+aO/NY1Fv/Lc9KIDrMx+433sFsVzemT2A6GvQx3z4buw2HOGHg+h7ZLX4I9jWOAtMPF//O7+1N4\nfx6/O78dB8srefzzxZz3j++ZsKj+5gcwxtOs4JvTLzYDLnoGfjMPcm+l+YYJ8HwP+OlVqCj3dHQ/\nq1r8P73zTOIjgrnlrRncPWY22/Yc9HR4xpwyK/im4UQ2gwueZHqv55xmn/H3w6g8WPNjrYc2tM6p\n0XxyZz/uO68tXyzYwHnPfM9n89bb6J2mSbOCbxrc3vB0uP5jp51//w548wIYdxPsWu/p0I4S6O/H\n3ee04bO7+pMSG8qdo2dz+zuzKN2939OhGVMnVvCNZ4hAx6Fwx08w4Pew+FN4vidMegbKD3g6uqO0\naxbJh7efwQMXtOe7paUM/MdEPppdbGf7psmxgm88KygMzv5fuGMatMyDbx+Fl/rCsq89HdlRAvz9\nuO2sVnxxT39aJUZw73tzuenfM9iwc5+nQzPGbVbwTeMQlwVXj3YGZxOB0ZfD28NgwQendZrFk9Uq\nMYL3b+3Lwxd15MeVWxj4zES+Xn2Ikh1W+E3jZ/3wTePS+ly4fQpMexmmvATjfgWBYdB2EGRf6mwP\nDPFoiP5+wq/OzOKcDkk88MF8Ri/ZyugnvyMzPox+rRPo1zqBvi3jiQ0P8micxhzLCr5pfAKCnBu0\n+t4Ja6c4Z/mLPoaFH0JwFLS/EDr9Alrln7YpF92RER/O6Ft6885nBRyMzeLHFVv4eM563p221rlE\n0TyKfq0TOKNVPLlZcYQF2f9uxrPsX6BpvPz8IfNMZ7nANSLngg9hyacwdwyExkKHi50z/4x+Hin+\nIkJapB95Z2Zx05lZHKqoZF7xTn5YsYUfVmzhXz+sZtTEVQT6C93TY7m+bwYXdm6O1HG2MGNOhRV8\n0zT4B0Drc5yl/BlY+Z1T/Bd8CLPecpp90nIh40zI7AcpORAQ3OBhBvr7kZMRS05GLHef04Z9ByuY\nvnobP6zcwoRFm7hz9Gz+nbmahy/qROdUz4wmanyXFXzT9AQEQ7sLnOXQPljxDRRNhNU/QMHjzj7+\nwZDayyn+Gf2c5x4Ypz80yJ8BbRMZ0DaR35/fnvdnrOOpr5Yy5MXJXNojld+f346kKM9ekzC+wwq+\nadoCQ51mnQ4XO6/3bnPa/Vf/AGt+cCZn0f8Dv0BI6QEt86HHcIhObfBQ/f2Eq3PTubBLc178bgVv\n/FDE+PkbuCO/NTedmUVIoL/b73WoopK563Ywe+0O8tol0sYmdjFusIJvvEtYnHNRt/2Fzuv9O2Hd\nT7B6susH4G/O0m4w5I6ArAFON9AGFBUSyIODO3B1bjp/Gb+Yv3+1lNHT1vI/gzswuHOzE7bvr9m6\nh4nLtzBp2WamrNzK7gPOOERPT1jKY0OzuTwn1a4NmBpZwTfeLSQa2pznLADb18CMN5x2/yWfQUI7\nZ6KWLldCSFSDhpaZEM6o63vy44otPPbZIu4YPYvczDgevrgj2SnR7Nx3iCkrtzJp+WYmLd/C2m17\nAUiJCeWiri0Y0CaBNsmRPPzxAn4/bh5TV27lz5dkEx5s/1ub6tm/DONbYjPgvEch70Gnm+dPo5xB\n3L55BLpe7RT/xHYNGtIZrRP4/O7+vDd9HU9/vZSLX5hM+2ZRLNu0m4pKJTzIn76tEri5fxb92ySS\nGR921Jn82zf15oXvVvDst8uYW7yDF6/tQftmDfvjZZoGtwq+iKwGdgMVHJmgvOp2AZ4DBgN7gV+q\n6izXthuAP7p2fVxV/10/oRtzCgJDnAlZul0DxTNh+qsw69/OY9YA6HWL0+zj3zDnRP5+wjW907mo\nq9O+P2fdDu7Ia0X/tol0S4sh0P/EN8X7+wn3nNuGXlmx3DN2DkNf+IFHh3Tiyl5p1sRjjnIy/5rz\nVXXLCbZdALRxLb2Bl4HeIhIH/AnoCSgwU0Q+UdXtpxCzMfUrNcdZBj7uNPXMeAPeHw7hSdD1Suh2\nHSS1b5BQDrfv18UZrRIYf3d/7nt/Dg98OJ8pq7byxLDORFgTj3Gpr7F0hgJvqWMqECMizYHzgQmq\nus1V5CcAg+rpM42pX+EJ0P8+uHsOXDXG6co59WV4qTe8ejZMfx327fB0lDVKjAzm3zfmcv/Atnw6\ndz1Dnp/MovW7PB2WaSTEnSFeRaQI2I5zlv6Kqo46ZvtnwJOqOtn1+lvgD0AeEKKqj7vWPwTsU9Wn\nqvmMEcAIgOTk5JyxY8fWKaGysjIiIiLqdGxj5G35QNPKKfDgDpI3fU+zjd8SsWcNlRLI5sQ+bGx2\nDttju4D415yPVhB0cAch+7cQdHA7u6LacjA4rkFiX7KtgpFzD1B2SLm2fRB5aQFuN/E0pe/IHd6W\nDxyfU35+/sxjm9uP5e7femeqaomIJAETRGSJqk48hViP4/oRGQXQs2dPzcvLq9P7FBYWUtdjGyNv\nyweaYk6XgCpsmIPf7HdJnv8fkksnQVQKdL2aOYdi6JaQ4kzgsms97Co+8nz3RtCKI2/lF+DMA5A7\nAtJ6n9YuoXnA5QMPcO/7c/n3os1slFjuPa+tWxd0m953VDNvywfqlpNbBV9VS1yPpSLyEZALVC34\nJUBaldeprnUlOP/uqq4vPKkIjWkMRKBFd2cZ+DgsHQ9z3oXJz9BNK2Gua7/AMOeHIKoFZJ3lPEa1\ncNaFxsCiT2D2O86AcM26OIW/82XODWSnQXxEMP/6ZS9GTlzJC9+t4KuFm8hrl8itA1rRp2WcXdT1\nMbUWfBEJB/xUdbfr+UDgsWN2+wS4U0TG4ly03amqG0TkK+AvIhLr2m8g8GD9hW+MBwSGQPYvnGXX\neuZ+M5au/c53CntITM1n7el9nAlf5r3vdAn95E6Y8BD0uB563Qwx6fUerp+f8Ou81lyTm847U9fw\nrx9Xc/WrU+mSGs2tA1oxKLsZ/n5W+H2BO2f4ycBHrjOBAGC0qn4pIrcBqOpIYDxOl8wVON0yb3Rt\n2yYifwamu97rMVXdVr8pGONBUS3YHtcDkju5f0xQOPS8EXJ+6dz9O+0V+PEF+PF5aHsB9B7h/HVQ\nz2ffMWFB3Hl2G27u35IPZhXz2qQi7hg9i/S4MG7pn8VlOWmEBrk/vINpemot+Kq6CuhazfqRVZ4r\ncMcJjn8DeOMUYjTGO4kcGf55Z7HTHXTmv2Dp504TUHxr50ax2EyIyYDYLOd1WPwp/RiEBPpzbe8M\nruqVzoRFGxn5/Soe+ngh//hmOdf3zeD6vpn1laFpZKyDrjGNQXQqnPOwM6H7wo+cEUB3rIGlX8Ce\nzUfvGxTh+gHIdJaUHs5fBBGJJ/WR/n7CoOzmnN+pGdNXb+eV71fy7DfLeblwJTFBStSs7wn09yMw\nwI9APyHQ348AfyHI3+/n5+lxYdw6oBXRYZ6biMa4zwq+MY1JYAh0u9pZDju4xxkDaMca2L7aeb59\nNWwvglUFMPVFZ7/kbGci+KyzIOMMCHavG6KIkJsVR25WHMs37ebdaWtZUrSO2PgIDlVUcqhCOVRR\nSXmFsu9Qxc/PD1ZUMn7+BsZOX8cDF7Tnsh6p+Nm1gEbNCr4xjV1QOCR3dJZjVZTDhrlO4S/63rkQ\nPOUFp/tnai60PMv5EUjJcWtGsDbJkTwypBOFhZvJy8updf+F63fy8McL+f24eYz9aS1/viSbTi1s\nYpfGygq+MU2Zf8CRoSEG3O9MCLN2KqwqdH4ACp+Ewr86zUDpfZzC36KH0wwUkXTKH9+pRTT/ubUv\nH8wq5skvlnDx85MZ3ieD+wa2IzrUmnkaGyv4xniTwFBncvdW+c7rvdtg9SRY9b0zMczK70ArnW3R\nac59BSk5zg9A8251GiLaz0+4vGcaAzs245kJS3l76ho+n7+BBy7owKU9UqyvfyNiBd8YbxYW59zZ\n23Go8/pAGWycByUzoWQWrJ8Fiz9x7SyQ0AZa9KDl9oMg053mpOAI5zEosspr1xIS7Vx3AKLDAnl0\naDaX90zj4Y8XcP9/5vLe9LU8OiSbji1suObGwAq+Mb4kOMK5oJtxxpF1e7bC+tlO8S+ZBUUTSdmz\nBdZ96N57RraAuCxXt9FMsuOyGHdxJp+sS+exbzZw0fOTuL5vJtf0Tqd1YoRd2PUgK/jG+LrweGhz\nrrO4TCosJK9/PzhY5vQSOuB6PLj76Od7tjq9hbavdrqSlm0EnGF4LwGGBkexIbgZs6fH8v601swN\n6EJIale6ZcTRPT2GbmmxxIUHeSRtX2QF3xhTPf9ACI11Fncd3OvqMroathch24posb2IpNLlXLhr\nGvAuu9ZH8uO6DnxX0YknKjtSEdua7q4fgO5psbRvHlnjhC+m7qzgG2PqT1BYtV1IA8AZPbRoElFF\nExm4qpBBu34CYPuBeKYs6UTBvPa8UtGJvWEtuK6Pc8dvYmRww+fgxazgG2MaRlQLZwaxrlfip+o0\nBRVNJLZoIhcUTWSwToRA2CaJLJqczNeTmxPVoj09evQkpVVn5+7iBppy0lvZfz1jTMMTgbiWzpLz\nS0QVShdD0ffElcyi56bl5GydQujGCc7QjEClBCBxWUh8a4hv5Yw1lHEGJLQ9rfMKeBMr+MYYzxM5\nqikoBECV7Vs2MmHyDyyaP4vEg+voumsLnQ+tJGpVAVK+3zk2JgPang9tzncGonN1EzXHs4JvjGmc\nRIhNbM4Vwy5j/0XD+HhOCY9MKmJFaRktooK4q08g+YELSNrwPX6z3naGlQgMc8YSajsQ2gx0BqWr\njSrs2+4MUrd3GzTr7PY4RE2NFXxjTKMXEujPlb3SuTwnje+XbWbUxFU8WLgVyMLfryXt4m/hwsjl\n9KucTdviHwlb9oVzYHI2tBlI4jY/+Gk5lG1yLaVHlj2lUHHwyIcFR0G3a5wJaRLaeCTf08UKvjGm\nyfDzE/LbJ5HfPomVm8tYULKT5ZvKWLZpN//Z1JGntmWiegmtpYTzAuYwaMs8sjc9SycqYRGo+CHh\nic44QuFJkNjeeR6R7DwGhjrDU09/HaaNdAae63ULtB3kFReMm34Gxhif1CoxglaJRze97D9UwYpS\n5wdg2aaz+Oem3ZRs3Ag7i9mi0WwjkpTQcLpExtA5NZouKdFkp0YTFVJloLf2F8L5f4GZ/4aZb8J7\n1zrjDvW8EXrcAOEJNQemCrs3wOYlULoEti6H8gPOetR51Mojz6s+hkTDxc/V83+pI6zgG2O8Rkig\nP9kp0WSnHD1E8+cTCojN6sy8kp3ML97JvJIdfD5/w8/bWyaEOz8AqTFc2SuNiIgkOOt3cOa9zoT1\n01+Fbx9zRh/tNMw560/t6dxbsHnJkaV0CWxeCgd2VgkqBoIjAQHB9SjHP4ofhNXyY3KKrOAbY7xe\neKBwRusEzmh9pKBu33OQ+SU7mV+yk3nFO5hetI2P56xnysotvHp9T2eUT/8A6DjEWUqXwPTXYO5Y\nmPeec4H40N4jHxIWD4kdoMvlTlPR4eUkZyI7ndwu+CLiD8wASlT1omO2/QNwjcdKGJCkqjGubRXA\nfNe2tao65JSjNsaYUxQbHsSAtokMaHukIL8xuYjHPlvEO1PXMPzYuX2T2sOFT8G5f3KK/pblzkXd\nxPaQ1KH2pp5G4GTO8O8BFgPHjXOqqvcefi4idwHdq2zep6rd6hyhMcY0kBv7ZTJx+WYe/3wxuVnx\ntGsWefxOwZGQe0vDB1cP3BqhSERSgQuB19zY/WpgzKkEZYwxniAiPHV5VyJDArl7zGz2H6rwdEj1\nSlS19p1ExgF/BSKB+49t0qmyXwYwFUhV1QrXunJgDlAOPKmq/z3BsSOAEQDJyck5Y8eOPflsgLKy\nMiIivOemCW/LB7wvJ2/LB7wvp5PNZ/7mcp6eeYBz0gMY3rFxDuB2bE75+fkzVbVnjQepao0LcBHw\nkut5HvBZDfv+AXj+mHUprseWwGqgVW2fmZOTo3VVUFBQ52MbI2/LR9X7cvK2fFS9L6e65PPnTxdq\nxh8+068Xbqz/gOrBsTkBM7SW2upOk04/YIiIrAbGAmeLyDsn2PcqjmnOUdUS1+MqoJCj2/eNMaZR\n+t2gdnRqEcXvx81l0679ng6nXtRa8FX1QVVNVdVMnIL+naped+x+ItIeiAWmVFkXKyLBrucJOD8e\ni+opdmOMOW2CA/z559Xd2X+okvven0NlZe3N341dnaeVEZHHRKRqF8urgLGuPy0O6wDMEJG5QAFO\nG74VfGNMk9AqMYJHhnTkhxVbGTVplafDOWUndeOVqhbiNMugqg8fs+2Ravb/Eehc5+iMMcbDruiZ\nxsRlW3jqq6X0bRlP17QYT4dUZzZxpDHG1EBE+MuwziRHhXD32NmUHSj3dEh1ZgXfGGNqER0WyD+u\n7Ma6bXv508cLPR1OnVnBN8YYN+RmxXHn2W34YFYxH88pqbf3LTtQzsrNZfy4cgvfLt5Ub+9bHRs8\nzRhj3HT32a35YcUW/vjRAnqkx5IWF/bztspKZX95BfsOVrDvUAX7D1Ww72Alew6Ws6XsAJt2HaB0\n13427drPpl0H2LR7P5t27mfPwSN388aFBzHrofNOW/xW8I0xxk0B/n48e2U3Bv9zEhe/MJnQQH/2\nHXKK/IHyylqPDwrwIzkqmOTIEDo0iyKvbZLzOiqEJNfjaY3/tL67McZ4mbS4MEYN78l709cSHOBP\nSKAfIUH+hAa6liB/QgKPfp0QEUxyVDDRoYHOsMseYgXfGGNOUt9W8fRtFe/pME6aXbQ1xhgfYQXf\nGGN8hBV8Y4zxEVbwjTHGR1jBN8YYH2EF3xhjfIQVfGOM8RFW8I0xxke4NYl5QxORzcCaOh6eAGyp\nx3A8zdvyAe/LydvyAe/LydvygeNzylDVxJoOaJQF/1SIyAytbeb2JsTb8gHvy8nb8gHvy8nb8oG6\n5WRNOsYY4yOs4BtjjI/wxoI/ytMB1DNvywe8Lydvywe8LydvywfqkJPXteEbY4ypnjee4RtjjKmG\nFXxjjPERXlPwRWSQiCwVkRUi8oCn46kPIrJaROaLyBwRmeHpeOpCRN4QkVIRWVBlXZyITBCR5a7H\nWE/GeDJOkM8jIlLi+p7miMhgT8Z4MkQkTUQKRGSRiCwUkXtc65vyd3SinJrk9yQiISLyk4jMdeXz\nqGt9lohMc9W890QkqNb38oY2fBHxB5YB5wHFwHTgalVd5NHATpGIrAZ6qmqTvWFERAYAZcBbqprt\nWvc3YJuqPun6cY5V1T94Mk53nSCfR4AyVX3Kk7HVhYg0B5qr6iwRiQRmApcAv6TpfkcnyukKmuD3\nJM6ciOGqWiYigcBk4B7gPuBDVR0rIiOBuar6ck3v5S1n+LnAClVdpaoHgbHAUA/HZABVnQhsO2b1\nUODfruf/xvmfsUk4QT5NlqpuUNVZrue7gcVACk37OzpRTk2SOspcLwNdiwJnA+Nc6936jryl4KcA\n66q8LqYJf8FVKPC1iMwUkRGeDqYeJavqBtfzjUCyJ4OpJ3eKyDxXk0+Taf6oSkQyge7ANLzkOzom\nJ2ii35OI+IvIHKAUmACsBHaoarlrF7dqnrcUfG91pqr2AC4A7nA1J3gVddoUm3q74stAK6AbsAF4\n2rPhnDwRiQA+AH6jqruqbmuq31E1OTXZ70lVK1S1G5CK06LRvi7v4y0FvwRIq/I61bWuSVPVEtdj\nKfARzhftDTa52lkPt7eWejieU6Kqm1z/Q1YCr9LEvidXu/AHwLuq+qFrdZP+jqrLqal/TwCqugMo\nAPoCMSIS4NrkVs3zloI/HWjjumodBFwFfOLhmE6JiIS7LjghIuHAQGBBzUc1GZ8AN7ie3wB87MFY\nTtnhwugyjCb0PbkuCL4OLFbVZ6psarLf0Ylyaqrfk4gkikiM63koTueUxTiF/zLXbm59R17RSwfA\n1cXqWcAfeENVn/BwSKdERFrinNUDBACjm2JOIjIGyMMZynUT8Cfgv8D7QDrOMNhXqGqTuBB6gnzy\ncJoJFFgN3Fql/btRE5EzgUnAfKDStfp/cNq8m+p3dKKcrqYJfk8i0gXnoqw/zkn6+6r6mKtGjAXi\ngNnAdap6oMb38paCb4wxpmbe0qRjjDGmFlbwjTHGR1jBN8YYH2EF3xhjfIQVfGOM8RFW8I0xxkdY\nwTfGGB/x/yaOb6fELk2kAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxDV_RX866Hp",
        "colab_type": "code",
        "outputId": "6448b84f-af1d-4bc1-e7c7-7dc8cebaaae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq2seq.load_state_dict(torch.load('./saved_models/seq2seq.pt').get('model'))\n",
        "test_loss = valid_step(seq2seq, criterion, test_iterator,\n",
        "                       sos_index=EN.vocab.stoi[EN.init_token],\n",
        "                       epoch_text='Test loss => ')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss => Valid Loss: 4.790: 100%|██████████| 5/5 [00:00<00:00, 12.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8tYcPCLgz5",
        "colab_type": "text"
      },
      "source": [
        "# Inference & BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCe-iET5mwf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "1d3ff501-f297-478b-f0a2-32e5957f637b"
      },
      "source": [
        "help(SeqToSeqNet.inference)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function inference in module __main__:\n",
            "\n",
            "inference(self, in_, seq_len, sos_index, eos_index, max_len, sample=True)\n",
            "    Inferring a sentence or a batch of sentences.\n",
            "    inputs\n",
            "        in_: (seq_len, batch_size)\n",
            "        seq_len: (batch_size)\n",
            "        sos_index: int\n",
            "        eos_index: int\n",
            "        max_len: int\n",
            "        sample: bool\n",
            "    \n",
            "    outputs\n",
            "        out: list(seq_len*, batch_size)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRIlUJjLeDj",
        "colab_type": "code",
        "outputId": "97427a7c-8638-45cf-b7fd-a4a1f63b3cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "references = []\n",
        "targets_with_sample = []\n",
        "targets_without_sample  = []\n",
        "seq2seq.eval()\n",
        "with torch.no_grad():\n",
        "    for i, example in enumerate(test_data.examples):\n",
        "        in_ = torch.tensor([FR.vocab.stoi[token]\n",
        "                            for token in example.src],\n",
        "                        dtype=torch.int64, device=device).unsqueeze(1)\n",
        "        if in_.size(0) == 0:\n",
        "            print(f'skipped example {i}!')\n",
        "            continue\n",
        "        seq_len = torch.tensor([in_.size(0)], dtype=torch.int64, device=device)\n",
        "        with_ = seq2seq.inference(in_, seq_len, EN.vocab.stoi[EN.init_token],\n",
        "                                  EN.vocab.stoi[EN.eos_token], MAX_LEN)\n",
        "        without = seq2seq.inference(in_, seq_len,  EN.vocab.stoi[EN.init_token],\n",
        "                                    EN.vocab.stoi[EN.eos_token], MAX_LEN, False)\n",
        "        targets_with_sample.append([EN.vocab.itos[int(idx)] for idx in with_[0]])\n",
        "        targets_without_sample.append([EN.vocab.itos[int(idx)] for idx in without[0]])\n",
        "        references.append([example.dest])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skipped example 516!\n",
            "CPU times: user 20.9 s, sys: 878 ms, total: 21.8 s\n",
            "Wall time: 21.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTolzzQaoAGd",
        "colab_type": "code",
        "outputId": "aab5bd3b-b676-4d19-a4e5-e3fd153d5eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(f'BLEU score with sampling: {bleu_score(targets_with_sample, references)}')\n",
        "print(f'BLEU score without sampling: {bleu_score(targets_without_sample, references)}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score with sampling: 0.0027251001447439194\n",
            "BLEU score without sampling: 0.006780573234594942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV-mzrtbp_mp",
        "colab_type": "code",
        "outputId": "fbbb9970-0adb-4d4f-b126-f16868147421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "idx = 1\n",
        "print(' '.join(references[idx][0]))\n",
        "print('================================')\n",
        "print(' '.join(targets_with_sample[idx]))\n",
        "print('================================')\n",
        "print(' '.join(targets_without_sample[idx]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "despite the fact that we do not consider that the european parliament should propose all these amendments to the treaty , we have elected to adopt positions on the individual points , as will be evident from our voting .\n",
            "================================\n",
            "the have last , if the is seem to not look regrettable and operates to led a good rapporteurs and the power to be place alleged <unk> development as europe . council to <unk> education .\n",
            "================================\n",
            "the , the the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hzyFn-Vqn3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}