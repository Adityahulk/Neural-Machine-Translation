{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 27 02:05:16 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 27%   40C    P8     6W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "import torch_utils\n",
    "from optim_utils import LRFinder\n",
    "from beam_utils import Node, find_best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:02<00:00, 71670.51it/s]\n",
      "100%|██████████| 200000/200000 [00:02<00:00, 95056.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after sampling: 200,000\n",
      "Example:\n",
      "\tFR => par écrit. - (EN) Les conservateurs saluent l'objectif général visé par l'amélioration des droits des passagers et de l'accès pour les personnes handicapées et par la création de règles équitables pour les utilisateurs de bus internationaux, c'est pourquoi j'ai voté en faveur du rapport.\n",
      "\tEN => in writing. - Conservatives welcome the overall aim of improving passenger rights, access for the disabled and creating a level playing field for international bus users, and for this reason voted in favour of the report.\n",
      "CPU times: user 6.62 s, sys: 841 ms, total: 7.46 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_fr = utils.read_file('./data/europarl-v7.fr-en.fr')\n",
    "data_en = utils.read_file('./data/europarl-v7.fr-en.en')\n",
    "\n",
    "assert len(data_fr) == len(data_en)\n",
    "\n",
    "indexes = np.random.choice(range(len(data_fr)), size=200_000, replace=False)\n",
    "\n",
    "pairs = [*zip(\n",
    "    utils.clean_lines([data_fr[index] for index in indexes]),\n",
    "    utils.clean_lines([data_en[index] for index in indexes])\n",
    ")]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_fr = [*map(lambda pair: len(pair['fr'].split()), pairs)]\n",
    "len_en = [*map(lambda pair: len(pair['en'].split()), pairs)]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist([*filter(lambda x: x < 50, len_fr)])\n",
    "axes[0].grid(True)\n",
    "axes[1].hist([*filter(lambda x: x < 50, len_en)])\n",
    "axes[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after filtering: 89,752\n",
      "CPU times: user 558 ms, sys: 2.99 ms, total: 561 ms\n",
      "Wall time: 560 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MIN_LENGTH, MAX_LENGTH = 10, 25\n",
    "pairs = [*filter(lambda pair: MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH and MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH, pairs)]\n",
    "print(f'Number of examples after filtering: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89752/89752 [00:26<00:00, 3358.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 89,752\n",
      "CPU times: user 42.3 s, sys: 411 ms, total: 42.7 s\n",
      "Wall time: 42.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FR = Field(lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True)\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en',\n",
    "           include_lengths=True)\n",
    "\n",
    "examples = [Example.fromdict(\n",
    "    data=pair,\n",
    "    fields={\n",
    "        'fr': ('src', FR),\n",
    "        'en': ('dest', EN)\n",
    "    }\n",
    ") for pair in tqdm.tqdm(pairs)]\n",
    "print(f'Number of examples: {len(examples):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 80,777\n",
      "valid set size: 4,487\n",
      "test set size: 4,488\n",
      "{'src': ['par', 'ailleurs', ',', 'de', 'nombreux', 'experts', 'militaires', 'soulignent', 'le', 'danger', 'd’', 'une', 'intervention', 'en', 'l’', 'absence', 'd’', 'un', 'mandat', 'précis', 'et', 'sans', 'équivoque', '.'], 'dest': ['furthermore', ',', 'many', 'military', 'experts', 'point', 'to', 'the', 'dangers', 'of', 'intervening', 'without', 'a', 'mandate', 'that', 'has', 'been', 'accurately', 'and', 'properly', 'drawn', 'up', '.']}\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
    "train_data, valid_data, test_data = data.split(split_ratio=[0.9, 0.05, 0.05])\n",
    "print(f'train set size: {len(train_data.examples):,}')\n",
    "print(f'valid set size: {len(valid_data.examples):,}')\n",
    "print(f'test set size: {len(test_data.examples):,}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 12,037\n",
      "Length of EN vocabulary: 9,417\n",
      "CPU times: user 1.18 s, sys: 0 ns, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MIN_COUNT = 5\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab):,}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## LSTM Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "    \n",
    "    def forward(self, input_sequences, sequence_lengths):\n",
    "        \"\"\"\n",
    "        Arg(s):\n",
    "            input_sequences (Tensor[seq_len, batch_size])\n",
    "            sequence_lengths (Tensor[batch_size,])\n",
    "            \n",
    "        Return(s):\n",
    "            outputs (Tensor[seq_len, batch_size, 2 * hidden_size])\n",
    "            hn (Tensor[n_layers * 2, batch_size, hidden_size])\n",
    "            cn (Tensor[n_layers * 2, batch_size, hidden_size])\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_sequences)\n",
    "        embedded = F.dropout(embedded, p=self.dropout)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths)\n",
    "        outputs, (hn, cn) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return outputs, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.51 s, sys: 126 ms, total: 6.63 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def test_encoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.35,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        outputs, hn, cn = encoder(\n",
    "            input_sequences=data.src[0],\n",
    "            sequence_lengths=data.src[1]\n",
    "        )\n",
    "        seq_len = data.src[0].size(0)\n",
    "        assert outputs.size() == torch.Size([seq_len, batch_size, 2 * 256]), outputs.size()\n",
    "        assert hn.size() == torch.Size([4 * 2, batch_size, 256]), hn.size()\n",
    "        assert cn.size() == torch.Size([4 * 2, batch_size, 256]), cn.size()\n",
    "        break\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luong Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, method):\n",
    "        if method not in ['dot', 'general', 'concat']:\n",
    "            raise NotImplemented(f'The {method} attention is not defined!')\n",
    "        \n",
    "        super(LuongAttnLayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.method = method\n",
    "        if method == 'general':\n",
    "            self.W = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        if method == 'concat':\n",
    "            self.W = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "            self.V = nn.Linear(hidden_size, 1, bias=False)\n",
    "            \n",
    "    def forward(self, h_state, enc_outputs, mask):\n",
    "        \"\"\"\n",
    "        :args\n",
    "            h_state (Tensor[n_layers, batch_size, hidden_size])\n",
    "            enc_outputs (Tensor[seq_len, batch_size, hidden_size])\n",
    "            mask (Tensor[seq_len, batch_size])\n",
    "\n",
    "        :return\n",
    "            attn_weights (Tensor[seq_len, batch_size, 1])\n",
    "        \"\"\"\n",
    "        if h_state.shape[0] > 1:\n",
    "            h_state = h_state.sum(dim=0) # [batch_size, hidden_size]\n",
    "            h_state = h_state.unsqueeze(0) # [1, batch_size, hidden_size]\n",
    "\n",
    "        # Calculating the alignment scores\n",
    "        if self.method == 'dot':\n",
    "            scores = torch.bmm(\n",
    "                enc_outputs.permute(1, 0, 2), # [batch_size, seq_len, hidden_size]\n",
    "                h_state.permute(1, 2, 0) # [batch_size, hidden_size, 1]\n",
    "            ) # [batch_size, seq_len, 1]\n",
    "            scores = scores.transpose(0, 1) # [seq_len, batch_size, 1]\n",
    "        elif self.method == 'general':\n",
    "            h_state = h_state.transpose(0, 1) # [batch_size, 1, hidden_size]\n",
    "            x = self.W(h_state) # [batch_size, 1, hidden_size]\n",
    "            scores = torch.bmm(\n",
    "                enc_outputs.permute(1, 0, 2), # [batch_size, seq_len, hidden_size]\n",
    "                x.permute(0, 2, 1), # [batch_size, hidden_size, 1]\n",
    "            ) # [batch_size, seq_len, 1]\n",
    "            scores = scores.transpose(0, 1) # [seq_len, batch_size, 1]\n",
    "        elif self.method == 'concat':\n",
    "            scores = self.V(\n",
    "                torch.tanh(self.W(\n",
    "                    enc_outputs + h_state # [seq_len, batch_size, hidden_size]\n",
    "                ))\n",
    "            ) # [seq_len, batch_size, 1]\n",
    "        else:\n",
    "            raise NotImplementedError(f'{method} not implemented!')\n",
    "            \n",
    "        # Apply mask to ignore <pad> tokens\n",
    "#         mask = mask.unsqueeze(2) # [seq_len, batch_size, 1]\n",
    "#         scores = scores * mask # scores.masked_fill(mask == 0, 1e-10)\n",
    "\n",
    "        # Calculating the attention weights by softmaxing the alignment scores\n",
    "        attn_weights = F.softmax(scores, dim=1) # [seq_len, batch_size, 1]\n",
    "\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 275 ms, sys: 0 ns, total: 275 ms\n",
      "Wall time: 64.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def test_luong_attn():\n",
    "    for method in ['dot', 'general', 'concat']:\n",
    "        attention = LuongAttnLayer(hidden_size=256, method=method)\n",
    "        n_layers, batch_size, hidden_size, seq_len = 2, 128, 256, 30\n",
    "        h_state = torch.rand((n_layers, batch_size, hidden_size))\n",
    "        enc_outputs = torch.rand((seq_len, batch_size, hidden_size))\n",
    "        mask = torch.randint(low=0, high=2, size=(seq_len, batch_size))\n",
    "        attn_weights = attention(h_state=h_state, enc_outputs=enc_outputs, mask=mask)\n",
    "        assert attn_weights.size() == torch.Size([seq_len, batch_size, 1]), attn_weights.size()\n",
    "    \n",
    "test_luong_attn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout,\n",
    "        attention\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "            \n",
    "    def forward(self, input_word_index, h_state, c_state, enc_outputs, mask):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_word_index (Tensor[batch_size,])\n",
    "            h_state (Tensor[num_layers, batch_size, hidden_size])\n",
    "            c_state (Tensor[num_layers, batch_size, hidden_size])\n",
    "            enc_outputs (Tensor[seq_len, batch_size, hidden_size])\n",
    "            mask (Tensor[seq_len, batch_size])\n",
    "            \n",
    "        :return\n",
    "            logit (Tensor[batch_size, vocab_size])\n",
    "            h_state (Tensor[num_layers, batch_size, hidden_size])\n",
    "            c_state (Tensor[num_layers, batch_size, hidden_size])\n",
    "            attn_weights (Tensor[batch_size, seq_len])\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_word_index.unsqueeze(0)) # [seq_len=1, batch_size, embedding_size]\n",
    "        embedded = F.dropout(embedded, p=self.dropout)\n",
    "        outputs, (h_state, c_state) = self.lstm(embedded, (h_state, c_state))\n",
    "        # outputs: [seq_len=1, batch_size, hidden_size]\n",
    "        # h_state: [n_layers, batch_size, hidden_size]\n",
    "        # c_state: [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # Compute Attention Weights\n",
    "        attn_weights = self.attention(h_state=outputs,\n",
    "                                      enc_outputs=enc_outputs,\n",
    "                                      mask=mask) # [seq_len, batch_size, 1]\n",
    "        \n",
    "        # Compute Context Vector\n",
    "        context_vector = torch.bmm(\n",
    "            enc_outputs.permute(1, 2, 0), # [batch_size, hidden_size, seq_len]\n",
    "            attn_weights.permute(1, 0, 2), # [batch_size, seq_len, 1]\n",
    "        ).permute(2, 0, 1) # [1, batch_size, hidden_size]\n",
    "        \n",
    "        # New input: concatenate context_vector with hidden_states\n",
    "        new_input = torch.cat((context_vector, outputs), dim=2) # [1, batch_size, hidden_size * 2]\n",
    "        \n",
    "        # Get logit\n",
    "        x = self.fc1(new_input.squeeze(0)) # [batch_size, hidden_size]\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        logit = self.fc2(x) # [batch_size, vocab_size]\n",
    "        \n",
    "        return logit, h_state, c_state, attn_weights.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeqLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, pad_index, device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and Decoder must have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            'Encoder and Decoder must have the same number of reccurrent hidden units'\n",
    "        \n",
    "        super(SeqToSeqLSTM, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_index = pad_index\n",
    "        self.init_h0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers) \n",
    "        self.init_c0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers)\n",
    "        self.fc = nn.Linear(2 * encoder.hidden_size, encoder.hidden_size)\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src_sequences):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            \n",
    "        :return\n",
    "            mask: Tensor[seq_len, batch_size]\n",
    "        \"\"\"\n",
    "        mask = src_sequences != self.pad_index\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src_sequences, src_lengths, dest_sequences, dest_lengths, tf_ratio):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            src_lengths: Tensor[batch_size,]\n",
    "            dest_sequences: Tensor[seq_len, batch_size]\n",
    "            dest_lengths: Tensor[batch_size,]\n",
    "            tf_ratio: float\n",
    "            \n",
    "        :return\n",
    "            logits: Tensor[max(decode_lengths), batch_size, vocab_size]\n",
    "            sorted_dest_sequences: Tensor[seq_len, batch_size]\n",
    "            sorted_decode_lengths: Tensor[batch_size,]\n",
    "            sorted_indices: Tensor[batch_size,]\n",
    "        \"\"\"\n",
    "        mask = self.create_mask(src_sequences) # [seq_len, batch_size]\n",
    "        \n",
    "        # Encoding\n",
    "        enc_outputs, h_state, c_state = self.encoder(\n",
    "            input_sequences=src_sequences,\n",
    "            sequence_lengths=src_lengths\n",
    "        )\n",
    "        # enc_outputs: [seq_len, batch_size, 2 * hidden_size]\n",
    "        # h_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        # c_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        \n",
    "        enc_outputs = self.fc(enc_outputs)\n",
    "        # enc_outputs: [seq_len, batch_size, hidden_size]\n",
    "        \n",
    "        # Sort the batch (dest) by decreasing lengths\n",
    "        sorted_dest_lengths, sorted_indices = torch.sort(dest_lengths, dim=0, descending=True)\n",
    "        sorted_dest_sequences = dest_sequences[:, sorted_indices]\n",
    "        enc_outputs = enc_outputs[:, sorted_indices, :]\n",
    "        h_state = h_state[:, sorted_indices, :]\n",
    "        c_state = c_state[:, sorted_indices, :]\n",
    "        \n",
    "        # Init hidden and memory states\n",
    "        h_state = self.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        c_state = self.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>\n",
    "        # So, decoding lengths are actual lengths - 1\n",
    "        sorted_decode_lengths = (sorted_dest_lengths - 1).tolist()\n",
    "        \n",
    "        # Decoding\n",
    "        batch_size, last = dest_sequences.size(1), None\n",
    "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
    "        for t in range(max(sorted_decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
    "            if last is not None:\n",
    "                if random.random() < tf_ratio:\n",
    "                    in_ = last[:batch_size_t]\n",
    "                else:\n",
    "                    in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            else:\n",
    "                in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            # in_ [batch_size,]\n",
    "            logit, h_state, c_state, _ = self.decoder(\n",
    "                in_, \n",
    "                h_state[:, :batch_size_t, :].contiguous(),\n",
    "                c_state[:, :batch_size_t, :].contiguous(),\n",
    "                enc_outputs[:, :batch_size_t, :],\n",
    "                mask[:, :batch_size_t]\n",
    "            )\n",
    "            # logit: [batch_size, vocab_size]\n",
    "            # h_state: [num_layers, batch_size, hidden_size]\n",
    "            # c_state: [num_layers, batch_size, hidden_size]\n",
    "            logits[t, :batch_size_t, :] = logit\n",
    "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
    "        \n",
    "        return logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 759 ms, total: 44.9 s\n",
      "Wall time: 7.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def test_seq2seq():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for method in ['dot', 'general', 'concat']:\n",
    "        attention = LuongAttnLayer(hidden_size=256, method=method)\n",
    "        decoder = DecoderLSTM(\n",
    "            embedding_size=300,\n",
    "            vocab_size=len(EN.vocab),\n",
    "            hidden_size=256,\n",
    "            n_layers=4,\n",
    "            dropout=0.25,\n",
    "            recurrent_dropout=0.25,\n",
    "            attention=attention\n",
    "        )\n",
    "        model = SeqToSeqLSTM(encoder, decoder,\n",
    "                             pad_index=EN.vocab.stoi[EN.pad_token],\n",
    "                             device='cpu')\n",
    "        for data in train_iterator:\n",
    "            logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "                model(\n",
    "                    src_sequences=data.src[0], \n",
    "                    src_lengths=data.src[1],\n",
    "                    dest_sequences=data.dest[0],\n",
    "                    dest_lengths=data.dest[1],\n",
    "                    tf_ratio=0.\n",
    "                )\n",
    "            assert logits.size() == torch.Size([\n",
    "                max(sorted_decode_lengths),\n",
    "                batch_size,\n",
    "                len(EN.vocab)\n",
    "            ]), logits.size()\n",
    "            assert sorted_dest_sequences.size() == torch.Size([\n",
    "                data.dest[0].shape[0],\n",
    "                batch_size\n",
    "            ]), sorted_dest_sequences.size()\n",
    "            assert len(sorted_decode_lengths) == batch_size, len(sorted_decode_lengths)\n",
    "            assert sorted_indices.size() == torch.Size([\n",
    "                batch_size,\n",
    "            ]), sorted_indices.size()\n",
    "            break\n",
    "        \n",
    "test_seq2seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, loader, epoch, grad_clip, tf_ratio, device):\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, data in pbar:\n",
    "        # Forward prop.\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(*data.src, *data.dest, tf_ratio=tf_ratio)\n",
    "        # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "        sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "        # Remove paddings\n",
    "        logits = nn.utils.rnn.pack_padded_sequence(\n",
    "            logits,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "            sorted_dest_sequences,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, sorted_dest_sequences)\n",
    "        # Back prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            torch_utils.clip_gradient(optimizer, grad_clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track metrics\n",
    "        loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "        acc_tracker.update(\n",
    "            torch_utils.accuracy(logits, sorted_dest_sequences, 5),\n",
    "            sum(sorted_decode_lengths)\n",
    "        )\n",
    "        # Update progressbar description\n",
    "        pbar.set_description(f'Epoch: {epoch + 1:03d} - loss: {loss_tracker.average:.3f} - acc: {acc_tracker.average:.3f}%')\n",
    "    return loss_tracker.average, acc_tracker.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, loader, field, epoch, device):\n",
    "    references, hypotheses = [], []\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar: \n",
    "            # Forward prop.\n",
    "            logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "                model(*data.src, *data.dest, tf_ratio=0.)\n",
    "            # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "            sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "            # Remove paddings\n",
    "            logits_copy = logits.clone()\n",
    "            logits = nn.utils.rnn.pack_padded_sequence(\n",
    "                logits,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_dest_sequences,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, sorted_dest_sequences)\n",
    "            # Track metrics\n",
    "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "            acc_tracker.update(\n",
    "                torch_utils.accuracy(logits, sorted_dest_sequences, 5),\n",
    "                sum(sorted_decode_lengths)\n",
    "            )\n",
    "            # Update references\n",
    "            target_sequences = data.dest[0].t()[sorted_indices]\n",
    "            for j in range(target_sequences.size(0)):\n",
    "                target_sequence = target_sequences[j].tolist()\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in target_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "            # Update hypotheses\n",
    "            _, preds = torch.max(logits_copy, dim=2)\n",
    "            preds = preds.t().tolist()\n",
    "            for j, p in enumerate(preds):\n",
    "                hypotheses.append([\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in preds[j][:sorted_decode_lengths[j]] # Remove padding\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ])\n",
    "            assert len(references) == len(hypotheses)\n",
    "            # Update progressbar description\n",
    "            pbar.set_description(f'Epoch: {epoch + 1:03d} - val_loss: {loss_tracker.average:.3f} - val_acc: {acc_tracker.average:.3f}%')\n",
    "        # Calculate BLEU-4 score\n",
    "        try:\n",
    "            bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "        except:\n",
    "            for i in range(len(hypotheses)):\n",
    "                try:\n",
    "                    print(bleu_score([hypotheses[i]], [references[i]], max_n=4, weights=[0.25, 0.25, 0.25, 0.25]), end=' ')\n",
    "                except:\n",
    "                    print(hypotheses[i])\n",
    "                    print(references[i])\n",
    "                    break\n",
    "        # Display some examples\n",
    "        for i in np.random.choice(len(loader), size=3, replace=False):\n",
    "            src, dest = ' '.join(references[i][0]), ' '.join(hypotheses[i])\n",
    "            display(HTML(f'<span style=\"color:blue\"><b>Ground truth translation:</b> {src}</span>'))\n",
    "            display(HTML(f'<span style=\"color:red\"><b>Predicted translation:</b> {dest}</span>'))\n",
    "            print('='*100)\n",
    "    return loss_tracker.average, acc_tracker.average, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, valid_loader, field, n_epochs, grad_clip, tf_ratio, last_improv, model_name, device):\n",
    "    history, best_bleu = {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_loss': [],\n",
    "        'bleu4': []\n",
    "    }, 0.\n",
    "    for epoch in range(n_epochs):\n",
    "         # Stop training if no improvment since last 4 epochs\n",
    "        if last_improv == 4:\n",
    "            print('Training Finished - The model has stopped improving since last 4 epochs')\n",
    "            break\n",
    "        # Decay LR if no improvment\n",
    "        if last_improv > 0:\n",
    "            torch_utils.adjust_lr(optimizer=optimizer,\n",
    "                                  shrink_factor=0.9,\n",
    "                                  verbose=True)\n",
    "        # Train step\n",
    "        loss, acc = train_step(model=model,\n",
    "                               optimizer=optimizer,\n",
    "                               criterion=criterion,\n",
    "                               loader=train_loader,\n",
    "                               epoch=epoch,\n",
    "                               grad_clip=grad_clip, \n",
    "                               tf_ratio=tf_ratio,\n",
    "                               device=device)\n",
    "        # Validation step\n",
    "        val_loss, val_acc, bleu4 = validate(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            loader=valid_loader,\n",
    "                                            field=field,\n",
    "                                            epoch=epoch,\n",
    "                                            device=device)\n",
    "        # Update history dict\n",
    "        history['acc'].append(acc)\n",
    "        history['loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['bleu4'].append(bleu4)\n",
    "        # Print BLEU score\n",
    "        text = f'BLEU-4: {bleu4*100:.3f}%'\n",
    "        if bleu4 > best_bleu:\n",
    "            best_bleu, last_improv = bleu4, 0\n",
    "        else:\n",
    "            last_improv += 1\n",
    "            text += f' - Last improvement since {last_improv} epoch(s)'\n",
    "        print(text)\n",
    "        # Decrease teacher forcing rate\n",
    "        tf_ratio = torch_utils.adjust_tf(tf_ratio,\n",
    "                                         shrink_factor=0.8,\n",
    "                                         verbose=False)\n",
    "        # Save checkpoint\n",
    "        torch_utils.save_checkpoint(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_name=model_name,\n",
    "                                    epoch=epoch,\n",
    "                                    last_improv=last_improv,\n",
    "                                    bleu4=bleu4,\n",
    "                                    is_best=bleu4 >= best_bleu)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.13 s, sys: 1.31 s, total: 9.44 s\n",
      "Wall time: 9.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load word vectors\n",
    "spacy_fr = spacy.load('fr_core_news_lg') # CBOW trained word vectors\n",
    "spacy_en = spacy.load('en_core_web_lg') # GloVe trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12215/12215 [01:42<00:00, 118.64it/s]\n",
      "100%|██████████| 9528/9528 [01:12<00:00, 132.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "fr_embeddings = torch_utils.load_embeddings(nlp=spacy_fr, field=FR)\n",
    "en_embeddings = torch_utils.load_embeddings(nlp=spacy_en, field=EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq-lstm-luong-attn'\n",
    "N_LAYERS = 4\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDING_SIZE = 300\n",
    "ENC_DROPOUT = 0.3\n",
    "ENC_RECURRENT_DROPOUT = 0.25\n",
    "DEC_DROPOUT = 0.15\n",
    "DEC_RECURRENT_DROPOUT = 0.2\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "INIT_LR = 1e-5\n",
    "GRAD_CLIP = 1.0\n",
    "TF_RATIO = 1.0\n",
    "END_LR = 10\n",
    "N_ITERS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 42,520,697\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLSTM(embedding_size=EMBEDDING_SIZE,\n",
    "                      vocab_size=len(FR.vocab),\n",
    "                      hidden_size=HIDDEN_SIZE,\n",
    "                      n_layers=N_LAYERS,\n",
    "                      dropout=ENC_DROPOUT,\n",
    "                      recurrent_dropout=ENC_RECURRENT_DROPOUT)\n",
    "encoder.load_pretrained_embeddings(fr_embeddings)\n",
    "encoder.fine_tuning_embeddings(fine_tune=True)\n",
    "attention = LuongAttnLayer(hidden_size=HIDDEN_SIZE, method='dot')\n",
    "decoder = DecoderLSTM(embedding_size=EMBEDDING_SIZE,\n",
    "                      vocab_size=len(EN.vocab),\n",
    "                      hidden_size=HIDDEN_SIZE,\n",
    "                      n_layers=N_LAYERS,\n",
    "                      dropout=DEC_DROPOUT,\n",
    "                      recurrent_dropout=DEC_RECURRENT_DROPOUT,\n",
    "                      attention=attention)\n",
    "decoder.load_pretrained_embeddings(en_embeddings)\n",
    "decoder.fine_tuning_embeddings(fine_tune=True)\n",
    "seq2seq = SeqToSeqLSTM(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       pad_index=EN.vocab.stoi[EN.pad_token],\n",
    "                       device=DEVICE)\n",
    "seq2seq.apply(torch_utils.xavier_init_weights)\n",
    "seq2seq.to(DEVICE)\n",
    "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=INIT_LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f'Number of parameters of the model: {torch_utils.count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True,\n",
    "                              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:13<00:11,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    }
   ],
   "source": [
    "lr_finder = LRFinder(model=seq2seq,\n",
    "                     optimizer=optimizer,\n",
    "                     criterion=criterion,\n",
    "                     grad_clip=GRAD_CLIP)\n",
    "\n",
    "lr_finder.range_test(data_loader=train_iterator,\n",
    "                     end_lr=END_LR, n_iters=N_ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested LR (steepest gradient): 3.27E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax, lr = lr_finder.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - loss: 5.676 - acc: 4.494%: 100%|██████████| 1263/1263 [05:04<00:00,  4.15it/s]\n",
      "Epoch: 001 - val_loss: 5.364 - val_acc: 5.024%: 100%|██████████| 71/71 [00:06<00:00, 11.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> it does not sit well with the cold and <unk> laws of the market . <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> it is <unk> the the the the the the . <eos> <eos> <eos> <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> we must also use best fishing practices . <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> we must to to to to the . .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the time necessary for the process is longer , however . <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is a a a a . . <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 2.139%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 - loss: 5.265 - acc: 5.186%:  45%|████▌     | 573/1263 [02:18<02:57,  3.88it/s]"
     ]
    }
   ],
   "source": [
    "history = train(model=seq2seq,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=train_iterator,\n",
    "                valid_loader=valid_iterator,\n",
    "                field=EN,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                grad_clip=GRAD_CLIP,\n",
    "                tf_ratio=TF_RATIO,\n",
    "                last_improv=0,\n",
    "                model_name=MODEL_NAME,\n",
    "                device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "axes[1].plot(history['acc'], label='train')\n",
    "axes[1].plot(history['val_acc'], label='valid')\n",
    "axes[1].plot(np.array(history['bleu4']) * 100., label='BLEU-4')\n",
    "axes[1].set_title('Top-5 Accuracy & BLEU-4 history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy & BLEU-4 (%)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.load_state_dict(torch.load(f'./checkpoint/BEST_{MODEL_NAME}.pt').get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, beam_size, src_field, dest_field, max_len, device):\n",
    "    src_sentences = [*map(lambda example: example.src, test_data.examples)]\n",
    "    dest_sentences = [*map(lambda example: example.dest, test_data.examples)]\n",
    "    \n",
    "    data = [*zip(\n",
    "        [*map(lambda word_list: src_field.process([word_list]), src_sentences)],\n",
    "        [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)]\n",
    "    )]\n",
    "    \n",
    "    references, hypotheses, sources = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(data), total=len(data))\n",
    "        for i, ((src_sequence, src_length), (dest_sequence, dest_length)) in pbar:\n",
    "            src_sequence, src_length = src_sequence.to(device), src_length.to(device)\n",
    "            dest_sequence, dest_length = dest_sequence.to(device), dest_length.to(device)\n",
    "            \n",
    "            # Encoding\n",
    "            enc_outputs, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                          sequence_lengths=src_length)\n",
    "\n",
    "            enc_outputs = model.fc(enc_outputs) # [seq_len, 1, hidden_size]\n",
    "            mask = model.create_mask(src_sequence) # [seq_len, 1]\n",
    "\n",
    "            # Init hidden and memory states\n",
    "            h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "            c_state = model.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "            h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "            c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "\n",
    "            # Decoding\n",
    "            tree = [[Node(\n",
    "                token=torch.LongTensor([\n",
    "                    dest_field.vocab.stoi[dest_field.init_token]\n",
    "                ]).to(device),\n",
    "                states=(h_state, c_state)\n",
    "            )]]\n",
    "            \n",
    "            for _ in range(max_len):\n",
    "                next_nodes = []\n",
    "                for node in tree[-1]:\n",
    "                    # Skip eos token\n",
    "                    if node.eos:\n",
    "                        continue\n",
    "                    # Decode\n",
    "                    logit, h_state, c_state, _ = model.decoder(\n",
    "                        input_word_index=node.token, \n",
    "                        h_state=node.states[0].contiguous(),\n",
    "                        c_state=node.states[1].contiguous(),\n",
    "                        enc_outputs=enc_outputs,\n",
    "                        mask=mask\n",
    "                    )\n",
    "                    # logit: [1, vocab_size]\n",
    "                    # h_state: [n_layers, 1, hidden_size]\n",
    "                    # c_state: [n_layers, 1, hidden_size]\n",
    "\n",
    "                    # Get scores\n",
    "                    logp = F.log_softmax(logit, dim=1).squeeze(dim=0) # [vocab_size]\n",
    "\n",
    "                    # Get top k tokens & logps\n",
    "                    topk_logps, topk_tokens = torch.topk(logp, beam_size)\n",
    "\n",
    "                    for k in range(beam_size):\n",
    "                        next_nodes.append(Node(\n",
    "                            token=topk_tokens[k, None],\n",
    "                            states=(h_state, c_state),\n",
    "                            logp=topk_logps[k, None].cpu().item(),\n",
    "                            parent=node,\n",
    "                            eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]\n",
    "                        ))\n",
    "\n",
    "                if len(next_nodes) == 0:\n",
    "                    break\n",
    "\n",
    "                # Sort next_nodes to get the best\n",
    "                next_nodes = sorted(next_nodes,\n",
    "                                    key=lambda node: node.logps,\n",
    "                                    reverse=True)\n",
    "                # Update the tree\n",
    "                tree.append(next_nodes[:beam_size])\n",
    "                \n",
    "            # Find the best path of the tree\n",
    "            best_path = find_best_path(tree)\n",
    "\n",
    "            # Get the translation\n",
    "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
    "            pred_translated = [*filter(lambda word: word not in [\n",
    "                dest_field.init_token, dest_field.eos_token\n",
    "            ], pred_translated[::-1])]\n",
    "\n",
    "            # Update hypotheses\n",
    "            hypotheses.append(pred_translated)\n",
    "\n",
    "            # Update references\n",
    "            references.append([[\n",
    "                dest_field.vocab.itos[indice] \n",
    "                for indice in dest_sequence \n",
    "                if indice not in (\n",
    "                    dest_field.vocab.stoi[dest_field.init_token],\n",
    "                    dest_field.vocab.stoi[dest_field.eos_token],\n",
    "                    dest_field.vocab.stoi[dest_field.pad_token]\n",
    "                )\n",
    "            ]])\n",
    "\n",
    "            # Update sources\n",
    "            sources.append([\n",
    "                src_field.vocab.itos[indice] \n",
    "                for indice in src_sequence \n",
    "                if indice not in (\n",
    "                    src_field.vocab.stoi[src_field.init_token],\n",
    "                    src_field.vocab.stoi[src_field.eos_token],\n",
    "                    src_field.vocab.stoi[src_field.pad_token]\n",
    "                )\n",
    "            ])\n",
    "    \n",
    "        # Calculate BLEU-4 score\n",
    "        assert len(hypotheses) == len(references) == len(sources)\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    return hypotheses, references, sources, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                          test_data=valid_data,\n",
    "                          beam_size=1,\n",
    "                          src_field=FR,\n",
    "                          dest_field=EN,\n",
    "                          max_len=MAX_LENGTH,\n",
    "                          device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
