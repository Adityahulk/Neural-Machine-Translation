{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "import torch_utils\n",
    "from beam_utils import Node, find_best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_fr = utils.read_file('./data/europarl-v7.fr-en.fr')\n",
    "data_en = utils.read_file('./data/europarl-v7.fr-en.en')\n",
    "\n",
    "assert len(data_fr) == len(data_en)\n",
    "\n",
    "indexes = np.random.choice(range(len(data_fr)), size=200_000, replace=False)\n",
    "\n",
    "pairs = [*zip(\n",
    "    utils.clean_lines([data_fr[index] for index in indexes]),\n",
    "    utils.clean_lines([data_en[index] for index in indexes])\n",
    ")]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_fr = [*map(lambda pair: len(pair['fr'].split()), pairs)]\n",
    "len_en = [*map(lambda pair: len(pair['en'].split()), pairs)]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist([*filter(lambda x: x < 50, len_fr)])\n",
    "axes[0].grid(True)\n",
    "axes[1].hist([*filter(lambda x: x < 50, len_en)])\n",
    "axes[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MIN_LENGTH, MAX_LENGTH = 10, 25\n",
    "pairs = [*filter(lambda pair: MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH and MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH, pairs)]\n",
    "print(f'Number of examples after filtering: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True)\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en',\n",
    "           include_lengths=True)\n",
    "\n",
    "examples = [Example.fromdict(\n",
    "    data=pair,\n",
    "    fields={\n",
    "        'fr': ('src', FR),\n",
    "        'en': ('dest', EN)\n",
    "    }\n",
    ") for pair in tqdm.tqdm(pairs)]\n",
    "print(f'Number of examples: {len(examples):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
    "train_data, valid_data, test_data = data.split(split_ratio=[0.9, 0.05, 0.05])\n",
    "print(f'train set size: {len(train_data.examples):,}')\n",
    "print(f'valid set size: {len(valid_data.examples):,}')\n",
    "print(f'test set size: {len(test_data.examples):,}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MIN_COUNT = 5\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab):,}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "    \n",
    "    def forward(self, input_sequences, sequence_lengths):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_sequences: Tensor[seq_len, batch_size]\n",
    "            sequence_lengths: Tensor[batch_size,]\n",
    "            \n",
    "        :return\n",
    "            outputs: Tensor[seq_len, batch_size, 2 * hidden_size]\n",
    "            hn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "            cn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_sequences)\n",
    "        embedded = F.dropout(embedded, p=self.dropout)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths)\n",
    "        outputs, (hn, cn) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return outputs, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.35,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in test_iterator:\n",
    "        outputs, hn, cn = encoder(\n",
    "            input_sequences=data.src[0],\n",
    "            sequence_lengths=data.src[1]\n",
    "        )\n",
    "        seq_len = data.src[0].size(0)\n",
    "        assert outputs.size() == torch.Size([seq_len, batch_size, 2 * 256]), outputs.size()\n",
    "        assert hn.size() == torch.Size([4 * 2, batch_size, 256]), hn.size()\n",
    "        assert cn.size() == torch.Size([4 * 2, batch_size, 256]), cn.size()\n",
    "        break\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luong et al. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttn(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, method):\n",
    "        if method not in ['dot', 'concat']:\n",
    "            raise NotImplemented(f'The {method} attention is not defined!')\n",
    "        \n",
    "        super(LuongAttn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.method = method\n",
    "        if method == 'general':\n",
    "            self.W = nn.Linear(hidden_size, hidden_size)\n",
    "        elif method == 'concat':\n",
    "            self.W = nn.Linear(hidden_size, hidden_size)\n",
    "            self.V = nn.Linear(hidden_size, 1)\n",
    "            \n",
    "    def forward(self, h_state, enc_outputs, mask):\n",
    "        \"\"\"\n",
    "        :args\n",
    "        h_state: Tensor[n_layers, batch_size, hidden_size]\n",
    "        enc_outputs: Tensor[seq_len, batch_size, hidden_size]\n",
    "        mask: Tensor[seq_len, batch_size]\n",
    "\n",
    "        :return\n",
    "            attn_weights: Tensor[seq_len, batch_size, 1]\n",
    "        \"\"\"\n",
    "        if h_state.shape[0] > 1:\n",
    "            h_state = h_state.sum(dim=0) # [batch_size, hidden_size]\n",
    "            h_state = h_state.unsqueeze(0) # [1, batch_size, hidden_size]\n",
    "\n",
    "        # Calculating the alignment scores\n",
    "        if self.method == 'dot':\n",
    "            scores = torch.bmm(\n",
    "                enc_outputs.permute(1, 0, 2), # [batch_size, seq_len, hidden_size]\n",
    "                h_state.permute(1, 2, 0) # [batch_size, hidden_size, 1]\n",
    "            ).permute(1, 0, 2) / np.sqrt(self.hidden_size) # [seq_len, batch_size, 1]\n",
    "\n",
    "        if self.method == 'concat':\n",
    "            scores = self.V(\n",
    "                torch.tanh(self.W(\n",
    "                    enc_outputs + h_state # [seq_len, batch_size, hidden_size]\n",
    "                ))\n",
    "            ) # [seq_len, batch_size, 1]\n",
    "\n",
    "        # Apply mask to ignore <pad> tokens\n",
    "        mask = mask.unsqueeze(2) # [seq_len, batch_size, 1]\n",
    "        scores = scores.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        # Calculating the attention weights by softmaxing the alignment scores\n",
    "        attn_weights = F.softmax(scores, dim=1) # [seq_len, batch_size, 1]\n",
    "\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_luong_attn():\n",
    "    for method in ['dot', 'concat']:\n",
    "        attention = LuongAttn(hidden_size=256, method=method)\n",
    "        n_layers, batch_size, hidden_size, seq_len = 2, 128, 256, 30\n",
    "        h_state = torch.rand((n_layers, batch_size, hidden_size))\n",
    "        enc_outputs = torch.rand((seq_len, batch_size, hidden_size))\n",
    "        mask = torch.randint(low=0, high=2, size=(seq_len, batch_size))\n",
    "        attn_weights = attention(h_state=h_state, enc_outputs=enc_outputs, mask=mask)\n",
    "        assert attn_weights.size() == torch.Size([seq_len, batch_size, 1]), attn_weights.size()\n",
    "    \n",
    "test_luong_attn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout,\n",
    "        attention\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "        \n",
    "    def forward(self, input_word_index, h_state, c_state, enc_outputs, mask):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_word_index: Tensor[batch_size,]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            enc_outputs: Tensor[seq_len, batch_size, hidden_size] \n",
    "            mask: Tensor[seq_len, batch_size]\n",
    "            \n",
    "        :return\n",
    "            logit: Tensor[batch_size, vocab_size]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            attn_weights: Tensor[batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_word_index.unsqueeze(0)) # [seq_len=1, batch_size, embedding_size]\n",
    "        outputs, (h_state, c_state) = self.lstm(embedded, (h_state, c_state))\n",
    "        # outputs: [seq_len=1, batch_size, hidden_size]\n",
    "        # h_state: [n_layers, batch_size, hidden_size]\n",
    "        # c_state: [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # Compute Attention Weights\n",
    "        attn_weights = self.attention(h_state=outputs,\n",
    "                                      enc_outputs=enc_outputs,\n",
    "                                      mask=mask) # [seq_len, batch_size, 1]\n",
    "        \n",
    "        # Compute Context Vector\n",
    "        context_vector = torch.bmm(\n",
    "            enc_outputs.permute(1, 2, 0), # [batch_size, hidden_size, seq_len]\n",
    "            attn_weights.permute(1, 0, 2), # [batch_size, seq_len, 1]\n",
    "        ).permute(2, 0, 1) # [1, batch_size, hidden_size]\n",
    "        \n",
    "        # New input: concatenate context_vector with hidden_states\n",
    "        new_input = torch.cat((context_vector, outputs), dim=2) # [1, batch_size, hidden_size * 2]\n",
    "        \n",
    "        # Get logit\n",
    "        logit = self.fc(F.dropout(new_input.squeeze(0), p=self.dropout))\n",
    "        # logit: [batch_size, vocab_size]\n",
    "        \n",
    "        return logit, h_state, c_state, attn_weights.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeqLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, pad_index, device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and Decoder must have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            'Encoder and Decoder must have the same number of reccurrent hidden units'\n",
    "        \n",
    "        super(SeqToSeqLSTM, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_index = pad_index\n",
    "        self.init_h0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers) \n",
    "        self.init_c0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers)\n",
    "        self.fc = nn.Linear(encoder.hidden_size * 2, encoder.hidden_size)\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src_sequences):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            \n",
    "        :return\n",
    "            mask: Tensor[seq_len, batch_size]\n",
    "        \"\"\"\n",
    "        mask = (src_sequences != self.pad_index)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src_sequences, src_lengths, dest_sequences, dest_lengths, tf_ratio):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            src_lengths: Tensor[batch_size,]\n",
    "            dest_sequences: Tensor[seq_len, batch_size]\n",
    "            dest_lengths: Tensor[batch_size,]\n",
    "            tf_ratio: float\n",
    "            \n",
    "        :return\n",
    "            logits: Tensor[max(decode_lengths), batch_size, vocab_size]\n",
    "            sorted_dest_sequences: Tensor[seq_len, batch_size]\n",
    "            sorted_decode_lengths: Tensor[batch_size,]\n",
    "            sorted_indices: Tensor[batch_size,]\n",
    "        \"\"\"\n",
    "        mask = self.create_mask(src_sequences) # [seq_len, batch_size]\n",
    "        \n",
    "        # Encoding\n",
    "        enc_outputs, h_state, c_state = self.encoder(\n",
    "            input_sequences=src_sequences,\n",
    "            sequence_lengths=src_lengths\n",
    "        )\n",
    "        # enc_outputs: [seq_len, batch_size, n_layers * hidden_size]\n",
    "        # h_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        # c_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        \n",
    "        enc_outputs = self.fc(enc_outputs)\n",
    "        # enc_outputs: [seq_len, batch_size, hidden_size]\n",
    "        \n",
    "        # Sort the batch (dest) by decreasing lengths\n",
    "        sorted_dest_lengths, sorted_indices = torch.sort(dest_lengths, dim=0, descending=True)\n",
    "        sorted_dest_sequences = dest_sequences[:, sorted_indices]\n",
    "        enc_outputs = enc_outputs[:, sorted_indices, :]\n",
    "        h_state = h_state[:, sorted_indices, :]\n",
    "        c_state = c_state[:, sorted_indices, :]\n",
    "        \n",
    "        # Init hidden and memory states\n",
    "        h_state = self.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        c_state = self.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>\n",
    "        # So, decoding lengths are actual lengths - 1\n",
    "        sorted_decode_lengths = (sorted_dest_lengths - 1).tolist()\n",
    "        \n",
    "        # Decoding\n",
    "        batch_size, last = dest_sequences.size(1), None\n",
    "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
    "        for t in range(max(sorted_decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
    "            if last is not None:\n",
    "                if random.random() < tf_ratio:\n",
    "                    in_ = last[:batch_size_t]\n",
    "                else:\n",
    "                    in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            else:\n",
    "                in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            # in_ [batch_size,]\n",
    "            logit, h_state, c_state, _ = self.decoder(\n",
    "                in_, \n",
    "                h_state[:, :batch_size_t, :].contiguous(),\n",
    "                c_state[:, :batch_size_t, :].contiguous(),\n",
    "                enc_outputs[:, :batch_size_t, :],\n",
    "                mask[:, :batch_size_t]\n",
    "            )\n",
    "            # logit: [batch_size, vocab_size]\n",
    "            # h_state: [num_layers, batch_size, hidden_size]\n",
    "            # c_state: [num_layers, batch_size, hidden_size]\n",
    "            logits[t, :batch_size_t, :] = logit\n",
    "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
    "        \n",
    "        return logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seq2seq():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    attention = LuongAttn(hidden_size=256, method='dot')\n",
    "    decoder = DecoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(EN.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25,\n",
    "        attention=attention\n",
    "    )\n",
    "    model = SeqToSeqLSTM(encoder, decoder,\n",
    "                         pad_index=EN.vocab.stoi[EN.pad_token],\n",
    "                         device='cpu')\n",
    "    for data in train_iterator:\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(\n",
    "                src_sequences=data.src[0], \n",
    "                src_lengths=data.src[1],\n",
    "                dest_sequences=data.dest[0],\n",
    "                dest_lengths=data.dest[1],\n",
    "                tf_ratio=0.\n",
    "            )\n",
    "        assert logits.size() == torch.Size([\n",
    "            max(sorted_decode_lengths),\n",
    "            batch_size,\n",
    "            len(EN.vocab)\n",
    "        ]), logits.size()\n",
    "        assert sorted_dest_sequences.size() == torch.Size([\n",
    "            data.dest[0].shape[0],\n",
    "            batch_size\n",
    "        ]), sorted_dest_sequences.size()\n",
    "        assert len(sorted_decode_lengths) == batch_size, len(sorted_decode_lengths)\n",
    "        assert sorted_indices.size() == torch.Size([\n",
    "            batch_size,\n",
    "        ]), sorted_indices.size()\n",
    "        break\n",
    "        \n",
    "test_seq2seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, loader, epoch, grad_clip, tf_ratio, device):\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, data in pbar:\n",
    "        # Forward prop.\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(*data.src, *data.dest, tf_ratio=tf_ratio)\n",
    "        # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "        sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "        # Remove paddings\n",
    "        logits = nn.utils.rnn.pack_padded_sequence(\n",
    "            logits,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "            sorted_dest_sequences,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, sorted_dest_sequences)\n",
    "        # Back prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            torch_utils.clip_gradient(optimizer, grad_clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track metrics\n",
    "        loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "        acc_tracker.update(\n",
    "            torch_utils.accuracy(logits, sorted_dest_sequences, 5),\n",
    "            sum(sorted_decode_lengths)\n",
    "        )\n",
    "        # Update progressbar description\n",
    "        pbar.set_description(f'Epoch: {epoch + 1:03d} - loss: {loss_tracker.average:.3f} - acc: {acc_tracker.average:.3f}%')\n",
    "    return loss_tracker.average, acc_tracker.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, loader, field, epoch, device):\n",
    "    references, hypotheses = [], []\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar: \n",
    "            # Forward prop.\n",
    "            logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "                model(*data.src, *data.dest, tf_ratio=0.)\n",
    "            # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "            sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "            # Remove paddings\n",
    "            logits_copy = logits.clone()\n",
    "            logits = nn.utils.rnn.pack_padded_sequence(\n",
    "                logits,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_dest_sequences,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, sorted_dest_sequences)\n",
    "            # Track metrics\n",
    "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "            acc_tracker.update(\n",
    "                torch_utils.accuracy(logits, sorted_dest_sequences, 5),\n",
    "                sum(sorted_decode_lengths)\n",
    "            )\n",
    "            # Update references\n",
    "            target_sequences = data.dest[0].t()[sorted_indices]\n",
    "            for j in range(target_sequences.size(0)):\n",
    "                target_sequence = target_sequences[j].tolist()\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in target_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "            # Update hypotheses\n",
    "            _, preds = torch.max(logits_copy, dim=2)\n",
    "            preds = preds.t().tolist()\n",
    "            for j, p in enumerate(preds):\n",
    "                hypotheses.append([\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in preds[j][:sorted_decode_lengths[j]] # Remove padding\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ])\n",
    "            assert len(references) == len(hypotheses)\n",
    "            # Update progressbar description\n",
    "            pbar.set_description(f'Epoch: {epoch + 1:03d} - val_loss: {loss_tracker.average:.3f} - val_acc: {acc_tracker.average:.3f}%')\n",
    "        # Calculate BLEU-4 score\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "        # Display some examples\n",
    "        for i in np.random.choice(len(loader), size=3, replace=False):\n",
    "            src, dest = ' '.join(references[i][0]), ' '.join(hypotheses[i])\n",
    "            display(HTML(f'<span style=\"color:blue\"><b>Ground truth translation:</b> {src}</span>'))\n",
    "            display(HTML(f'<span style=\"color:red\"><b>Predicted translation:</b> {dest}</span>'))\n",
    "            print('='*100)\n",
    "    return loss_tracker.average, acc_tracker.average, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, valid_loader, field, n_epochs, grad_clip, tf_ratio, last_improv, model_name, device):\n",
    "    history, best_bleu = {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_loss': [],\n",
    "        'bleu4': []\n",
    "    }, 0.\n",
    "    for epoch in range(n_epochs):\n",
    "         # Stop training if no improvment since last 4 epochs\n",
    "        if last_improv == 4:\n",
    "            print('Training Finished - The model has stopped improving since last 4 epochs')\n",
    "            break\n",
    "        # Decay LR if no improvment\n",
    "        if last_improv > 0:\n",
    "            torch_utils.adjust_lr(optimizer=optimizer,\n",
    "                                  shrink_factor=0.9,\n",
    "                                  verbose=True)\n",
    "        # Train step\n",
    "        loss, acc = train_step(model=model,\n",
    "                               optimizer=optimizer,\n",
    "                               criterion=criterion,\n",
    "                               loader=train_loader,\n",
    "                               epoch=epoch,\n",
    "                               grad_clip=grad_clip, \n",
    "                               tf_ratio=tf_ratio,\n",
    "                               device=device)\n",
    "        # Validation step\n",
    "        val_loss, val_acc, bleu4 = validate(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            loader=valid_loader,\n",
    "                                            field=field,\n",
    "                                            epoch=epoch,\n",
    "                                            device=device)\n",
    "        # Update history dict\n",
    "        history['acc'].append(acc)\n",
    "        history['loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['bleu4'].append(bleu4)\n",
    "        # Print BLEU score\n",
    "        text = f'BLEU-4: {bleu4*100:.3f}%'\n",
    "        if bleu4 > best_bleu:\n",
    "            best_bleu, last_improv = bleu4, 0\n",
    "        else:\n",
    "            last_improv += 1\n",
    "            text += f' - Last improvement since {last_improv} epoch(s)'\n",
    "        print(text)\n",
    "        # Decrease teacher forcing rate\n",
    "        tf_ratio = torch_utils.adjust_tf(tf_ratio,\n",
    "                                         shrink_factor=0.8,\n",
    "                                         verbose=False)\n",
    "        # Save checkpoint\n",
    "        torch_utils.save_checkpoint(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_name=model_name,\n",
    "                                    epoch=epoch,\n",
    "                                    last_improv=last_improv,\n",
    "                                    bleu4=bleu4,\n",
    "                                    is_best=bleu4 >= best_bleu)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load word vectors\n",
    "spacy_fr = spacy.load('fr_core_news_lg') # CBOW trained word vectors\n",
    "spacy_en = spacy.load('en_core_web_lg') # GloVe trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "fr_embeddings = torch_utils.load_embeddings(nlp=spacy_fr, field=FR)\n",
    "en_embeddings = torch_utils.load_embeddings(nlp=spacy_en, field=EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq-lstm-luong-attn'\n",
    "N_LAYERS = 2\n",
    "HIDDEN_SIZE = 256\n",
    "EMBEDDING_SIZE = 300\n",
    "ENC_DROPOUT = 0.3\n",
    "ENC_RECURRENT_DROPOUT = 0.25\n",
    "DEC_DROPOUT = 0.15\n",
    "DEC_RECURRENT_DROPOUT = 0.2\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "GRAD_CLIP = 1.0\n",
    "TF_RATIO = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(embedding_size=EMBEDDING_SIZE,\n",
    "                      vocab_size=len(FR.vocab),\n",
    "                      hidden_size=HIDDEN_SIZE,\n",
    "                      n_layers=N_LAYERS,\n",
    "                      dropout=ENC_DROPOUT,\n",
    "                      recurrent_dropout=ENC_RECURRENT_DROPOUT)\n",
    "encoder.load_pretrained_embeddings(fr_embeddings)\n",
    "encoder.fine_tuning_embeddings(fine_tune=True)\n",
    "attention = LuongAttn(hidden_size=HIDDEN_SIZE, method='concat')\n",
    "decoder = DecoderLSTM(embedding_size=EMBEDDING_SIZE,\n",
    "                      vocab_size=len(EN.vocab),\n",
    "                      hidden_size=HIDDEN_SIZE,\n",
    "                      n_layers=N_LAYERS,\n",
    "                      dropout=DEC_DROPOUT,\n",
    "                      recurrent_dropout=DEC_RECURRENT_DROPOUT,\n",
    "                      attention=attention)\n",
    "decoder.load_pretrained_embeddings(en_embeddings)\n",
    "decoder.fine_tuning_embeddings(fine_tune=True)\n",
    "seq2seq = SeqToSeqLSTM(encoder=encoder,\n",
    "                       decoder=decoder,\n",
    "                       pad_index=EN.vocab.stoi[EN.pad_token],\n",
    "                       device=DEVICE)\n",
    "seq2seq.apply(torch_utils.xavier_init_weights)\n",
    "seq2seq.to(DEVICE)\n",
    "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f'Number of parameters of the model: {torch_utils.count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True,\n",
    "                              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(model=seq2seq,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=train_iterator,\n",
    "                valid_loader=valid_iterator,\n",
    "                field=EN,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                grad_clip=GRAD_CLIP,\n",
    "                tf_ratio=TF_RATIO,\n",
    "                last_improv=0,\n",
    "                model_name=MODEL_NAME,\n",
    "                device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "axes[1].plot(history['acc'], label='train')\n",
    "axes[1].plot(history['val_acc'], label='valid')\n",
    "axes[1].plot(np.array(history['bleu4']) * 100., label='BLEU-4')\n",
    "axes[1].set_title('Top-5 Accuracy & BLEU-4 history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Top-5 Accuracy & BLEU-4 (%)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.load_state_dict(torch.load(f'./checkpoint/BEST_{MODEL_NAME}.pt').get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, beam_size, src_field, dest_field, max_len, device):\n",
    "    references, hypotheses, sources = [], [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar:\n",
    "            (src_sequences, src_lengths) = data.src[0], data.src[1]\n",
    "            (dest_sequences, dest_lengths) = data.dest[0], data.dest[1]\n",
    "            \n",
    "            batch_size = src_sequences.shape[1]\n",
    "            for j in range(batch_size): # We evaluate sentence by sentence\n",
    "                src_sequence = src_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                dest_sequence = dest_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                src_length, dest_length = src_lengths[j, None], dest_lengths[j, None] # [1,]\n",
    "                \n",
    "                # Encoding\n",
    "                enc_outputs, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                              sequence_lengths=src_length)\n",
    "                \n",
    "                enc_outputs = model.fc(enc_outputs) # [seq_len, 1, hidden_size]\n",
    "                mask = model.create_mask(src_sequence) # [seq_len, 1]\n",
    "                \n",
    "                assert enc_outputs.shape[0] == mask.shape[0], f\"{enc_outputs.shape[0]}, {' '.join([*map(lambda x: src_field.vocab.itos[x], src_sequence.squeeze(0))])}\"\n",
    "                \n",
    "                # Init hidden and memory states\n",
    "                h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                c_state = model.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                \n",
    "                # Decoding\n",
    "                tree = [[Node(\n",
    "                    token=torch.LongTensor([\n",
    "                        dest_field.vocab.stoi[dest_field.init_token]\n",
    "                    ]).to(device),\n",
    "                    states=(h_state, c_state)\n",
    "                )]]\n",
    "                \n",
    "                for _ in range(max_len):\n",
    "                    next_nodes = []\n",
    "                    for node in tree[-1]:\n",
    "                        # Skip eos token\n",
    "                        if node.eos:\n",
    "                            continue\n",
    "                        # Decode\n",
    "                        logit, h_state, c_state, _ = model.decoder(\n",
    "                            input_word_index=node.token, \n",
    "                            h_state=node.states[0].contiguous(),\n",
    "                            c_state=node.states[1].contiguous(),\n",
    "                            enc_outputs=enc_outputs,\n",
    "                            mask=mask\n",
    "                        )\n",
    "                        # logit: [1, vocab_size]\n",
    "                        # h_state: [n_layers, 1, hidden_size]\n",
    "                        # c_state: [n_layers, 1, hidden_size]\n",
    "\n",
    "                        # Get scores\n",
    "                        logp = F.log_softmax(logit, dim=1).squeeze(dim=0) # [vocab_size]\n",
    "\n",
    "                        # Get top k tokens & logps\n",
    "                        topk_logps, topk_tokens = torch.topk(logp, beam_size)\n",
    "\n",
    "                        for k in range(beam_size):\n",
    "                            next_nodes.append(Node(\n",
    "                                token=topk_tokens[k, None],\n",
    "                                states=(h_state, c_state),\n",
    "                                logp=topk_logps[k, None].cpu().item(),\n",
    "                                parent=node,\n",
    "                                eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]\n",
    "                            ))\n",
    "                    \n",
    "                    if len(next_nodes) == 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Sort next_nodes to get the best\n",
    "                    next_nodes = sorted(next_nodes,\n",
    "                                        key=lambda node: node.logps,\n",
    "                                        reverse=True)\n",
    "                    # Update the tree\n",
    "                    tree.append(next_nodes[:beam_size])\n",
    "                \n",
    "                # Find the best path of the tree\n",
    "                best_path = find_best_path(tree)\n",
    "                \n",
    "                # Get the translation\n",
    "                pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
    "                pred_translated = [*filter(lambda word: word not in [\n",
    "                    dest_field.init_token, dest_field.eos_token\n",
    "                ], pred_translated[::-1])]\n",
    "                \n",
    "                # Update hypotheses\n",
    "                hypotheses.append(pred_translated)\n",
    "                \n",
    "                # Update references\n",
    "                references.append([[\n",
    "                    dest_field.vocab.itos[indice] \n",
    "                    for indice in dest_sequence \n",
    "                    if indice not in (\n",
    "                        dest_field.vocab.stoi[dest_field.init_token],\n",
    "                        dest_field.vocab.stoi[dest_field.eos_token],\n",
    "                        dest_field.vocab.stoi[dest_field.pad_token]\n",
    "                    )\n",
    "                ]])\n",
    "                \n",
    "                # Update sources\n",
    "                sources.append([\n",
    "                    src_field.vocab.itos[indice] \n",
    "                    for indice in src_sequence \n",
    "                    if indice not in (\n",
    "                        src_field.vocab.stoi[src_field.init_token],\n",
    "                        src_field.vocab.stoi[src_field.eos_token],\n",
    "                        src_field.vocab.stoi[src_field.pad_token]\n",
    "                    )\n",
    "                ])\n",
    "    \n",
    "        # Calculate BLEU-4 score\n",
    "        assert len(hypotheses) == len(references) == len(sources)\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    \n",
    "    return hypotheses, references, sources, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                          loader=valid_iterator,\n",
    "                          beam_size=1,\n",
    "                          src_field=FR,\n",
    "                          dest_field=EN,\n",
    "                          max_len=MAX_LENGTH,\n",
    "                          device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                          loader=test_iterator,\n",
    "                          beam_size=1,\n",
    "                          src_field=FR,\n",
    "                          dest_field=EN,\n",
    "                          max_len=MAX_LENGTH,\n",
    "                          device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
