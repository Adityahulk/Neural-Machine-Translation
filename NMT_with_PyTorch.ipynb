{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT with PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9Sc0ST76twF",
        "colab_type": "code",
        "outputId": "49271a83-b2d8-4dc5-a9c8-5d5d2f5718dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "!pip install torchtext --upgrade\n",
        "!python -m spacy download fr\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 51kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 61kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.4.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n",
            "Collecting fr_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.1.0/fr_core_news_sm-2.1.0.tar.gz (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 868kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.1.0-cp36-none-any.whl size=13156209 sha256=5d82848ddce77bfa06dd3ce1caf4a4c3db563ab55483b0e0650ee8eb32a1a8de\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sa34auyx/wheels/ab/82/2a/61dd0ff02e22f10eef65a5aa35453a0eb745c84b4c874b612f\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
            "You can now load the model via spacy.load('fr')\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM7QNn0xxCaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Example, Field, Dataset\n",
        "from torchtext.data.iterator import BucketIterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bidq94KZ36Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "SEED = 781\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXBFwfmcA0LY",
        "colab_type": "code",
        "outputId": "0e7e14ec-fdac-4a9a-8430-e59c9d970f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "if not os.path.exists('./data'):\n",
        "    !mkdir ./data\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
        "    -O ./data/fr-en.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-15 13:11:59--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202718517 (193M) [application/x-gzip]\n",
            "Saving to: ‘./data/fr-en.tgz’\n",
            "\n",
            "./data/fr-en.tgz    100%[===================>] 193.33M  4.37MB/s    in 45s     \n",
            "\n",
            "2020-02-15 13:12:44 (4.34 MB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0VvuklFVG-f",
        "colab_type": "code",
        "outputId": "5ce78542-6ebd-487b-a97b-bc802c06b314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!tar -xzvf ./data/fr-en.tgz -C ./data/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "europarl-v7.fr-en.en\n",
            "europarl-v7.fr-en.fr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95zqRUW_BEH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    try:\n",
        "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
        "            content = file.readlines()\n",
        "        return content\n",
        "    except:\n",
        "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwD1a8eHWIB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    # NFD => Normal Form Decompose\n",
        "    # Mn => Non Marking Space\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
        "                    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = re.sub(r'([!.?])', r' \\1', s)\n",
        "    s = re.sub(r'[^a-zA-Z1-9!.?]+', r' ', s)\n",
        "    s = re.sub(r'\\s+', r' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w1KLG09WgPg",
        "colab_type": "code",
        "outputId": "3c2a22e0-2e70-497f-b7ab-9aa3530dac54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%%time\n",
        "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
        "             read_file('./data/europarl-v7.fr-en.en'))]\n",
        "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
        "print('Number of examples:', len(pairs))\n",
        "pairs = np.random.choice(pairs, size=30000, replace=False)\n",
        "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
        "              pairs)]\n",
        "print('Number of examples after sampling:', len(pairs))\n",
        "print('Example:', pairs[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 2007723\n",
            "Number of examples after sampling: 30000\n",
            "Example: {'fr': 'madame le president c est parce que nous ne souhaitons pas pour le maroc ce que nous refusons pour nous memes que nous n avons pas vote l accord d association avec ce grand pays .', 'en': 'madam president it is because we would not wish on morocco something we reject for ourselves that we have not voted for the association agreement with that great country .'}\n",
            "CPU times: user 6.92 s, sys: 504 ms, total: 7.42 s\n",
            "Wall time: 7.43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiIYkYqE5ARI",
        "colab_type": "code",
        "outputId": "926e7226-ff9a-4106-bef1-8e3f48db691a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "%%time\n",
        "FR = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           pad_token='<pad>',\n",
        "           unk_token='<unk>',\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='fr',\n",
        "           preprocessing=lambda x: x[::-1])\n",
        "EN = Field(init_token='<sos>',\n",
        "           eos_token='<eos>',\n",
        "           pad_token='<pad>',\n",
        "           unk_token='<unk>',\n",
        "           lower=True,\n",
        "           tokenize='spacy',\n",
        "           tokenizer_language='en')\n",
        "\n",
        "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
        "                                                'en': ('dest', EN)})\n",
        "            for pair in tqdm.tqdm(pairs)]\n",
        "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
        "train, valid, test = data.split(split_ratio=[0.7, 0.2, 0.1])\n",
        "print('train size:', len(train.examples))\n",
        "print('valid size:', len(valid.examples))\n",
        "print('test size:', len(test.examples))\n",
        "print(vars(train.examples[0]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:44<00:00, 670.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train size: 21000\n",
            "valid size: 3000\n",
            "test size: 6000\n",
            "{'src': ['.', 'fiscale', 'harmonisation', 'l', 'non', 'et', 'fiscale', 'concurrence', 'la', 'promouvoir', 'a', 'interet', 'tout', 'a', 'ue', 'l', 'que', 'fermement', 'crois', 'je'], 'dest': ['i', 'firmly', 'believe', 'that', 'the', 'eu', 'is', 'best', 'served', 'by', 'promoting', 'tax', 'competition', 'not', 'tax', 'harmonisation', '.']}\n",
            "CPU times: user 49.4 s, sys: 268 ms, total: 49.7 s\n",
            "Wall time: 50.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWqpg9Azsp1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FR.build_vocab(train, min_freq=5,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
        "EN.build_vocab(train, min_freq=5,\n",
        "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nig1u2ebMwVz",
        "colab_type": "code",
        "outputId": "3c393971-d152-43e9-99cc-0f6850ceb6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Length of FR vocabulary:', len(FR.vocab))\n",
        "print('Length of EN vocabulary:', len(EN.vocab))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of FR vocabulary: 6820\n",
            "Length of EN vocabulary: 5812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDaNHsaAMxWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_it, valid_it, test_it = BucketIterator.splits((train, valid, test),\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    device=DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17GWbzdnPZ4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedded_dim,\n",
        "                 hidden_units, n_layers, dropout, bi=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bi,\n",
        "                            dropout=dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedded = self.embedding(inputs)\n",
        "        embedded = self.dropout(embedded)\n",
        "        outputs, (h_state, c_state) = self.lstm(embedded)\n",
        "        return outputs, (h_state, c_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_wAlelsKC6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedded_dim,\n",
        "                 hidden_units, n_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=n_layers,\n",
        "                            dropout=dropout)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, h_state, c_state):\n",
        "        embedded = self.embedding(inputs)\n",
        "        embedded = self.dropout(embedded)\n",
        "        outputs, (h_state, c_state) = self.lstm(embedded, (h_state, c_state))\n",
        "        logits = self.linear(outputs)\n",
        "        return logits, (h_state, c_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK1uCzTUMubJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SeqToSeqNet(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(SeqToSeqNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        _, (h_state, c_state) = self.encoder(inputs)\n",
        "        target = targets[0, :]\n",
        "        outputs = []\n",
        "        for t in range(1, targets.size(0)):\n",
        "            logits, (h_state, c_state) = self.decoder(target, h_state, c_state)\n",
        "            outputs.append(logits)\n",
        "            target = targets[t, :]\n",
        "        return torch.stack(outputs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kONXPTzQYHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func():\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRkzCVrnQCB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data_it, optimizer, grad_clip=1.0):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKVDf3QOQpQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_it):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}