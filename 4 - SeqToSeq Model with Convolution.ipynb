{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 - SeqToSeq Model with Convolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORTWt6wmW1Z8c+G2cnyLBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dksifoua/Neural-Machine-Translation/blob/master/4%20-%20SeqToSeq%20Model%20with%20Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft__kT5Lf8kT",
        "outputId": "6b9b37fb-bd88-44cf-9ae7-cb5186344fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 30 00:08:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q_P39ZaVzjI"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ1b-EopVxZw"
      },
      "source": [
        "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
        "!pip install torchtext --upgrade >> /dev/null 2>&1\n",
        "!pip install spacy --upgrade >> /dev/null 2>&1\n",
        "!python -m spacy download de >> /dev/null 2>&1\n",
        "!python -m spacy download en >> /dev/null 2>&1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ijeZ54V2Ku"
      },
      "source": [
        "import tqdm\n",
        "import spacy\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import Multi30k"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYxyc0jDV3za",
        "outputId": "b9ea2c74-90d0-4007-da57-010ca9d26275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTKXlQxZV7ZD"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImPuxpUVV5oE",
        "outputId": "56d9c9b8-af07-4df3-d746-561b97858bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "%%time\n",
        "DE = Field(init_token='<sos>', eos_token='<eos>', lower=True, tokenize='spacy', tokenizer_language='de', batch_first=True)\n",
        "EN = Field(init_token='<sos>', eos_token='<eos>', lower=True, tokenize='spacy', tokenizer_language='en', batch_first=True)\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'),  fields=(DE, EN))\n",
        "print(f'train set size: {len(train_data.examples):,}')\n",
        "print(f'valid set size: {len(valid_data.examples):,}')\n",
        "print(f'test set size: {len(test_data.examples):,}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 29,000\n",
            "valid set size: 1,014\n",
            "test set size: 1,000\n",
            "{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
            "CPU times: user 6.04 s, sys: 170 ms, total: 6.21 s\n",
            "Wall time: 6.21 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh4G_3vKWAIc"
      },
      "source": [
        "## Build vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYYP4wTLV_rq",
        "outputId": "94ae5aa0-6aab-4947-d10c-c3f5bdc22c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "MIN_COUNT = 2\n",
        "DE.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "EN.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "print(f'Length of DE vocabulary: {len(DE.vocab):,}')\n",
        "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of DE vocabulary: 7,854\n",
            "Length of EN vocabulary: 5,893\n",
            "CPU times: user 284 ms, sys: 877 µs, total: 285 ms\n",
            "Wall time: 285 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x_MjNvuWDVv"
      },
      "source": [
        "## Modeling\n",
        "\n",
        "The `scale` variable is used by the authors to *ensure that the variance throughout the network does not change dramatically*. The performance of the model seems to vary wildly using different seeds if this is not used.\n",
        "\n",
        "***Encoder layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xEDqfyWaaHD"
      },
      "source": [
        "class ConvBlockLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_channels, kernel_size, scale, dropout):\n",
        "        super(ConvBlockLayer, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.scale = scale\n",
        "        self.dropout = dropout\n",
        "        self.conv1d = nn.Conv1d(n_channels, n_channels * 2, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "\n",
        "    def forward(self, conv_input):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, n_channels, seq_len] conv_input\n",
        "        :return [batch_size, n_channels, seq_len]\n",
        "        \"\"\"\n",
        "        conved = self.conv1d(conv_input) # [batch_size, n_channels * 2, seq_len]\n",
        "        conved = F.dropout(F.glu(conved, dim=1), p=self.dropout) # [batch_size, n_channels, seq_len]\n",
        "        conved = conv_input + conved # [batch_size, n_channels, seq_len] Residual connection\n",
        "        return conved * self.scale"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbndycItWC21"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, n_positions, embedding_size, hidden_size, kernel_size, scale, n_layers, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_positions = n_positions\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.scale = scale\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.position_embedding = nn.Embedding(n_positions, embedding_size)\n",
        "        self.fc_embedding_hidden = nn.Linear(embedding_size, hidden_size)\n",
        "        self.conv1d_blocks = nn.Sequential(\n",
        "            *[ConvBlockLayer(n_channels=hidden_size, kernel_size=kernel_size, scale=scale, dropout=dropout) for _ in range(n_layers)])\n",
        "        self.fc_hidden_embedding = nn.Linear(hidden_size, embedding_size)\n",
        "\n",
        "    def forward(self, input_sequences, input_positions):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len] input_sequences\n",
        "        :param Tensor[batch_size, seq_len] input_positions\n",
        "        :return Tensor[batch_size, seq_len, embedding_size] conved\n",
        "        :return Tensor[batch_size, seq_len, embedding_size] combined\n",
        "        \"\"\"\n",
        "        seq_embed = self.token_embedding(input_sequences) # [batch_size, seq_len, embedding_size]\n",
        "        pos_embed = self.position_embedding(input_positions) # [batch_size, seq_len, embedding_size]\n",
        "        embed = F.dropout(seq_embed + pos_embed, p=self.dropout) # [batch_size, seq_len, embedding_size]\n",
        "        conv_input = F.dropout(self.fc_embedding_hidden(embed), p=self.dropout) # [batch_size, seq_len, hidden_size]\n",
        "        conv_input = conv_input.permute(0, 2, 1) # [batch_size, hidden_size, seq_len]\n",
        "        conved = self.conv1d_blocks(conv_input) # [batch_size, hidden_size, seq_len]\n",
        "        conved = conved.permute(0, 2, 1) # [batch_size, seq_len, hidden_size]\n",
        "        conved = self.fc_hidden_embedding(conved) # [batch_size, seq_len, embedding_size]\n",
        "        combined = (h_state + embed) * self.scale # [batch_size, seq_len, embedding_size]\n",
        "        return conved, combined"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJABBYSbolaN"
      },
      "source": [
        "***Attention layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyAhP1DEokfO"
      },
      "source": [
        "class MultiStepAttnLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, embedding_size, scale):\n",
        "        super(MultiStepAttnLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.scale = scale\n",
        "        self.fc_hidden_embedding = nn.Linear(hidden_size, embedding_size)\n",
        "    \n",
        "    def forward(self, conved, embed, enc_conved):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_seq_len, hidden_size] conved\n",
        "        :param Tensor[batch_size, dest_seq_len, embedding_size] embed\n",
        "        :param Tensor[batch_size, src_seq_len, embedding_size] enc_conved\n",
        "        :return Tensor[batch_size, dest_seq_len, src_seq_len] attn_weights\n",
        "        \"\"\"\n",
        "        conv_embed = self.fc_hidden_embedding(conved) # [batch_size, dest_seq_len, embedding_size]\n",
        "        combined = (conv_embed + embed) * self.scale # [batch_size, dest_seq_len, embedding_size]\n",
        "        scores = torch.matmul(combined, enc_conved.permute(0, 2, 1)) # [batch_size, dest_seq_len, src_seq_len]\n",
        "        attn_weights = F.softmax(scores, dim=2) # [batch_size, dest_seq_len, src_seq_len]\n",
        "        return attn_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcZ7maHuuSdr"
      },
      "source": [
        "***Decoder layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flEqH4KXuR0w"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, n_positions, embedding_size, hidden_size, kernel_size, scale, n_layers, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_positions = n_positions\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.scale = scale\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.position_embedding = nn.Embedding(n_positions, embedding_size)\n",
        "        self.fc_embedding_hidden = nn.Linear(embedding_size, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}