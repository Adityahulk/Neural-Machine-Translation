{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEd7p3ARFcyr"
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gttqmxRIFSUa",
    "outputId": "a57491fa-3286-4201-9bc3-22e222adc11a"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext --upgrade > /dev/null 2>&1\n",
    "!python -m spacy download fr > /dev/null 2>&1\n",
    "!python -m spacy download en > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-A0mVf7GNix"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0iX1ZuNG0wH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 781\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 27 11:01:21 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2BPfwqcFk4h"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc5EcEA1FnCw"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    !mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "wmajgrxCHwsw",
    "outputId": "abcd63e9-f6f2-4eab-bb4e-72616f57de64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-25 22:47:40--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
      "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
      "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 202718517 (193M) [application/x-gzip]\n",
      "Saving to: ‘./data/fr-en.tgz’\n",
      "\n",
      "./data/fr-en.tgz    100%[===================>] 193.33M   131KB/s    in 25m 59s \n",
      "\n",
      "2020-03-25 23:13:38 (127 KB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
      "\n",
      "CPU times: user 25 s, sys: 7.49 s, total: 32.5 s\n",
      "Wall time: 25min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget --no-check-certificate \\\n",
    "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
    "    -O ./data/fr-en.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "M2r79GZZH7Ip",
    "outputId": "838d4e4c-217d-4c93-afaf-1d4e2a22335d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl-v7.fr-en.en\n",
      "europarl-v7.fr-en.fr\n",
      "CPU times: user 108 ms, sys: 20 ms, total: 128 ms\n",
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!tar -xzvf ./data/fr-en.tgz -C ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tazMbPR6Hnjg"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95Q9N_zBHpTr"
   },
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "        return content\n",
    "    except:\n",
    "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02KzJaPmIjI2"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    # NFD => Normal Form Decompose\n",
    "    # Mn => Non Marking Space\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalize_string(s):\n",
    "    # Transform accented characters into unaccented ones\n",
    "    s = unicode_to_ascii(s.strip())\n",
    "    # Remove a sequence of whitespace characters\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "wlJtKDpMJF-1",
    "outputId": "27290cb2-4a77-4200-b790-819142f587c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2,007,723\n",
      "CPU times: user 3.15 s, sys: 1.14 s, total: 4.29 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
    "              read_file('./data/europarl-v7.fr-en.en'))]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not build models the entire dataset, since is very large. Instead, I sample a subset of 30,000 sentence pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after sampling: 30,000\n",
      "Example:\n",
      "\tFR => Les procedures par le biais desquelles de tels produits entrent et sortent de l'Union europeenne doivent etre ouvertes, transparentes et, par dessus tout, sures.\n",
      "\tEN => The procedures whereby such products come in and out of the European Union have to be open, transparent and, above all, safe.\n",
      "CPU times: user 4.22 s, sys: 80 ms, total: 4.3 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = np.random.choice(pairs, size=30000, replace=False)\n",
    "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
    "              pairs)]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I build the train/valid/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "BAq2uyDyJ6KD",
    "outputId": "64369eb2-8c31-44bf-ecbb-abb0de8122d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:57<00:00, 523.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 572 ms, total: 1min 2s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           preprocessing=lambda x: x[::-1],\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True) # For pack_padded_sequence\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en')\n",
    "\n",
    "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
    "                                                'en': ('dest', EN)})\n",
    "            for pair in tqdm.tqdm(pairs)]\n",
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 27000\n",
      "valid size: 1500\n",
      "test size: 1500\n",
      "{'src': ['.', 'europeenne', 'communaute', 'la', 'de', 'niveau', 'au', 'micro-gestion', 'une', 'a', 'proceder', 'de', 'tentation', 'la', 'a', 'resister', 'de', 'que', 'ainsi', ',', 'terrain', 'de', 'acteurs', 'les', 'par', 'fournies', 'etre', 'peuvent', 'qui', 'competences', 'des', 'et', 'connaissances', 'des', 'ampleur', \"l'\", 'reconnaitre', 'de', 'important', 'est', 'il', 'et', ',', 'propre', 'specificite', 'sa', 'possede', 'europeennes', 'mers', 'des', 'chacune'], 'dest': ['each', 'of', 'the', 'seas', 'in', 'europe', 'has', 'its', 'own', 'specificity', ',', 'and', 'it', 'is', 'important', 'to', 'recognise', 'the', 'level', 'of', 'knowledge', 'and', 'expertise', 'that', 'can', 'be', 'provided', 'by', 'the', 'stakeholders', 'on', 'the', 'ground', 'and', 'to', 'resist', 'the', 'temptation', 'to', 'micro', '-', 'manage', 'on', 'an', 'eu', 'level', '.']}\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.split(split_ratio=[0.9, 0.05, 0.05])\n",
    "print(f'train size: {len(train_data.examples)}')\n",
    "print(f'valid size: {len(valid_data.examples)}')\n",
    "print(f'test size: {len(test_data.examples)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model understands only number, we need to transform text sequences into sequence of numbers where each numbers represents an unique word. To do this, we build a vocabulary for each language that map words to indexes and vice versa. the vocabulary id built from train set only in order to prevent data leakage. We also add some special tokens:\n",
    "- `<sos>`: for start of sentence.\n",
    "- `<unk>`: for unknown or less frequent words.\n",
    "- `<eos>`: for end of sentence. \n",
    "- `<pad>`: for padding (make all sentences in a batch the same size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "JycVMjsRLmoB",
    "outputId": "1e833ee2-cf9e-47e2-fc21-1b06f9be07f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 14508\n",
      "Length of EN vocabulary: 11499\n",
      "CPU times: user 480 ms, sys: 0 ns, total: 480 ms\n",
      "Wall time: 480 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=2,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=2,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab)}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKKRGB9cIbn8"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "We used a neural and probabilistic framework to generate english translations of french sentences. The goal is to maximizing the likelihood of a generated english translate given a french sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yT-6GZgfMXIu"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "The part of model map th source sequence to hidden vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJL7MVwAMVtR"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
    "                 n_layers=1, dropout=0, bidirectional=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(dropout if n_layers > 1 else 0),\n",
    "                            bidirectional=bidirectional)\n",
    "    \n",
    "    def forward(self, in_, seq_len):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (seq_len, batch_size)\n",
    "            seq_len: (batch_size)\n",
    "\n",
    "        outputs\n",
    "            out: (seq_len, batch_size, num_directions * hidden_size)\n",
    "            hn: (num_layers * num_directions, batch_size, hidden_size)\n",
    "            cn: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(in_)\n",
    "        embedded = self.dropout(embedded)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, seq_len)\n",
    "        out, (hn, cn) = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out)\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cFeoEJpMYgE"
   },
   "source": [
    "## Decoder\n",
    "\n",
    "The part of model performs language modeling given the hidden vector outputs by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deAfHkCcIdzj"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
    "                 n_layers=1, dropout=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(dropout if n_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, in_, h0, c0):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (1, batch_size) => seq_len = 1, a word\n",
    "            h0: (num_layers, batch_size, hidden_size)\n",
    "            c0: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        embed = self.embedding(_in) \n",
    "        # embedded: (1, batch_size, embed_size)\n",
    "        out, hn, cn = self.lstm(embedded)\n",
    "        # out: (1, batch_size, hidden_size)\n",
    "        # hn: (num_layers, batch_size, hidden_size)\n",
    "        # cn: (num_layers, batch_size, hidden_size)\n",
    "        logit = self.fc(out.squeeze(0))\n",
    "        # logit: (batch_size, vocab_size)\n",
    "\n",
    "        outputs: logit, hn, cn\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(in_)\n",
    "        embedded = self.dropout(embedded)\n",
    "        out, (hn, cn) = self.lstm(embedded, (h0, c0))\n",
    "        logit = self.fc(out.squeeze(0))\n",
    "        return logit, hn, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZwOJLkTMbCt"
   },
   "source": [
    "## Sequence to sequence model\n",
    "\n",
    "This puts encoder and decoder together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5Wd0iNaMgp1"
   },
   "outputs": [],
   "source": [
    "class SeqToSeqNet(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device=device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "        'Encoder and Decoder have to have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "        'Encoder and Decoder have to have the same number of reccurent hidden units'\n",
    "\n",
    "        super(SeqToSeqNet, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def encode(self, in_, seq_len):\n",
    "        _, hn, cn = self.encoder(in_, seq_len)\n",
    "        # Sum the two directional encoder hn state\n",
    "        if self.encoder.bidirectional:\n",
    "            hn = hn[:self.encoder.n_layers, :, :] + \\\n",
    "                    hn[self.encoder.n_layers:, :, :]\n",
    "            cn = cn[:self.encoder.n_layers, :, :] + \\\n",
    "                    cn[self.encoder.n_layers:, :, :]\n",
    "        return hn, cn\n",
    "\n",
    "    def decode(self, h_state, c_state, target, sos_index, teacher_forcing, ratio):\n",
    "        target_len, batch_size = target.size()\n",
    "        out = torch.zeros((target_len, batch_size, self.decoder.vocab_size),\n",
    "                           device=self.device)\n",
    "        in_ = target[0, :].unsqueeze(0)\n",
    "        for t in range(1, target_len):\n",
    "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
    "            out[t] = logit # (batch_size, vocab_size)\n",
    "            if teacher_forcing and random.random() < ratio:\n",
    "                in_ = logit.argmax(1).unsqueeze(0) # (1, batch_size)\n",
    "            else:\n",
    "                in_ = target[t, :].unsqueeze(0)\n",
    "        return out\n",
    "\n",
    "    def forward(self, in_, seq_len, target, sos_index,\n",
    "                teacher_forcing=True, ratio=.5):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (seq_len, batch_size)\n",
    "            seq_len: (batch_size)\n",
    "            target: (seq_len, batch_size)\n",
    "            sos_index: int\n",
    "            eos_index: int\n",
    "\n",
    "        outputs\n",
    "            out: (seq_len, batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        hn, cn = self.encode(in_, seq_len)\n",
    "        out = self.decode(hn, cn, target, sos_index, teacher_forcing, ratio)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCLUmCfFMjGV"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_aldUUdZ5dv"
   },
   "outputs": [],
   "source": [
    "def init_weights(model: nn.Module):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, a=-0.08, b=0.08)\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1teOdv5q7ns"
   },
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    grad_mean, layers = [], []\n",
    "    for name, param in named_parameters:\n",
    "        if param.requires_grad and 'bias' not in name:\n",
    "            layers.append(name)\n",
    "            grad_mean.append(param.grad.abs().mean())\n",
    "    plt.plot(grad_mean, alpha=0.3, color='b')\n",
    "    plt.hlines(0, 0, len(grad_mean) + 1, linewidth=1, color='k' )\n",
    "    plt.xticks(range(0, len(grad_mean), 1), layers, rotation='vertical')\n",
    "    plt.xlim(xmin=0, xmax=len(grad_mean))\n",
    "    # plt.ylim(bottom=-0.001, top=0.02) # Zoom on lower gradients\n",
    "    plt.xlabel('Layers')\n",
    "    plt.ylabel('Mean of gradients')\n",
    "    plt.title('Gradient Flow')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8QgblulqoWT"
   },
   "outputs": [],
   "source": [
    "def train_step(model, opt, loss_func, data_it, grad_clip, sos_index,\n",
    "               epoch_text=''):\n",
    "    epoch_loss = 0.\n",
    "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
    "    model.train()\n",
    "    for i, data in pbar:\n",
    "        opt.zero_grad()\n",
    "        logits = model(*data.src, data.dest, sos_index)\n",
    "        # *data.src: unpack in_ and seq_len\n",
    "        loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
    "                         data.dest[1:].view(-1))\n",
    "        loss.backward()\n",
    "        # plot_grad_flow(model.named_parameters())\n",
    "        if grad_clip:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(epoch_text + f'Train Loss: {epoch_loss/(i+1):.3f}')\n",
    "    # plt.show() # Show the gradient flow\n",
    "    return epoch_loss / len(data_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYND0IGKrdJu"
   },
   "outputs": [],
   "source": [
    "def valid_step(model, loss_func, data_it, sos_index, epoch_text=''):\n",
    "    epoch_loss = 0.\n",
    "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in pbar:\n",
    "            logits = model(*data.src, data.dest, sos_index,\n",
    "                           teacher_forcing=False)\n",
    "            loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
    "                             data.dest[1:].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_description(epoch_text + f'Valid Loss: {epoch_loss/(i+1):.3f}')\n",
    "    return epoch_loss / len(data_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECEXh0oHwSFN"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, train_it, valid_it, n_epochs, sos_index,\n",
    "          grad_clip=None, save_to='./saved_models', filename='seq2seq-baseline.pt'):\n",
    "    assert callable(loss_function)\n",
    "    if not os.path.exists(save_to):\n",
    "        !mkdir {save_to}\n",
    "\n",
    "    history = {'loss': [], 'val_loss': []}\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_text = f'Epoch: {epoch + 1:02d} - '\n",
    "        loss = train_step(model, optimizer, loss_function, train_it, grad_clip,\n",
    "                          sos_index, epoch_text)\n",
    "        val_loss = valid_step(model, loss_function, valid_it, sos_index,\n",
    "                              epoch_text)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict()},\n",
    "                       f=os.path.join(save_to, filename))\n",
    "\n",
    "        history['loss'].append(loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZV_iUlh3CWo"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "LR = 1e-3\n",
    "GRAD_CLIP = 1.0\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 30\n",
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBekgFKP3C3S"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data,\n",
    "                               test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True, # For pack_padded_sequence\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aCWVfRdAxY6N",
    "outputId": "1d3a0be8-26c7-404c-ba6c-b1722e7d871d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 27,103,199\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embed_size=EMBEDDING_DIM,\n",
    "                  vocab_size=len(FR.vocab),\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT).to(device)\n",
    "decoder = Decoder(embed_size=EMBEDDING_DIM,\n",
    "                  vocab_size=len(EN.vocab),\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT).to(device)\n",
    "seq2seq = SeqToSeqNet(encoder=encoder, decoder=decoder).to(device)\n",
    "seq2seq.apply(init_weights)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=EN.vocab.stoi[EN.pad_token])\n",
    "print(f'Number of parameters of the model: {count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R22m0tls06BS",
    "outputId": "d6f9779c-82ff-4e0b-9a4b-e8fdffe98111"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 01 - Train Loss: 6.112: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 01 - Valid Loss: 5.648: 100%|██████████| 12/12 [00:00<00:00, 18.30it/s]\n",
      "Epoch: 02 - Train Loss: 5.691: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 02 - Valid Loss: 5.166: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 03 - Train Loss: 5.429: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 03 - Valid Loss: 4.903: 100%|██████████| 12/12 [00:00<00:00, 18.33it/s]\n",
      "Epoch: 04 - Train Loss: 5.245: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 04 - Valid Loss: 4.736: 100%|██████████| 12/12 [00:00<00:00, 18.39it/s]\n",
      "Epoch: 05 - Train Loss: 5.086: 100%|██████████| 211/211 [00:55<00:00,  3.84it/s]\n",
      "Epoch: 05 - Valid Loss: 4.601: 100%|██████████| 12/12 [00:00<00:00, 18.56it/s]\n",
      "Epoch: 06 - Train Loss: 4.969: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 06 - Valid Loss: 4.510: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 07 - Train Loss: 4.825: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 07 - Valid Loss: 4.418: 100%|██████████| 12/12 [00:00<00:00, 18.49it/s]\n",
      "Epoch: 08 - Train Loss: 4.714: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 08 - Valid Loss: 4.342: 100%|██████████| 12/12 [00:00<00:00, 18.67it/s]\n",
      "Epoch: 09 - Train Loss: 4.615: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 09 - Valid Loss: 4.294: 100%|██████████| 12/12 [00:00<00:00, 18.60it/s]\n",
      "Epoch: 10 - Train Loss: 4.533: 100%|██████████| 211/211 [00:55<00:00,  3.81it/s]\n",
      "Epoch: 10 - Valid Loss: 4.237: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 11 - Train Loss: 4.434: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 11 - Valid Loss: 4.188: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 12 - Train Loss: 4.330: 100%|██████████| 211/211 [00:54<00:00,  3.88it/s]\n",
      "Epoch: 12 - Valid Loss: 4.156: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 13 - Train Loss: 4.271: 100%|██████████| 211/211 [00:54<00:00,  3.89it/s]\n",
      "Epoch: 13 - Valid Loss: 4.133: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 14 - Train Loss: 4.175: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 14 - Valid Loss: 4.131: 100%|██████████| 12/12 [00:00<00:00, 18.59it/s]\n",
      "Epoch: 15 - Train Loss: 4.095: 100%|██████████| 211/211 [00:54<00:00,  3.85it/s]\n",
      "Epoch: 15 - Valid Loss: 4.093: 100%|██████████| 12/12 [00:00<00:00, 18.40it/s]\n",
      "Epoch: 16 - Train Loss: 4.004: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 16 - Valid Loss: 4.085: 100%|██████████| 12/12 [00:00<00:00, 18.40it/s]\n",
      "Epoch: 17 - Train Loss: 3.922: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 17 - Valid Loss: 4.085: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 18 - Train Loss: 3.839: 100%|██████████| 211/211 [00:55<00:00,  3.84it/s]\n",
      "Epoch: 18 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 19 - Train Loss: 3.765: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 19 - Valid Loss: 4.056: 100%|██████████| 12/12 [00:00<00:00, 18.45it/s]\n",
      "Epoch: 20 - Train Loss: 3.696: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 20 - Valid Loss: 4.065: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 21 - Train Loss: 3.637: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 21 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 22 - Train Loss: 3.571: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 22 - Valid Loss: 4.051: 100%|██████████| 12/12 [00:00<00:00, 18.44it/s]\n",
      "Epoch: 23 - Train Loss: 3.481: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 23 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.31it/s]\n",
      "Epoch: 24 - Train Loss: 3.440: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 24 - Valid Loss: 4.072: 100%|██████████| 12/12 [00:00<00:00, 18.42it/s]\n",
      "Epoch: 25 - Train Loss: 3.364: 100%|██████████| 211/211 [00:54<00:00,  3.85it/s]\n",
      "Epoch: 25 - Valid Loss: 4.072: 100%|██████████| 12/12 [00:00<00:00, 18.58it/s]\n",
      "Epoch: 26 - Train Loss: 3.312: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 26 - Valid Loss: 4.077: 100%|██████████| 12/12 [00:00<00:00, 18.49it/s]\n",
      "Epoch: 27 - Train Loss: 3.264: 100%|██████████| 211/211 [00:55<00:00,  3.83it/s]\n",
      "Epoch: 27 - Valid Loss: 4.087: 100%|██████████| 12/12 [00:00<00:00, 18.39it/s]\n",
      "Epoch: 28 - Train Loss: 3.212: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 28 - Valid Loss: 4.095: 100%|██████████| 12/12 [00:00<00:00, 18.66it/s]\n",
      "Epoch: 29 - Train Loss: 3.150: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 29 - Valid Loss: 4.112: 100%|██████████| 12/12 [00:00<00:00, 18.42it/s]\n",
      "Epoch: 30 - Train Loss: 3.082: 100%|██████████| 211/211 [00:54<00:00,  3.89it/s]\n",
      "Epoch: 30 - Valid Loss: 4.126: 100%|██████████| 12/12 [00:00<00:00, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 7s, sys: 2min 49s, total: 27min 57s\n",
      "Wall time: 28min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train(seq2seq, optimizer, criterion, train_iterator, valid_iterator,\n",
    "                sos_index=EN.vocab.stoi[EN.init_token],\n",
    "                n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "PQ_klP1-6XyF",
    "outputId": "594ec77b-331d-4a6e-87eb-3da5088583a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='valid')\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DxDV_RX866Hp",
    "outputId": "6448b84f-af1d-4bc1-e7c7-7dc8cebaaae2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loss => Valid Loss: 4.082: 100%|██████████| 12/12 [00:00<00:00, 13.56it/s]\n"
     ]
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('./saved_models/seq2seq-baseline.pt').get('model'))\n",
    "test_loss = valid_step(seq2seq, criterion, test_iterator,\n",
    "                       sos_index=EN.vocab.stoi[EN.init_token],\n",
    "                       epoch_text='Test loss => ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kC8tYcPCLgz5"
   },
   "source": [
    "# Inference & BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "bCe-iET5mwf3",
    "outputId": "1d3ff501-f297-478b-f0a2-32e5957f637b"
   },
   "outputs": [],
   "source": [
    "class InferenceAlgo:\n",
    "    \"\"\"\n",
    "    Inference algorithms\n",
    "    \"\"\"\n",
    "    GREEDY = 'GREEDY'\n",
    "    SAMPLING = 'SAMPLING'\n",
    "    BEAM_SEARCH = 'BEAM_SEARCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \n",
    "    def __init__(self, model, src_field, dest_field, device=device):\n",
    "        self.model = model\n",
    "        self.src_field = src_field\n",
    "        self.dest_field = dest_field\n",
    "        self.device = device\n",
    "        \n",
    "    def greedy_search(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def sampling(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def beam_search(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def translate(self, data_it, max_len, algo):\n",
    "        translated_sequences = []\n",
    "        pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in pbar:\n",
    "                h_state, c_state = self.model.encoder(*data.src)\n",
    "                if algo == InferenceAlgo.GREEDY:\n",
    "                    batch_translated_sequences = self.greedy_search(h_state, c_state, max_len)\n",
    "                elif algo == InferenceAlgo.SAMPLING:\n",
    "                    batch_translated_sequences = self.sampling(h_state, c_state, max_len)\n",
    "                elif algo == InferenceAlgo.BEAM_SEARCH:\n",
    "                    batch_translated_sequences = self.sampling(h_state, c_state, max_len)\n",
    "                else:\n",
    "                    raise('Not implemented inference algo!')\n",
    "                translated_sequences.append(batch_translated_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "RdRIlUJjLeDj",
    "outputId": "97427a7c-8638-45cf-b7fd-a4a1f63b3cd4"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# references = []\n",
    "# targets_with_sample = []\n",
    "# targets_without_sample  = []\n",
    "# seq2seq.eval()\n",
    "# with torch.no_grad():\n",
    "#     for i, example in enumerate(test_data.examples):\n",
    "#         in_ = torch.tensor([FR.vocab.stoi[token]\n",
    "#                             for token in example.src],\n",
    "#                         dtype=torch.int64, device=device).unsqueeze(1)\n",
    "#         if in_.size(0) == 0:\n",
    "#             print(f'skipped example {i}!')\n",
    "#             continue\n",
    "#         seq_len = torch.tensor([in_.size(0)], dtype=torch.int64, device=device)\n",
    "#         with_ = seq2seq.inference(in_, seq_len, EN.vocab.stoi[EN.init_token],\n",
    "#                                   EN.vocab.stoi[EN.eos_token], MAX_LEN)\n",
    "#         without = seq2seq.inference(in_, seq_len,  EN.vocab.stoi[EN.init_token],\n",
    "#                                     EN.vocab.stoi[EN.eos_token], MAX_LEN, False)\n",
    "#         targets_with_sample.append([EN.vocab.itos[int(idx)] for idx in with_[0]])\n",
    "#         targets_without_sample.append([EN.vocab.itos[int(idx)] for idx in without[0]])\n",
    "#         references.append([example.dest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yTolzzQaoAGd",
    "outputId": "aab5bd3b-b676-4d19-a4e5-e3fd153d5eec"
   },
   "outputs": [],
   "source": [
    "# print(f'BLEU score with sampling: {bleu_score(targets_with_sample, references)}')\n",
    "# print(f'BLEU score without sampling: {bleu_score(targets_without_sample, references)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "JV-mzrtbp_mp",
    "outputId": "fbbb9970-0adb-4d4f-b126-f16868147421"
   },
   "outputs": [],
   "source": [
    "# idx = 1\n",
    "# print(' '.join(references[idx][0]))\n",
    "# print('================================')\n",
    "# print(' '.join(targets_with_sample[idx]))\n",
    "# print('================================')\n",
    "# print(' '.join(targets_without_sample[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hzyFn-Vqn3S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wEd7p3ARFcyr",
    "v2BPfwqcFk4h",
    "tazMbPR6Hnjg",
    "yT-6GZgfMXIu",
    "7cFeoEJpMYgE",
    "2ZwOJLkTMbCt"
   ],
   "name": "1 - Sequence to Sequence Model with RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
