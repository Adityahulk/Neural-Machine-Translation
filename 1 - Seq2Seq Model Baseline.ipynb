{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEd7p3ARFcyr"
   },
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gttqmxRIFSUa",
    "outputId": "a57491fa-3286-4201-9bc3-22e222adc11a"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext --upgrade > /dev/null 2>&1\n",
    "!python -m spacy download fr > /dev/null 2>&1\n",
    "!python -m spacy download en > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-A0mVf7GNix"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import random\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0iX1ZuNG0wH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 781\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2BPfwqcFk4h"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc5EcEA1FnCw"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./data'):\n",
    "    !mkdir ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "wmajgrxCHwsw",
    "outputId": "abcd63e9-f6f2-4eab-bb4e-72616f57de64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-25 22:47:40--  http://www.statmt.org/europarl/v7/fr-en.tgz\n",
      "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
      "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 202718517 (193M) [application/x-gzip]\n",
      "Saving to: ‘./data/fr-en.tgz’\n",
      "\n",
      "./data/fr-en.tgz    100%[===================>] 193.33M   131KB/s    in 25m 59s \n",
      "\n",
      "2020-03-25 23:13:38 (127 KB/s) - ‘./data/fr-en.tgz’ saved [202718517/202718517]\n",
      "\n",
      "CPU times: user 25 s, sys: 7.49 s, total: 32.5 s\n",
      "Wall time: 25min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!wget --no-check-certificate \\\n",
    "    http://www.statmt.org/europarl/v7/fr-en.tgz \\\n",
    "    -O ./data/fr-en.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "M2r79GZZH7Ip",
    "outputId": "838d4e4c-217d-4c93-afaf-1d4e2a22335d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl-v7.fr-en.en\n",
      "europarl-v7.fr-en.fr\n",
      "CPU times: user 108 ms, sys: 20 ms, total: 128 ms\n",
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!tar -xzvf ./data/fr-en.tgz -C ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tazMbPR6Hnjg"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "95Q9N_zBHpTr"
   },
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, mode='rt', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "        return content\n",
    "    except:\n",
    "        raise NotImplementedError(f'File {filepath} doesn\\'t exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02KzJaPmIjI2"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    # NFD => Normal Form Decompose\n",
    "    # Mn => Non Marking Space\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) \\\n",
    "                    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalize_string(s):\n",
    "    # Transform accented characters into unaccented ones\n",
    "    s = unicode_to_ascii(s.strip())\n",
    "    # Remove a sequence of whitespace characters\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "wlJtKDpMJF-1",
    "outputId": "27290cb2-4a77-4200-b790-819142f587c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2,007,723\n",
      "CPU times: user 3.22 s, sys: 1.08 s, total: 4.3 s\n",
      "Wall time: 7.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = [*zip(read_file('./data/europarl-v7.fr-en.fr'),\n",
    "              read_file('./data/europarl-v7.fr-en.en'))]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not build models the entire dataset, since is very large. Instead, I sample a subset of 30,000 sentence pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after sampling: 30,000\n",
      "Example:\n",
      "\tFR => Les procedures par le biais desquelles de tels produits entrent et sortent de l'Union europeenne doivent etre ouvertes, transparentes et, par dessus tout, sures.\n",
      "\tEN => The procedures whereby such products come in and out of the European Union have to be open, transparent and, above all, safe.\n",
      "CPU times: user 4.25 s, sys: 88 ms, total: 4.34 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = np.random.choice(pairs, size=30000, replace=False)\n",
    "pairs = [*map(lambda pair: {k: normalize_string(v) for k, v in pair.items()},\n",
    "              pairs)]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I build the train/valid/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "BAq2uyDyJ6KD",
    "outputId": "64369eb2-8c31-44bf-ecbb-abb0de8122d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:58<00:00, 513.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 488 ms, total: 1min 3s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           preprocessing=lambda x: x[::-1],\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True) # For pack_padded_sequence\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en')\n",
    "\n",
    "examples = [Example.fromdict(data=pair, fields={'fr': ('src', FR),\n",
    "                                                'en': ('dest', EN)})\n",
    "            for pair in tqdm.tqdm(pairs)]\n",
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 27000\n",
      "valid size: 1500\n",
      "test size: 1500\n",
      "{'src': ['.', 'europeenne', 'communaute', 'la', 'de', 'niveau', 'au', 'micro-gestion', 'une', 'a', 'proceder', 'de', 'tentation', 'la', 'a', 'resister', 'de', 'que', 'ainsi', ',', 'terrain', 'de', 'acteurs', 'les', 'par', 'fournies', 'etre', 'peuvent', 'qui', 'competences', 'des', 'et', 'connaissances', 'des', 'ampleur', \"l'\", 'reconnaitre', 'de', 'important', 'est', 'il', 'et', ',', 'propre', 'specificite', 'sa', 'possede', 'europeennes', 'mers', 'des', 'chacune'], 'dest': ['each', 'of', 'the', 'seas', 'in', 'europe', 'has', 'its', 'own', 'specificity', ',', 'and', 'it', 'is', 'important', 'to', 'recognise', 'the', 'level', 'of', 'knowledge', 'and', 'expertise', 'that', 'can', 'be', 'provided', 'by', 'the', 'stakeholders', 'on', 'the', 'ground', 'and', 'to', 'resist', 'the', 'temptation', 'to', 'micro', '-', 'manage', 'on', 'an', 'eu', 'level', '.']}\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data.split(split_ratio=[0.9, 0.05, 0.05])\n",
    "print(f'train size: {len(train_data.examples)}')\n",
    "print(f'valid size: {len(valid_data.examples)}')\n",
    "print(f'test size: {len(test_data.examples)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model understands only number, we need to transform text sequences into sequence of numbers where each numbers represents an unique word. To do this, we build a vocabulary for each language that map words to indexes and vice versa. the vocabulary id built from train set only in order to prevent data leakage. We also add some special tokens:\n",
    "- `<sos>`: for start of sentence.\n",
    "- `<unk>`: for unknown or less frequent words.\n",
    "- `<eos>`: for end of sentence. \n",
    "- `<pad>`: for padding (make all sentences in a batch the same size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "JycVMjsRLmoB",
    "outputId": "1e833ee2-cf9e-47e2-fc21-1b06f9be07f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 14508\n",
      "Length of EN vocabulary: 11499\n",
      "CPU times: user 488 ms, sys: 0 ns, total: 488 ms\n",
      "Wall time: 487 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=2,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=2,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab)}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKKRGB9cIbn8"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "We used a neural and probabilistic framework to generate english translations of french sentences. The goal is to maximizing the likelihood of a generated english translate given a french sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yT-6GZgfMXIu"
   },
   "source": [
    "## Encoder\n",
    "\n",
    "The part of model map th source sequence to hidden vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJL7MVwAMVtR"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
    "                 n_layers=1, dropout=0, bidirectional=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(dropout if n_layers > 1 else 0),\n",
    "                            bidirectional=bidirectional)\n",
    "    \n",
    "    def forward(self, in_, seq_len):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (seq_len, batch_size)\n",
    "            seq_len: (batch_size)\n",
    "\n",
    "        outputs\n",
    "            out: (seq_len, batch_size, num_directions * hidden_size)\n",
    "            hn: (num_layers * num_directions, batch_size, hidden_size)\n",
    "            cn: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(in_)\n",
    "        embedded = self.dropout(embedded)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, seq_len)\n",
    "        out, (hn, cn) = self.lstm(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out)\n",
    "        return out, hn, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cFeoEJpMYgE"
   },
   "source": [
    "## Decoder\n",
    "\n",
    "The part of model performs language modeling given the hidden vector outputs by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deAfHkCcIdzj"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, vocab_size, hidden_size,\n",
    "                 n_layers=1, dropout=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(dropout if n_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, in_, h0, c0):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (1, batch_size) => seq_len = 1, a word\n",
    "            h0: (num_layers, batch_size, hidden_size)\n",
    "            c0: (num_layers, batch_size, hidden_size)\n",
    "\n",
    "        embed = self.embedding(_in) \n",
    "        # embedded: (1, batch_size, embed_size)\n",
    "        out, hn, cn = self.lstm(embedded)\n",
    "        # out: (1, batch_size, hidden_size)\n",
    "        # hn: (num_layers, batch_size, hidden_size)\n",
    "        # cn: (num_layers, batch_size, hidden_size)\n",
    "        logit = self.fc(out.squeeze(0))\n",
    "        # logit: (batch_size, vocab_size)\n",
    "\n",
    "        outputs: logit, hn, cn\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(in_)\n",
    "        embedded = self.dropout(embedded)\n",
    "        out, (hn, cn) = self.lstm(embedded, (h0, c0))\n",
    "        logit = self.fc(out.squeeze(0))\n",
    "        return logit, hn, cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZwOJLkTMbCt"
   },
   "source": [
    "## Sequence to sequence model\n",
    "\n",
    "This puts encoder and decoder together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5Wd0iNaMgp1"
   },
   "outputs": [],
   "source": [
    "class SeqToSeqNet(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device=device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "        'Encoder and Decoder have to have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "        'Encoder and Decoder have to have the same number of reccurent hidden units'\n",
    "\n",
    "        super(SeqToSeqNet, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def encode(self, in_, seq_len):\n",
    "        _, hn, cn = self.encoder(in_, seq_len)\n",
    "        # Sum the two directional encoder hn state\n",
    "        if self.encoder.bidirectional:\n",
    "            hn = hn[:self.encoder.n_layers, :, :] + \\\n",
    "                    hn[self.encoder.n_layers:, :, :]\n",
    "            cn = cn[:self.encoder.n_layers, :, :] + \\\n",
    "                    cn[self.encoder.n_layers:, :, :]\n",
    "        return hn, cn\n",
    "\n",
    "    def decode(self, h_state, c_state, target, sos_index, teacher_forcing, ratio):\n",
    "        target_len, batch_size = target.size()\n",
    "        out = torch.zeros((target_len, batch_size, self.decoder.vocab_size),\n",
    "                           device=self.device)\n",
    "        in_ = target[0, :].unsqueeze(0)\n",
    "        for t in range(1, target_len):\n",
    "            logit, h_state, c_state = self.decoder(in_, h_state, c_state)\n",
    "            out[t] = logit # (batch_size, vocab_size)\n",
    "            if teacher_forcing and random.random() < ratio:\n",
    "                in_ = logit.argmax(1).unsqueeze(0) # (1, batch_size)\n",
    "            else:\n",
    "                in_ = target[t, :].unsqueeze(0)\n",
    "        return out\n",
    "\n",
    "    def forward(self, in_, seq_len, target, sos_index,\n",
    "                teacher_forcing=True, ratio=.5):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "            in_: (seq_len, batch_size)\n",
    "            seq_len: (batch_size)\n",
    "            target: (seq_len, batch_size)\n",
    "            sos_index: int\n",
    "            eos_index: int\n",
    "\n",
    "        outputs\n",
    "            out: (seq_len, batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        hn, cn = self.encode(in_, seq_len)\n",
    "        out = self.decode(hn, cn, target, sos_index, teacher_forcing, ratio)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCLUmCfFMjGV"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_aldUUdZ5dv"
   },
   "outputs": [],
   "source": [
    "def init_weights(model: nn.Module):\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.uniform_(param.data, a=-0.08, b=0.08)\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1teOdv5q7ns"
   },
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    grad_mean, layers = [], []\n",
    "    for name, param in named_parameters:\n",
    "        if param.requires_grad and 'bias' not in name:\n",
    "            layers.append(name)\n",
    "            grad_mean.append(param.grad.abs().mean())\n",
    "    plt.plot(grad_mean, alpha=0.3, color='b')\n",
    "    plt.hlines(0, 0, len(grad_mean) + 1, linewidth=1, color='k' )\n",
    "    plt.xticks(range(0, len(grad_mean), 1), layers, rotation='vertical')\n",
    "    plt.xlim(xmin=0, xmax=len(grad_mean))\n",
    "    # plt.ylim(bottom=-0.001, top=0.02) # Zoom on lower gradients\n",
    "    plt.xlabel('Layers')\n",
    "    plt.ylabel('Mean of gradients')\n",
    "    plt.title('Gradient Flow')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8QgblulqoWT"
   },
   "outputs": [],
   "source": [
    "def train_step(model, opt, loss_func, data_it, grad_clip, sos_index,\n",
    "               epoch_text=''):\n",
    "    epoch_loss = 0.\n",
    "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
    "    model.train()\n",
    "    for i, data in pbar:\n",
    "        opt.zero_grad()\n",
    "        logits = model(*data.src, data.dest, sos_index)\n",
    "        # *data.src: unpack in_ and seq_len\n",
    "        loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
    "                         data.dest[1:].view(-1))\n",
    "        loss.backward()\n",
    "        # plot_grad_flow(model.named_parameters())\n",
    "        if grad_clip:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_description(epoch_text + f'Train Loss: {epoch_loss/(i+1):.3f}')\n",
    "    # plt.show() # Show the gradient flow\n",
    "    return epoch_loss / len(data_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYND0IGKrdJu"
   },
   "outputs": [],
   "source": [
    "def valid_step(model, loss_func, data_it, sos_index, epoch_text=''):\n",
    "    epoch_loss = 0.\n",
    "    pbar = tqdm.tqdm(enumerate(data_it), total=len(data_it))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in pbar:\n",
    "            logits = model(*data.src, data.dest, sos_index,\n",
    "                           teacher_forcing=False)\n",
    "            loss = loss_func(logits[1:].view(-1, logits.size(-1)),\n",
    "                             data.dest[1:].view(-1))\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_description(epoch_text + f'Valid Loss: {epoch_loss/(i+1):.3f}')\n",
    "    return epoch_loss / len(data_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECEXh0oHwSFN"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_function, train_it, valid_it, n_epochs, sos_index,\n",
    "          grad_clip=None, save_to='./saved_models', filename='seq2seq-baseline.pt'):\n",
    "    assert callable(loss_function)\n",
    "    if not os.path.exists(save_to):\n",
    "        !mkdir {save_to}\n",
    "\n",
    "    history = {'loss': [], 'val_loss': []}\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_text = f'Epoch: {epoch + 1:02d} - '\n",
    "        loss = train_step(model, optimizer, loss_function, train_it, grad_clip,\n",
    "                          sos_index, epoch_text)\n",
    "        val_loss = valid_step(model, loss_function, valid_it, sos_index,\n",
    "                              epoch_text)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict()},\n",
    "                       f=os.path.join(save_to, filename))\n",
    "\n",
    "        history['loss'].append(loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZV_iUlh3CWo"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5\n",
    "LR = 1e-3\n",
    "GRAD_CLIP = 1.0\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 30\n",
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBekgFKP3C3S"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data,\n",
    "                               test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True, # For pack_padded_sequence\n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aCWVfRdAxY6N",
    "outputId": "1d3a0be8-26c7-404c-ba6c-b1722e7d871d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 27,103,199\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(embed_size=EMBEDDING_DIM,\n",
    "                  vocab_size=len(FR.vocab),\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT).to(device)\n",
    "decoder = Decoder(embed_size=EMBEDDING_DIM,\n",
    "                  vocab_size=len(EN.vocab),\n",
    "                  hidden_size=HIDDEN_SIZE,\n",
    "                  n_layers=N_LAYERS,\n",
    "                  dropout=DROPOUT).to(device)\n",
    "seq2seq = SeqToSeqNet(encoder=encoder, decoder=decoder).to(device)\n",
    "seq2seq.apply(init_weights)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=EN.vocab.stoi[EN.pad_token])\n",
    "print(f'Number of parameters of the model: {count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R22m0tls06BS",
    "outputId": "d6f9779c-82ff-4e0b-9a4b-e8fdffe98111"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 01 - Train Loss: 6.112: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 01 - Valid Loss: 5.648: 100%|██████████| 12/12 [00:00<00:00, 18.30it/s]\n",
      "Epoch: 02 - Train Loss: 5.691: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 02 - Valid Loss: 5.166: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 03 - Train Loss: 5.429: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 03 - Valid Loss: 4.903: 100%|██████████| 12/12 [00:00<00:00, 18.33it/s]\n",
      "Epoch: 04 - Train Loss: 5.245: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 04 - Valid Loss: 4.736: 100%|██████████| 12/12 [00:00<00:00, 18.39it/s]\n",
      "Epoch: 05 - Train Loss: 5.086: 100%|██████████| 211/211 [00:55<00:00,  3.84it/s]\n",
      "Epoch: 05 - Valid Loss: 4.601: 100%|██████████| 12/12 [00:00<00:00, 18.56it/s]\n",
      "Epoch: 06 - Train Loss: 4.969: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 06 - Valid Loss: 4.510: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 07 - Train Loss: 4.825: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 07 - Valid Loss: 4.418: 100%|██████████| 12/12 [00:00<00:00, 18.49it/s]\n",
      "Epoch: 08 - Train Loss: 4.714: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 08 - Valid Loss: 4.342: 100%|██████████| 12/12 [00:00<00:00, 18.67it/s]\n",
      "Epoch: 09 - Train Loss: 4.615: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 09 - Valid Loss: 4.294: 100%|██████████| 12/12 [00:00<00:00, 18.60it/s]\n",
      "Epoch: 10 - Train Loss: 4.533: 100%|██████████| 211/211 [00:55<00:00,  3.81it/s]\n",
      "Epoch: 10 - Valid Loss: 4.237: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 11 - Train Loss: 4.434: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 11 - Valid Loss: 4.188: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 12 - Train Loss: 4.330: 100%|██████████| 211/211 [00:54<00:00,  3.88it/s]\n",
      "Epoch: 12 - Valid Loss: 4.156: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 13 - Train Loss: 4.271: 100%|██████████| 211/211 [00:54<00:00,  3.89it/s]\n",
      "Epoch: 13 - Valid Loss: 4.133: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 14 - Train Loss: 4.175: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 14 - Valid Loss: 4.131: 100%|██████████| 12/12 [00:00<00:00, 18.59it/s]\n",
      "Epoch: 15 - Train Loss: 4.095: 100%|██████████| 211/211 [00:54<00:00,  3.85it/s]\n",
      "Epoch: 15 - Valid Loss: 4.093: 100%|██████████| 12/12 [00:00<00:00, 18.40it/s]\n",
      "Epoch: 16 - Train Loss: 4.004: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 16 - Valid Loss: 4.085: 100%|██████████| 12/12 [00:00<00:00, 18.40it/s]\n",
      "Epoch: 17 - Train Loss: 3.922: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 17 - Valid Loss: 4.085: 100%|██████████| 12/12 [00:00<00:00, 18.50it/s]\n",
      "Epoch: 18 - Train Loss: 3.839: 100%|██████████| 211/211 [00:55<00:00,  3.84it/s]\n",
      "Epoch: 18 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 19 - Train Loss: 3.765: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 19 - Valid Loss: 4.056: 100%|██████████| 12/12 [00:00<00:00, 18.45it/s]\n",
      "Epoch: 20 - Train Loss: 3.696: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 20 - Valid Loss: 4.065: 100%|██████████| 12/12 [00:00<00:00, 18.47it/s]\n",
      "Epoch: 21 - Train Loss: 3.637: 100%|██████████| 211/211 [00:54<00:00,  3.86it/s]\n",
      "Epoch: 21 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.43it/s]\n",
      "Epoch: 22 - Train Loss: 3.571: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 22 - Valid Loss: 4.051: 100%|██████████| 12/12 [00:00<00:00, 18.44it/s]\n",
      "Epoch: 23 - Train Loss: 3.481: 100%|██████████| 211/211 [00:54<00:00,  3.84it/s]\n",
      "Epoch: 23 - Valid Loss: 4.066: 100%|██████████| 12/12 [00:00<00:00, 18.31it/s]\n",
      "Epoch: 24 - Train Loss: 3.440: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 24 - Valid Loss: 4.072: 100%|██████████| 12/12 [00:00<00:00, 18.42it/s]\n",
      "Epoch: 25 - Train Loss: 3.364: 100%|██████████| 211/211 [00:54<00:00,  3.85it/s]\n",
      "Epoch: 25 - Valid Loss: 4.072: 100%|██████████| 12/12 [00:00<00:00, 18.58it/s]\n",
      "Epoch: 26 - Train Loss: 3.312: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 26 - Valid Loss: 4.077: 100%|██████████| 12/12 [00:00<00:00, 18.49it/s]\n",
      "Epoch: 27 - Train Loss: 3.264: 100%|██████████| 211/211 [00:55<00:00,  3.83it/s]\n",
      "Epoch: 27 - Valid Loss: 4.087: 100%|██████████| 12/12 [00:00<00:00, 18.39it/s]\n",
      "Epoch: 28 - Train Loss: 3.212: 100%|██████████| 211/211 [00:54<00:00,  3.87it/s]\n",
      "Epoch: 28 - Valid Loss: 4.095: 100%|██████████| 12/12 [00:00<00:00, 18.66it/s]\n",
      "Epoch: 29 - Train Loss: 3.150: 100%|██████████| 211/211 [00:55<00:00,  3.82it/s]\n",
      "Epoch: 29 - Valid Loss: 4.112: 100%|██████████| 12/12 [00:00<00:00, 18.42it/s]\n",
      "Epoch: 30 - Train Loss: 3.082: 100%|██████████| 211/211 [00:54<00:00,  3.89it/s]\n",
      "Epoch: 30 - Valid Loss: 4.126: 100%|██████████| 12/12 [00:00<00:00, 18.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 7s, sys: 2min 49s, total: 27min 57s\n",
      "Wall time: 28min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train(seq2seq, optimizer, criterion, train_iterator, valid_iterator,\n",
    "                sos_index=EN.vocab.stoi[EN.init_token],\n",
    "                n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "PQ_klP1-6XyF",
    "outputId": "594ec77b-331d-4a6e-87eb-3da5088583a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='valid')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DxDV_RX866Hp",
    "outputId": "6448b84f-af1d-4bc1-e7c7-7dc8cebaaae2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loss => Valid Loss: 4.082: 100%|██████████| 12/12 [00:00<00:00, 15.54it/s]\n"
     ]
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load('./saved_models/seq2seq-baseline.pt').get('model'))\n",
    "test_loss = valid_step(seq2seq, criterion, test_iterator,\n",
    "                       sos_index=EN.vocab.stoi[EN.init_token],\n",
    "                       epoch_text='Test loss => ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kC8tYcPCLgz5"
   },
   "source": [
    "# Inference & BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "bCe-iET5mwf3",
    "outputId": "1d3ff501-f297-478b-f0a2-32e5957f637b"
   },
   "outputs": [],
   "source": [
    "class Mode:\n",
    "    \"\"\"\n",
    "    Inference methods\n",
    "    \"\"\"\n",
    "    GREEDY = 'GREEDY'\n",
    "    SAMPLING = 'SAMPLING'\n",
    "    BEAM_SEARCH = 'BEAM_SEARCH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference:\n",
    "    \n",
    "    def __init__(self, model, src_field, dest_field, device=device):\n",
    "        self.model = model\n",
    "        self.src_field = src_field\n",
    "        self.dest_field = dest_field\n",
    "        self.device = device\n",
    "        \n",
    "    def greedy_search(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def sampling(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def beam_search(self, h_state, c_state, max_len):\n",
    "        pass\n",
    "    \n",
    "    def inference(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "RdRIlUJjLeDj",
    "outputId": "97427a7c-8638-45cf-b7fd-a4a1f63b3cd4"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# references = []\n",
    "# targets_with_sample = []\n",
    "# targets_without_sample  = []\n",
    "# seq2seq.eval()\n",
    "# with torch.no_grad():\n",
    "#     for i, example in enumerate(test_data.examples):\n",
    "#         in_ = torch.tensor([FR.vocab.stoi[token]\n",
    "#                             for token in example.src],\n",
    "#                         dtype=torch.int64, device=device).unsqueeze(1)\n",
    "#         if in_.size(0) == 0:\n",
    "#             print(f'skipped example {i}!')\n",
    "#             continue\n",
    "#         seq_len = torch.tensor([in_.size(0)], dtype=torch.int64, device=device)\n",
    "#         with_ = seq2seq.inference(in_, seq_len, EN.vocab.stoi[EN.init_token],\n",
    "#                                   EN.vocab.stoi[EN.eos_token], MAX_LEN)\n",
    "#         without = seq2seq.inference(in_, seq_len,  EN.vocab.stoi[EN.init_token],\n",
    "#                                     EN.vocab.stoi[EN.eos_token], MAX_LEN, False)\n",
    "#         targets_with_sample.append([EN.vocab.itos[int(idx)] for idx in with_[0]])\n",
    "#         targets_without_sample.append([EN.vocab.itos[int(idx)] for idx in without[0]])\n",
    "#         references.append([example.dest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yTolzzQaoAGd",
    "outputId": "aab5bd3b-b676-4d19-a4e5-e3fd153d5eec"
   },
   "outputs": [],
   "source": [
    "print(f'BLEU score with sampling: {bleu_score(targets_with_sample, references)}')\n",
    "print(f'BLEU score without sampling: {bleu_score(targets_without_sample, references)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "JV-mzrtbp_mp",
    "outputId": "fbbb9970-0adb-4d4f-b126-f16868147421"
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(' '.join(references[idx][0]))\n",
    "print('================================')\n",
    "print(' '.join(targets_with_sample[idx]))\n",
    "print('================================')\n",
    "print(' '.join(targets_without_sample[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hzyFn-Vqn3S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wEd7p3ARFcyr",
    "v2BPfwqcFk4h",
    "tazMbPR6Hnjg",
    "yT-6GZgfMXIu",
    "7cFeoEJpMYgE",
    "2ZwOJLkTMbCt"
   ],
   "name": "1 - Sequence to Sequence Model with RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
