{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 11 13:10:07 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   33C    P8     7W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "import torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "SEED = 781\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2,007,723\n",
      "CPU times: user 3.31 s, sys: 1.08 s, total: 4.39 s\n",
      "Wall time: 4.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = [*zip(\n",
    "    utils.read_file('./data/europarl-v7.fr-en.fr'),\n",
    "    utils.read_file('./data/europarl-v7.fr-en.en')\n",
    ")]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after sampling: 200,000\n",
      "Example:\n",
      "\tFR => Les procédures par le biais desquelles de tels produits entrent et sortent de l'Union européenne doivent être ouvertes, transparentes et, par dessus tout, sûres.\n",
      "\n",
      "\tEN => The procedures whereby such products come in and out of the European Union have to be open, transparent and, above all, safe.\n",
      "\n",
      "CPU times: user 1.29 s, sys: 63.1 ms, total: 1.36 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = np.random.choice(pairs, size=200_000, replace=False)\n",
    "pairs = [*map(\n",
    "    lambda pair: {k: v for k, v in pair.items()}, # utils.normalize_string(v)\n",
    "    pairs\n",
    ")]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_fr = [*map(lambda pair: len(pair['fr'].split()), pairs)]\n",
    "len_en = [*map(lambda pair: len(pair['en'].split()), pairs)]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist([*filter(lambda x: x < 50, len_fr)])\n",
    "axes[0].grid(True)\n",
    "axes[1].hist([*filter(lambda x: x < 50, len_en)])\n",
    "axes[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:24<00:00, 2377.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after filtering: 39,389\n"
     ]
    }
   ],
   "source": [
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True)\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en',\n",
    "           include_lengths=True)\n",
    "\n",
    "MIN_LENGTH, MAX_LENGTH = 20, 30\n",
    "\n",
    "examples = [Example.fromdict(\n",
    "    data=pair,\n",
    "    fields={\n",
    "        'fr': ('src', FR),\n",
    "        'en': ('dest', EN)\n",
    "    }\n",
    ") for pair in tqdm.tqdm(pairs)]\n",
    "examples = [*filter(\n",
    "    lambda example: MIN_LENGTH <= len(example.src) and len(example.src) <= MAX_LENGTH \\\n",
    "        and MIN_LENGTH <= len(example.dest) and len(example.dest) <= MAX_LENGTH,\n",
    "    examples\n",
    ")]\n",
    "print(f'Number of examples after filtering: {len(examples):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 31,511\n",
      "valid set size: 3,939\n",
      "test set size: 3,939\n",
      "{'src': [\"d'\", 'un', 'point', 'de', 'vue', 'psychologique', ',', 'la', 'destruction', 'des', 'infrastructures', 'critiques', 'entraîne', 'une', 'diminution', 'de', 'la', 'confiance', 'de', 'la', 'population', 'en', \"l'\", 'union', 'européenne', '.'], 'dest': ['from', 'a', 'psychological', 'point', 'of', 'view', ',', 'the', 'destruction', 'of', 'critical', 'infrastructures', 'leads', 'to', 'a', 'loss', 'of', 'public', 'confidence', 'in', 'the', 'european', 'union', '.']}\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
    "train_data, valid_data, test_data = data.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "print(f'train set size: {len(train_data.examples):,}')\n",
    "print(f'valid set size: {len(valid_data.examples):,}')\n",
    "print(f'test set size: {len(test_data.examples):,}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 7,988\n",
      "Length of EN vocabulary: 6,589\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab):,}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "    \n",
    "    def forward(self, input_sequences, sequence_lengths):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_sequences: Tensor[seq_len, batch_size]\n",
    "            sequence_lengths: Tensor[batch_size,]\n",
    "            \n",
    "        :return\n",
    "            outputs: Tensor[seq_len, batch_size, 2 * hidden_size]\n",
    "            hn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "            cn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_sequences)\n",
    "        embedded = self.dropout(embedded)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths)\n",
    "        outputs, (hn, cn) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return outputs, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        outputs, hn, cn = encoder(\n",
    "            input_sequences=data.src[0],\n",
    "            sequence_lengths=data.src[1]\n",
    "        )\n",
    "        seq_len = data.src[0].size(0)\n",
    "        assert outputs.size() == torch.Size([seq_len, batch_size, 2 * 256]), outputs.size()\n",
    "        assert hn.size() == torch.Size([4 * 2, batch_size, 256]), hn.size()\n",
    "        assert cn.size() == torch.Size([4 * 2, batch_size, 256]), cn.size()\n",
    "        break\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "        \n",
    "    def forward(self, input_word_index, h_state, c_state):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_word_index: Tensor[batch_size,]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            \n",
    "        :return\n",
    "            logit: Tensor[batch_size, vocab_size]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_word_index.unsqueeze(0))\n",
    "        embedded = self.dropout(embedded)\n",
    "        outputs, (h_state, c_state) = self.lstm(embedded, (h_state, c_state))\n",
    "        logit = self.fc(outputs.squeeze(0))\n",
    "        return logit, h_state, c_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    decoder = DecoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(EN.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        logit, h_state, c_state = decoder(\n",
    "            input_word_index=data.dest[0][0],\n",
    "            h_state=torch.rand(4, batch_size, 256),\n",
    "            c_state=torch.rand(4, batch_size, 256)\n",
    "        )\n",
    "        assert logit.size() == torch.Size([batch_size, len(EN.vocab)]), logit.size()\n",
    "        assert h_state.size() == torch.Size([4, batch_size, 256]), h_state.size()\n",
    "        assert c_state.size() == torch.Size([4, batch_size, 256]), c_state.size()\n",
    "        break\n",
    "        \n",
    "test_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeqLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and Decoder must have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            'Encoder and Decoder must have the same number of reccurrent hidden units'\n",
    "        \n",
    "        super(SeqToSeqLSTM, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src_sequences, src_lengths, dest_sequences, dest_lengths, tf_ratio):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            src_lengths: Tensor[batch_size,]\n",
    "            dest_sequences: Tensor[seq_len, batch_size]\n",
    "            dest_lengths: Tensor[batch_size,]\n",
    "            tf_ratio: float\n",
    "            \n",
    "        :return\n",
    "            logits: Tensor[max(decode_lengths), batch_size, vocab_size]\n",
    "            sorted_dest_sequences: Tensor[seq_len, batch_size]\n",
    "            sorted_decode_lengths: Tensor[batch_size,]\n",
    "            sorted_indices: Tensor[batch_size,]\n",
    "        \"\"\"\n",
    "        # Encoding\n",
    "        _, h_state, c_state = self.encoder(\n",
    "            input_sequences=src_sequences,\n",
    "            sequence_lengths=src_lengths\n",
    "        )\n",
    "        # h_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        # c_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        \n",
    "        # Sort the batch (dest) by decreasing lengths\n",
    "        sorted_dest_lengths, sorted_indices = torch.sort(dest_lengths, dim=0, descending=True)\n",
    "        sorted_dest_sequences = dest_sequences[:, sorted_indices]\n",
    "        \n",
    "        # Init hidden and memory states\n",
    "        h_state = h_state[:self.decoder.n_layers] \\\n",
    "            + h_state[self.decoder.n_layers:] # [n_layers, batch_size, hidden_size]\n",
    "        c_state = c_state[:self.decoder.n_layers] \\\n",
    "            + c_state[self.decoder.n_layers:] # [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>\n",
    "        # So, decoding lengths are actual lengths - 1\n",
    "        sorted_decode_lengths = (sorted_dest_lengths - 1).tolist()\n",
    "        \n",
    "        # Decoding\n",
    "        batch_size, last = h_state.size(1), None\n",
    "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
    "        for t in range(max(sorted_decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
    "            if last is not None:\n",
    "                if random.random() < tf_ratio:\n",
    "                    in_ = last[:batch_size_t]\n",
    "                else:\n",
    "                    in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            else:\n",
    "                in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            # in_ [batch_size,]\n",
    "            logit, h_state, c_state = self.decoder(\n",
    "                in_, \n",
    "                h_state[:, :batch_size_t, :].contiguous(),\n",
    "                c_state[:, :batch_size_t, :].contiguous()\n",
    "            )\n",
    "            # logit: [batch_size, vocab_size]\n",
    "            # h_state: [num_layers, batch_size, hidden_size]\n",
    "            # c_state: [num_layers, batch_size, hidden_size]\n",
    "            logits[t, :batch_size_t, :] = logit\n",
    "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
    "        \n",
    "        return logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seq2seq():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    decoder = DecoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(EN.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    model = SeqToSeqLSTM(encoder, decoder, device='cpu')\n",
    "    for data in train_iterator:\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(\n",
    "                src_sequences=data.src[0], \n",
    "                src_lengths=data.src[1],\n",
    "                dest_sequences=data.dest[0],\n",
    "                dest_lengths=data.dest[1],\n",
    "                tf_ratio=0.\n",
    "            )\n",
    "        assert logits.size() == torch.Size([\n",
    "            max(sorted_decode_lengths),\n",
    "            batch_size,\n",
    "            len(EN.vocab)\n",
    "        ]), logits.size()\n",
    "        assert sorted_dest_sequences.size() == torch.Size([\n",
    "            data.dest[0].shape[0],\n",
    "            batch_size\n",
    "        ]), sorted_dest_sequences.size()\n",
    "        assert len(sorted_decode_lengths) == batch_size, len(sorted_decode_lengths)\n",
    "        assert sorted_indices.size() == torch.Size([\n",
    "            batch_size,\n",
    "        ]), sorted_indices.size()\n",
    "        break\n",
    "        \n",
    "test_seq2seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, loader, epoch, grad_clip, tf_ratio, device):\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, data in pbar:\n",
    "        # Forward prop.\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(*data.src, *data.dest, tf_ratio=tf_ratio)\n",
    "        # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "        sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "        # Remove paddings\n",
    "        logits = nn.utils.rnn.pack_padded_sequence(\n",
    "            logits,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "            sorted_dest_sequences,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, sorted_dest_sequences)\n",
    "        # Back prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            torch_utils.clip_gradient(optimizer, grad_clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track metrics\n",
    "        loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "        acc_tracker.update(\n",
    "            torch_utils.accuracy(logits, sorted_dest_sequences, 1),\n",
    "            sum(sorted_decode_lengths)\n",
    "        )\n",
    "        # Update progressbar description\n",
    "        pbar.set_description(f'Epoch: {epoch + 1:03d} - loss: {loss_tracker.average:.3f} - acc: {acc_tracker.average:.3f}%')\n",
    "    return loss_tracker.average, acc_tracker.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, loader, field, epoch, device):\n",
    "    references, hypotheses = [], []\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar: \n",
    "            # Forward prop.\n",
    "            logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "                model(*data.src, *data.dest, tf_ratio=0.)\n",
    "            # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "            sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "            # Remove paddings\n",
    "            logits_copy = logits.clone()\n",
    "            logits = nn.utils.rnn.pack_padded_sequence(\n",
    "                logits,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_dest_sequences,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, sorted_dest_sequences)\n",
    "            # Track metrics\n",
    "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "            acc_tracker.update(\n",
    "                torch_utils.accuracy(logits, sorted_dest_sequences, 1),\n",
    "                sum(sorted_decode_lengths)\n",
    "            )\n",
    "            # Update references\n",
    "            target_sequences = data.dest[0].t()[sorted_indices]\n",
    "            for j in range(target_sequences.size(0)):\n",
    "                target_sequence = target_sequences[j].tolist()\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in target_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "            # Update hypotheses\n",
    "            _, preds = torch.max(logits_copy, dim=2)\n",
    "            preds = preds.t().tolist()\n",
    "            for j, p in enumerate(preds):\n",
    "                hypotheses.append([\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in preds[j][:sorted_decode_lengths[j]] # Remove padding\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ])\n",
    "            # Update progressbar description\n",
    "            pbar.set_description(f'Epoch: {epoch + 1:03d} - val_loss: {loss_tracker.average:.3f} - val_acc: {acc_tracker.average:.3f}%')\n",
    "        # Calculate BLEU-4 score\n",
    "        # print(\"hypotheses: \", hypotheses[0])\n",
    "        # print(\"references: \", references[0])\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    return loss_tracker.average, acc_tracker.average, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, valid_loader, field, n_epochs, grad_clip, tf_ratio, last_improv, model_name, device):\n",
    "    history, best_bleu = {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_loss': [],\n",
    "        'bleu4': []\n",
    "    }, 0.\n",
    "    for epoch in range(n_epochs):\n",
    "         # Stop training if no improvment since last 4 epochs\n",
    "        if last_improv == 4:\n",
    "            print('Training Finished - The model has stopped improving since last 4 epochs')\n",
    "            break\n",
    "        # Decay LR if no improvment\n",
    "        if last_improv > 0:\n",
    "            torch_utils.adjust_lr(optimizer, 0.8)\n",
    "        # Train step\n",
    "        loss, acc = train_step(model=model,\n",
    "                               optimizer=optimizer,\n",
    "                               criterion=criterion,\n",
    "                               loader=train_loader,\n",
    "                               epoch=epoch,\n",
    "                               grad_clip=grad_clip, \n",
    "                               tf_ratio=tf_ratio,\n",
    "                               device=device)\n",
    "        # Validation step\n",
    "        val_loss, val_acc, bleu4 = validate(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            loader=valid_loader,\n",
    "                                            field=field,\n",
    "                                            epoch=epoch,\n",
    "                                            device=device)\n",
    "        # Update history dict\n",
    "        history['acc'].append(acc)\n",
    "        history['loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['bleu4'].append(bleu4)\n",
    "        # Print BLEU score\n",
    "        text = f'BLEU-4: {bleu4*100:.3f}%'\n",
    "        if best_bleu > bleu4:\n",
    "            last_improv += 1\n",
    "            text += f' - Last improvement since {last_improv} epoch(s)'\n",
    "        else:\n",
    "            best_bleu, last_improv = bleu4, 0\n",
    "        print(text)\n",
    "        # Save checkpoint\n",
    "        torch_utils.save_checkpoint(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_name=model_name,\n",
    "                                    epoch=epoch,\n",
    "                                    last_improv=last_improv,\n",
    "                                    bleu4=bleu4,\n",
    "                                    is_best=bleu4 >= best_bleu)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word vectors\n",
    "spacy_en = spacy.load('en_core_web_lg') # GloVe trained word vectors\n",
    "spacy_fr = spacy.load('fr_core_news_lg') # CBOW trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6663/6663 [00:55<00:00, 119.91it/s]\n",
      "100%|██████████| 8114/8114 [01:15<00:00, 107.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "en_embeddings = torch_utils.load_embeddings(nlp=spacy_en, field=EN)\n",
    "fr_embeddings = torch_utils.load_embeddings(nlp=spacy_fr, field=FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq-lstm'\n",
    "N_LAYERS = 4\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDING_SIZE = 300\n",
    "DROPOUT = 0.25\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "GRAD_CLIP = 1.\n",
    "TF_RATIO = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 37,957,161\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLSTM(\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    vocab_size=len(FR.vocab),\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    recurrent_dropout=DROPOUT\n",
    ")\n",
    "encoder.load_pretrained_embeddings(fr_embeddings)\n",
    "encoder.fine_tuning_embeddings(fine_tune=True)\n",
    "decoder = DecoderLSTM(\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    vocab_size=len(EN.vocab),\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    recurrent_dropout=DROPOUT\n",
    ")\n",
    "decoder.load_pretrained_embeddings(en_embeddings)\n",
    "decoder.fine_tuning_embeddings(fine_tune=True)\n",
    "seq2seq = SeqToSeqLSTM(encoder=encoder, decoder=decoder, device=DEVICE).to(DEVICE)\n",
    "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f'Number of parameters of the model: {torch_utils.count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True,\n",
    "                              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - loss: 5.741 - acc: 6.062%: 100%|██████████| 247/247 [01:13<00:00,  3.35it/s]\n",
      "Epoch: 001 - val_loss: 5.195 - val_acc: 9.018%: 100%|██████████| 31/31 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 1.276%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 - loss: 4.908 - acc: 10.429%: 100%|██████████| 247/247 [01:14<00:00,  3.30it/s]\n",
      "Epoch: 002 - val_loss: 4.639 - val_acc: 11.745%: 100%|██████████| 31/31 [00:03<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 3.156%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003 - loss: 4.530 - acc: 12.123%: 100%|██████████| 247/247 [01:15<00:00,  3.29it/s]\n",
      "Epoch: 003 - val_loss: 4.443 - val_acc: 12.555%: 100%|██████████| 31/31 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 3.482%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004 - loss: 4.327 - acc: 12.908%: 100%|██████████| 247/247 [01:15<00:00,  3.25it/s]\n",
      "Epoch: 004 - val_loss: 4.297 - val_acc: 13.162%: 100%|██████████| 31/31 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 4.044%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005 - loss: 4.188 - acc: 13.405%: 100%|██████████| 247/247 [01:16<00:00,  3.24it/s]\n",
      "Epoch: 005 - val_loss: 4.222 - val_acc: 13.598%: 100%|██████████| 31/31 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 4.336%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006 - loss: 4.075 - acc: 13.830%: 100%|██████████| 247/247 [01:16<00:00,  3.25it/s]\n",
      "Epoch: 006 - val_loss: 4.166 - val_acc: 13.951%: 100%|██████████| 31/31 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 4.703%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007 - loss: 3.982 - acc: 14.155%: 100%|██████████| 247/247 [01:15<00:00,  3.25it/s]\n",
      "Epoch: 007 - val_loss: 4.128 - val_acc: 14.178%: 100%|██████████| 31/31 [00:04<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 4.730%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008 - loss: 3.896 - acc: 14.426%: 100%|██████████| 247/247 [01:16<00:00,  3.25it/s]\n",
      "Epoch: 008 - val_loss: 4.098 - val_acc: 14.372%: 100%|██████████| 31/31 [00:03<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 4.991%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009 - loss: 3.819 - acc: 14.700%: 100%|██████████| 247/247 [01:16<00:00,  3.24it/s]\n",
      "Epoch: 009 - val_loss: 4.085 - val_acc: 14.520%: 100%|██████████| 31/31 [00:03<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.042%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010 - loss: 3.748 - acc: 14.943%: 100%|██████████| 247/247 [01:15<00:00,  3.25it/s]\n",
      "Epoch: 010 - val_loss: 4.071 - val_acc: 14.690%: 100%|██████████| 31/31 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.242%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011 - loss: 3.680 - acc: 15.173%: 100%|██████████| 247/247 [01:15<00:00,  3.25it/s]\n",
      "Epoch: 011 - val_loss: 4.069 - val_acc: 14.751%: 100%|██████████| 31/31 [00:03<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012 - loss: 3.619 - acc: 15.367%: 100%|██████████| 247/247 [01:15<00:00,  3.26it/s]\n",
      "Epoch: 012 - val_loss: 4.062 - val_acc: 14.823%: 100%|██████████| 31/31 [00:03<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.429%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013 - loss: 3.560 - acc: 15.561%: 100%|██████████| 247/247 [01:15<00:00,  3.26it/s]\n",
      "Epoch: 013 - val_loss: 4.065 - val_acc: 14.884%: 100%|██████████| 31/31 [00:03<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.419% - Last improvement since 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014 - loss: 3.485 - acc: 15.866%: 100%|██████████| 247/247 [01:16<00:00,  3.25it/s]\n",
      "Epoch: 014 - val_loss: 4.067 - val_acc: 14.911%: 100%|██████████| 31/31 [00:03<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.554%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015 - loss: 3.439 - acc: 16.015%: 100%|██████████| 247/247 [01:16<00:00,  3.25it/s]\n",
      "Epoch: 015 - val_loss: 4.070 - val_acc: 14.986%: 100%|██████████| 31/31 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.547% - Last improvement since 1 epoch(s)\n"
     ]
    }
   ],
   "source": [
    "history = train(model=seq2seq,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=train_iterator,\n",
    "                valid_loader=valid_iterator,\n",
    "                field=EN,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                grad_clip=GRAD_CLIP,\n",
    "                tf_ratio=TF_RATIO,\n",
    "                last_improv=0,\n",
    "                model_name=MODEL_NAME,\n",
    "                device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[1].plot(history['acc'], label='train')\n",
    "axes[1].plot(history['val_acc'], label='valid')\n",
    "axes[1].plot(np.array(history['bleu4']) * 100., label='BLEU-4')\n",
    "axes[1].set_title('Accuracy & BLEU-4 history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy & BLEU-4 (%)')\n",
    "axes[1].grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load(f'./checkpoint/{MODEL_NAME}.pt').get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, beam_size, field, max_len, device):\n",
    "    references, hypotheses = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar:\n",
    "            (src_sequences, src_lengths) = data.src[0], data.src[1]\n",
    "            (dest_sequences, dest_lengths) = data.dest[0], data.dest[1]\n",
    "            \n",
    "            batch_size = src_sequences.shape[1]\n",
    "            for j in range(batch_size): # We evaluate sentence by sentence\n",
    "                src_sequence = src_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                dest_sequence = dest_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                src_length, dest_length = src_lengths[j, None], dest_lengths[j, None] # [1,]\n",
    "                \n",
    "                k = beam_size\n",
    "                # Top k previous token indices at each step\n",
    "                topk_prev_tokens = torch.LongTensor([\n",
    "                    [field.vocab.stoi[field.init_token]]\n",
    "                ] * k).to(device)  # [k, 1]\n",
    "                # Top k sequences\n",
    "                topk_sequences = topk_prev_tokens  # [k, 1]\n",
    "                # Top k sequences' logps\n",
    "                topk_logps = torch.zeros(k, 1).to(device)  # [k, 1]\n",
    "                # Complete sequences and logps\n",
    "                complete_sequences, complete_sequence_logps = [], []\n",
    "                \n",
    "                # Encoding\n",
    "                _, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                    sequence_lengths=src_length)\n",
    "                # h_state: [n_layers * 2, 1, hidden_size]\n",
    "                # c_state: [n_layers * 2, 1, hidden_size]\n",
    "                \n",
    "                # Init hidden and memory states\n",
    "                h_state = h_state[:model.decoder.n_layers] \\\n",
    "                    + h_state[model.decoder.n_layers:] # [n_layers, 1, hidden_size]\n",
    "                c_state = c_state[:model.decoder.n_layers] \\\n",
    "                    + c_state[model.decoder.n_layers:] # [n_layers, 1, hidden_size]\n",
    "                h_state = h_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "                c_state = c_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "                \n",
    "                # Decoding\n",
    "                step = 1\n",
    "                while True:\n",
    "                    logit, h_state, c_state = model.decoder(\n",
    "                        input_word_index=topk_prev_tokens.squeeze(1), \n",
    "                        h_state=h_state.contiguous(),\n",
    "                        c_state=c_state.contiguous()\n",
    "                    )\n",
    "                    # logit: [k, vocab_size]\n",
    "                    # h_state: [n_layers, k, hidden_size]\n",
    "                    # c_state: [n_layers, k, hidden_size]\n",
    "                    \n",
    "                    # Get scores\n",
    "                    logp = F.log_softmax(logit, dim=1) # [k, vocab_size]\n",
    "                    # Extend\n",
    "                    logp = topk_logps.expand_as(logp) + logp  # [k, vocab_size]\n",
    "                    \n",
    "                    # At the 1st step, the score is 0\n",
    "                    if step == 1:\n",
    "                        topk_logps, topk_tokens = logp[0].topk(k, 0, True, True)  # [k,]\n",
    "                    else:\n",
    "                        # Unroll and find top logp, and their unrolled indices\n",
    "                        topk_logps, topk_tokens = logp.view(-1).topk(k, 0, True, True)  # [k,]\n",
    "                    \n",
    "                    # Convert unrolled indices to actual indices of logp\n",
    "                    prev_tokens = topk_tokens // model.decoder.vocab_size  # [k,]\n",
    "                    next_tokens = topk_tokens % model.decoder.vocab_size  # [k,]\n",
    "                    \n",
    "                    # Add new indices to topk_sequences\n",
    "                    topk_sequences = torch.cat((\n",
    "                        topk_sequences[prev_tokens],\n",
    "                        next_tokens.unsqueeze(1)\n",
    "                    ), dim=1) # [k, step + 1]\n",
    "                    \n",
    "                    # Get the complete and incomplete sequences\n",
    "                    incomplete_indices = [\n",
    "                        indice for indice, next_token in enumerate(next_tokens) \n",
    "                        if next_token != field.vocab.stoi[field.eos_token]\n",
    "                    ]\n",
    "                    complete_indices = list(set(range(len(next_tokens))) - set(incomplete_indices))\n",
    "                    \n",
    "                    # Set aside complete sequences\n",
    "                    if len(complete_indices) > 0:\n",
    "                        complete_sequences.extend(topk_sequences[complete_indices].tolist())\n",
    "                        complete_sequence_logps.extend(topk_logps[complete_indices])\n",
    "                        \n",
    "                    # Reduce beam length accordingly\n",
    "                    k -= len(complete_indices)\n",
    "                    \n",
    "                    # Proceed with incomplete sequences\n",
    "                    if k == 0:\n",
    "                        break\n",
    "                        \n",
    "                    topk_sequences = topk_sequences[incomplete_indices]\n",
    "                    h_state = h_state[:, prev_tokens[incomplete_indices], :]\n",
    "                    c_state = c_state[:, prev_tokens[incomplete_indices], :]\n",
    "                    topk_logps = topk_logps[incomplete_indices].unsqueeze(1)\n",
    "                    topk_prev_tokens = next_tokens[incomplete_indices].unsqueeze(1)\n",
    "                    \n",
    "                    # Break if things have been going on too long\n",
    "                    if step > max_len:\n",
    "                        if len(complete_indices) == 0:\n",
    "                            complete_sequences.extend(topk_sequences.tolist())\n",
    "                            complete_sequence_logps.extend(topk_logps[incomplete_indices])\n",
    "                        break\n",
    "\n",
    "                    # Update step\n",
    "                    step += 1\n",
    "                    \n",
    "                i = complete_sequence_logps.index(max(complete_sequence_logps))\n",
    "                pred_sequence = complete_sequences[i]\n",
    "                \n",
    "                # Update references\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in dest_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.eos_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "                \n",
    "                # Update hypotheses\n",
    "                hypothese = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in pred_sequence\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.eos_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                hypotheses.append(hypothese)\n",
    "                \n",
    "                assert len(references) == len(hypotheses)\n",
    "            \n",
    "        # Calculate BLEU-4 score\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    return hypotheses, references, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [02:45<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 0.873% with beam_size=1\n"
     ]
    }
   ],
   "source": [
    "h, r, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=1,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [03:27<00:00,  6.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 1.048% with beam_size=3\n"
     ]
    }
   ],
   "source": [
    "_, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=3,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [03:39<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 1.009% with beam_size=5\n"
     ]
    }
   ],
   "source": [
    "_, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=5,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [03:54<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 1.760% with beam_size=10\n"
     ]
    }
   ],
   "source": [
    "_, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=10,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3939/3939 [03:41<00:00, 17.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
    "    if isinstance(sentences, list):\n",
    "        sentences = [*map(src_field.preprocess, sentences)]\n",
    "        targets = None\n",
    "    if isinstance(sentences, Dataset):\n",
    "        targets = [*map(lambda example: ' '.join(example.dest), sentences.examples)]\n",
    "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
    "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        translated_sentences = []\n",
    "        pbar = tqdm.tqdm(enumerate(data), total=len(data))\n",
    "        for i, (src_sequence, src_length) in pbar:\n",
    "            src_sequence, src_length = src_sequence.to(DEVICE), src_length.to(DEVICE)\n",
    "            k = beam_size\n",
    "            # Top k previous token indices at each step\n",
    "            topk_prev_tokens = torch.LongTensor([\n",
    "                [dest_field.vocab.stoi[dest_field.init_token]]\n",
    "            ] * k).to(device)  # [k, 1]\n",
    "            # Top k sequences\n",
    "            topk_sequences = topk_prev_tokens  # [k, 1]\n",
    "            # Top k sequences' logps\n",
    "            topk_logps = torch.zeros(k, 1).to(device)  # [k, 1]\n",
    "            # Complete sequences and logps\n",
    "            complete_sequences, complete_sequence_logps = [], []\n",
    "\n",
    "            # Encoding\n",
    "            _, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                sequence_lengths=src_length)\n",
    "            # h_state: [n_layers * 2, 1, hidden_size]\n",
    "            # c_state: [n_layers * 2, 1, hidden_size]\n",
    "\n",
    "            # Init hidden and memory states\n",
    "            h_state = h_state[:model.decoder.n_layers] \\\n",
    "                + h_state[model.decoder.n_layers:] # [n_layers, 1, hidden_size]\n",
    "            c_state = c_state[:model.decoder.n_layers] \\\n",
    "                + c_state[model.decoder.n_layers:] # [n_layers, 1, hidden_size]\n",
    "            h_state = h_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "            c_state = c_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "\n",
    "            # Decoding\n",
    "            step = 1\n",
    "            while True:\n",
    "                logit, h_state, c_state = model.decoder(\n",
    "                    input_word_index=topk_prev_tokens.squeeze(1), \n",
    "                    h_state=h_state.contiguous(),\n",
    "                    c_state=c_state.contiguous()\n",
    "                )\n",
    "                # logit: [k, vocab_size]\n",
    "                # h_state: [n_layers, k, hidden_size]\n",
    "                # c_state: [n_layers, k, hidden_size]\n",
    "\n",
    "                # Get scores\n",
    "                logp = F.log_softmax(logit, dim=1) # [k, vocab_size]\n",
    "                # Extend\n",
    "                logp = topk_logps.expand_as(logp) + logp  # [k, vocab_size]\n",
    "\n",
    "                # At the 1st step, the score is 0\n",
    "                if step == 1:\n",
    "                    topk_logps, topk_tokens = logp[0].topk(k, 0, True, True)  # [k,]\n",
    "                else:\n",
    "                    # Unroll and find top logp, and their unrolled indices\n",
    "                    topk_logps, topk_tokens = logp.view(-1).topk(k, 0, True, True)  # [k,]\n",
    "\n",
    "                # Convert unrolled indices to actual indices of logp\n",
    "                prev_tokens = topk_tokens // model.decoder.vocab_size  # [k,]\n",
    "                next_tokens = topk_tokens % model.decoder.vocab_size  # [k,]\n",
    "\n",
    "                # Add new indices to topk_sequences\n",
    "                topk_sequences = torch.cat((\n",
    "                    topk_sequences[prev_tokens],\n",
    "                    next_tokens.unsqueeze(1)\n",
    "                ), dim=1) # [k, step + 1]\n",
    "\n",
    "                # Get the complete and incomplete sequences\n",
    "                incomplete_indices = [\n",
    "                    indice for indice, next_token in enumerate(next_tokens) \n",
    "                    if next_token != dest_field.vocab.stoi[dest_field.eos_token]\n",
    "                ]\n",
    "                complete_indices = list(set(range(len(next_tokens))) - set(incomplete_indices))\n",
    "\n",
    "                # Set aside complete sequences\n",
    "                if len(complete_indices) > 0:\n",
    "                    complete_sequences.extend(topk_sequences[complete_indices].tolist())\n",
    "                    complete_sequence_logps.extend(topk_logps[complete_indices])\n",
    "\n",
    "                # Reduce beam length accordingly\n",
    "                k -= len(complete_indices)\n",
    "\n",
    "                # Proceed with incomplete sequences\n",
    "                if k == 0:\n",
    "                    break\n",
    "\n",
    "                topk_sequences = topk_sequences[incomplete_indices]\n",
    "                h_state = h_state[:, prev_tokens[incomplete_indices], :]\n",
    "                c_state = c_state[:, prev_tokens[incomplete_indices], :]\n",
    "                topk_logps = topk_logps[incomplete_indices].unsqueeze(1)\n",
    "                topk_prev_tokens = next_tokens[incomplete_indices].unsqueeze(1)\n",
    "\n",
    "                # Break if things have been going on too long\n",
    "                if step > max_len:\n",
    "                    if len(complete_indices) == 0:\n",
    "                        complete_sequences.extend(topk_sequences.tolist())\n",
    "                        complete_sequence_logps.extend(topk_logps[incomplete_indices])\n",
    "                    break\n",
    "\n",
    "                # Update step\n",
    "                step += 1\n",
    "\n",
    "            idx = complete_sequence_logps.index(max(complete_sequence_logps))\n",
    "            pred_sequence = complete_sequences[idx]\n",
    "            \n",
    "            translated_sentences.append(\n",
    "                ' '.join([\n",
    "                    dest_field.vocab.itos[token]\n",
    "                    for token in pred_sequence \n",
    "                    if token not in {\n",
    "                        dest_field.vocab.stoi[dest_field.init_token],\n",
    "                        dest_field.vocab.stoi[dest_field.eos_token],\n",
    "                        dest_field.vocab.stoi[dest_field.pad_token]\n",
    "                    }\n",
    "                ])\n",
    "            )\n",
    "    sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
    "    return sentences, translated_sentences, targets\n",
    "\n",
    "sentences, translated_sentences, dest_sentences = translate(sentences=test_data,\n",
    "                                                            model=seq2seq,\n",
    "                                                            beam_size=10,\n",
    "                                                            src_field=FR,\n",
    "                                                            dest_field=EN,\n",
    "                                                            max_len=MAX_LENGTH,\n",
    "                                                            device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3439  868 1737   25 2191 2477 1357 2012 1016 1871]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> les fonds structurels et le fonds de cohésion offrent un effet de levier financier susceptible de faciliter le redressement économique , en particulier en cette période de crise .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> the structural and cohesion funds provide financial leverage which may facilitate economic recovery , particularly during the current crisis .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , commissioner , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> tous les députés   - je dis cela à votre intention , madame pack   - reçoivent des lettres les invitant à soutenir les amendements déposés par nos collègues .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> all members of parliament – i say this for your benefit mrs pack – receive letters urging us to support amendments tabled by our honourable friends .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , commissioner , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> comme l ' a déjà signalé le rapporteur , nous sommes probablement en train de débattre d ' un des sujets les plus importants de cette législature .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> as indicated by the rapporteur , we are discussing probably one of the most important issues that we will ever have to discuss in this parliament .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , commissioner , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> en conclusion , je ne peux que me réjouir de ce rapport et des progrès qui ont déjà été réalisés .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> in conclusion , i can only welcome this report , and the same applies to the progress which has already been made .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> malheureusement , nous avons dû apprendre de certains rédacteurs en chef de serbie , de yougoslavie , qu' ils devaient attendre très , très longtemps .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> unfortunately , we have had to hear from editors in serbia , in yugoslavia , that they are waiting a very , very long time .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> ce n' est pas exagérer que de dire que , d' une certaine manière , nous nous sentons trahis .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> it is not putting it too strongly to say that , in a sense , we feel betrayed by it .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> je crois même que c' est ce qui m' a le plus inquiété à l' issue de ma troisième participation aux négociations .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> i even think that this is what worried me most at the end of my third participation in the negotiations .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> en même temps , le taux de chômage des jeunes représente un problème très sérieux , et il est plus élevé que dans n' importe quel groupe d' âge .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> at the same time , a very serious problem is the unemployment rate among young people , which is higher than in any other age group .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , commissioner , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> cela pose la question de savoir s' il est temps de réviser le règlement de manière à pouvoir éliminer les minorités de blocage des deux côtés .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> it begs the question whether it is time that the rules of procedure were reviewed so that blocking minorities on both sides can be done away with .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span><b>Source:</b> la crédibilité du parlement européen était en jeu , nous ne voulions pas que le parlement européen soit un prétexte facile pour un éventuel échec .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Translation:</b> the credibility of the european parliament was at stake and we did not want the european parliament to be an easy pretext for possible failure .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span><b>Predicted:</b> mr president , ladies and gentlemen , i would like to thank the rapporteur , mr <unk> , for his excellent work .</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "indexes = np.random.choice(len(test_data.examples), 10)\n",
    "print(indexes)\n",
    "print()\n",
    "for i in indexes:\n",
    "    display(HTML(f'<span><b>Source:</b> {sentences[i]}</span>'))\n",
    "    display(HTML(f'<span><b>Translation:</b> {dest_sentences[i]}</span>'))\n",
    "    display(HTML(f'<span><b>Predicted:</b> {translated_sentences[i]}</span>'))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
