{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  9 02:16:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   35C    P8     7W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 781\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2,007,723\n",
      "CPU times: user 3.55 s, sys: 885 ms, total: 4.44 s\n",
      "Wall time: 4.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = [*zip(\n",
    "    utils.read_file('./data/europarl-v7.fr-en.fr'),\n",
    "    utils.read_file('./data/europarl-v7.fr-en.en')\n",
    ")]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after sampling: 200,000\n",
      "Example:\n",
      "\tFR => C'est pourquoi j'ai quelque appréhension, si nous accordons à certains pays une flexibilité spéciale, car alors dans le pire des cas ils seront perdants, en d'autres termes ils ne bénéficieront pas des avantages technologiques que les autres pays de l'UE recevront.\n",
      "\n",
      "\tEN => For this reason, I am slightly concerned if we are going to allow some countries special flexibility, as then in the worst-case scenario they will be losing out, which is to say they will not receive the technological benefits that the other EU countries will.\n",
      "\n",
      "CPU times: user 1.31 s, sys: 43.9 ms, total: 1.36 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs = np.random.choice(pairs, size=200_000, replace=False)\n",
    "pairs = [*map(\n",
    "    lambda pair: {k: v for k, v in pair.items()}, # utils.normalize_string(v)\n",
    "    pairs\n",
    ")]\n",
    "print(f'Number of examples after sampling: {len(pairs):,}')\n",
    "print(f'Example:\\n\\tFR => {pairs[0][\"fr\"]}\\n\\tEN => {pairs[0][\"en\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_fr = [*map(lambda pair: len(pair['fr'].split()), pairs)]\n",
    "len_en = [*map(lambda pair: len(pair['en'].split()), pairs)]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist([*filter(lambda x: x < 50, len_fr)])\n",
    "axes[0].grid(True)\n",
    "axes[1].hist([*filter(lambda x: x < 50, len_en)])\n",
    "axes[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:20<00:00, 2485.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after filtering: 39,016\n"
     ]
    }
   ],
   "source": [
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True) # For pack_padded_sequence\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en')\n",
    "\n",
    "MIN_LENGTH, MAX_LENGTH = 20, 30\n",
    "\n",
    "examples = [Example.fromdict(\n",
    "    data=pair,\n",
    "    fields={\n",
    "        'fr': ('src', FR),\n",
    "        'en': ('dest', EN)\n",
    "    }\n",
    ") for pair in tqdm.tqdm(pairs)]\n",
    "examples = [*filter(\n",
    "    lambda example: MIN_LENGTH <= len(example.src) and len(example.src) <= MAX_LENGTH \\\n",
    "        and MIN_LENGTH <= len(example.dest) and len(example.dest) <= MAX_LENGTH,\n",
    "    examples\n",
    ")]\n",
    "print(f'Number of examples after filtering: {len(examples):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 31,213\n",
      "valid set size: 3,901\n",
      "test set size: 3,902\n",
      "{'src': [\"c'\", 'est', 'pour', 'cette', 'raison', 'que', 'nous', 'assistons', 'à', 'épuisement', 'majeur', 'des', 'stocks', 'de', 'poissons', 'et', 'nous', 'en', 'serons', 'tous', 'affectés', '.'], 'dest': ['that', 'is', 'why', 'we', 'are', 'seeing', 'great', 'depletion', 'of', 'fish', 'stocks', ',', 'and', 'we', 'will', 'all', 'suffer', 'in', 'the', 'end', '.']}\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
    "train_data, valid_data, test_data = data.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "print(f'train set size: {len(train_data.examples):,}')\n",
    "print(f'valid set size: {len(valid_data.examples):,}')\n",
    "print(f'test set size: {len(test_data.examples):,}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 7,955\n",
      "Length of EN vocabulary: 6,512\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab):,}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "    \n",
    "    def forward(self, input_sequences, sequence_lengths):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_sequences: Tensor[seq_len, batch_size]\n",
    "            sequence_lengths: Tensor[batch_size,]\n",
    "            \n",
    "        :return\n",
    "            outputs: Tensor[seq_len, batch_size, 2 * hidden_size]\n",
    "            hn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "            cn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_sequences)\n",
    "        embedded = self.dropout(embedded)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths)\n",
    "        outputs, (hn, cn) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return outputs, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        outputs, hn, cn = encoder(\n",
    "            input_sequences=data.src[0],\n",
    "            sequence_lengths=data.src[1]\n",
    "        )\n",
    "        seq_len = data.src[0].size(0)\n",
    "        assert outputs.size() == torch.Size([seq_len, batch_size, 2 * 256]), outputs.size()\n",
    "        assert hn.size() == torch.Size([4 * 2, batch_size, 256]), hn.size()\n",
    "        assert cn.size() == torch.Size([4 * 2, batch_size, 256]), cn.size()\n",
    "        break\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
