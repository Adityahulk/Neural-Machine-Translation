{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 15 18:27:55 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 38%   54C    P0    44W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.iterator import BucketIterator\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "import torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FR sentences: 2,007,723\n",
      "Number of EN sentences: 2,007,723\n",
      "CPU times: user 1.76 s, sys: 825 ms, total: 2.59 s\n",
      "Wall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_fr = utils.read_file('./data/europarl-v7.fr-en.fr')\n",
    "data_en = utils.read_file('./data/europarl-v7.fr-en.en')\n",
    "print(f'Number of FR sentences: {len(data_fr):,}')\n",
    "print(f'Number of EN sentences: {len(data_en):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2007723/2007723 [01:08<00:00, 29297.37it/s]\n",
      "100%|██████████| 2007723/2007723 [00:59<00:00, 33484.26it/s]\n"
     ]
    }
   ],
   "source": [
    "data_fr = utils.clean_lines(data_fr)\n",
    "data_en = utils.clean_lines(data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 2,007,723\n"
     ]
    }
   ],
   "source": [
    "pairs = [*zip(data_fr, data_en)]\n",
    "pairs = [*map(lambda x: {'fr': x[0], 'en': x[1]}, pairs)]\n",
    "print(f'Number of examples: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_fr = [*map(lambda pair: len(pair['fr'].split()), pairs)]\n",
    "len_en = [*map(lambda pair: len(pair['en'].split()), pairs)]\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].hist([*filter(lambda x: x < 50, len_fr)])\n",
    "axes[0].grid(True)\n",
    "axes[1].hist([*filter(lambda x: x < 50, len_en)])\n",
    "axes[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples after filtering: 221,823\n",
      "CPU times: user 4.23 s, sys: 3.68 ms, total: 4.23 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MIN_LENGTH, MAX_LENGTH = 5, 10\n",
    "pairs = [*filter(lambda pair: MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH and MIN_LENGTH <= len(pair['fr'].split()) <= MAX_LENGTH, pairs)]\n",
    "print(f'Number of examples after filtering: {len(pairs):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 221823/221823 [00:34<00:00, 6521.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 221,823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FR = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='fr',\n",
    "           include_lengths=True)\n",
    "EN = Field(init_token='<sos>',\n",
    "           eos_token='<eos>',\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en',\n",
    "           include_lengths=True)\n",
    "\n",
    "examples = [Example.fromdict(\n",
    "    data=pair,\n",
    "    fields={\n",
    "        'fr': ('src', FR),\n",
    "        'en': ('dest', EN)\n",
    "    }\n",
    ") for pair in tqdm.tqdm(pairs)]\n",
    "print(f'Number of examples: {len(examples):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 177,458\n",
      "valid set size: 22,183\n",
      "test set size: 22,182\n",
      "{'src': ['evidemment', 'il', 'y', 'en', 'a', 'eu', 'beaucoup', 'plus'], 'dest': ['clearly', 'there', 'have', 'been', 'many', 'more']}\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(examples, fields={'src': FR, 'dest': EN})\n",
    "train_data, valid_data, test_data = data.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "print(f'train set size: {len(train_data.examples):,}')\n",
    "print(f'valid set size: {len(valid_data.examples):,}')\n",
    "print(f'test set size: {len(test_data.examples):,}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FR vocabulary: 11,794\n",
      "Length of EN vocabulary: 8,765\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5\n",
    "FR.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "EN.build_vocab(train_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=['<sos>', '<eos>', '<unk>', '<pad>'])\n",
    "print(f'Length of FR vocabulary: {len(FR.vocab):,}')\n",
    "print(f'Length of EN vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "    \n",
    "    def forward(self, input_sequences, sequence_lengths):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_sequences: Tensor[seq_len, batch_size]\n",
    "            sequence_lengths: Tensor[batch_size,]\n",
    "            \n",
    "        :return\n",
    "            outputs: Tensor[seq_len, batch_size, 2 * hidden_size]\n",
    "            hn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "            cn: Tensor[n_layers * 2, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_sequences)\n",
    "        embedded = F.dropout(embedded, p=self.dropout)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, sequence_lengths)\n",
    "        outputs, (hn, cn) = self.lstm(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return outputs, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_encoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.35,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        outputs, hn, cn = encoder(\n",
    "            input_sequences=data.src[0],\n",
    "            sequence_lengths=data.src[1]\n",
    "        )\n",
    "        seq_len = data.src[0].size(0)\n",
    "        assert outputs.size() == torch.Size([seq_len, batch_size, 2 * 256]), outputs.size()\n",
    "        assert hn.size() == torch.Size([4 * 2, batch_size, 256]), hn.size()\n",
    "        assert cn.size() == torch.Size([4 * 2, batch_size, 256]), cn.size()\n",
    "        break\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        vocab_size,\n",
    "        hidden_size,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        recurrent_dropout\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.recurrent_dropout = recurrent_dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                            num_layers=n_layers,\n",
    "                            dropout=(recurrent_dropout if n_layers > 1 else 0))\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "        \n",
    "    def forward(self, input_word_index, h_state, c_state):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            input_word_index: Tensor[batch_size,]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            \n",
    "        :return\n",
    "            logit: Tensor[batch_size, vocab_size]\n",
    "            h_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "            c_state: Tensor[num_layers, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_word_index.unsqueeze(0))\n",
    "        outputs, (h_state, c_state) = self.lstm(embedded, (h_state, c_state))\n",
    "        logit = self.fc(F.dropout(outputs, p=self.dropout))\n",
    "        logit = logit.squeeze(0)\n",
    "        return logit, h_state, c_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decoder():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    decoder = DecoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(EN.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    for data in train_iterator:\n",
    "        logit, h_state, c_state = decoder(\n",
    "            input_word_index=data.dest[0][0],\n",
    "            h_state=torch.rand(4, batch_size, 256),\n",
    "            c_state=torch.rand(4, batch_size, 256)\n",
    "        )\n",
    "        assert logit.size() == torch.Size([batch_size, len(EN.vocab)]), logit.size()\n",
    "        assert h_state.size() == torch.Size([4, batch_size, 256]), h_state.size()\n",
    "        assert c_state.size() == torch.Size([4, batch_size, 256]), c_state.size()\n",
    "        break\n",
    "        \n",
    "test_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeqLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and Decoder must have the same number of reccurent layers'\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            'Encoder and Decoder must have the same number of reccurrent hidden units'\n",
    "        \n",
    "        super(SeqToSeqLSTM, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.init_h0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers) \n",
    "        self.init_c0 = nn.Linear(decoder.n_layers * 2, decoder.n_layers)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src_sequences, src_lengths, dest_sequences, dest_lengths, tf_ratio):\n",
    "        \"\"\"\n",
    "        :params\n",
    "            src_sequences: Tensor[seq_len, batch_size]\n",
    "            src_lengths: Tensor[batch_size,]\n",
    "            dest_sequences: Tensor[seq_len, batch_size]\n",
    "            dest_lengths: Tensor[batch_size,]\n",
    "            tf_ratio: float\n",
    "            \n",
    "        :return\n",
    "            logits: Tensor[max(decode_lengths), batch_size, vocab_size]\n",
    "            sorted_dest_sequences: Tensor[seq_len, batch_size]\n",
    "            sorted_decode_lengths: Tensor[batch_size,]\n",
    "            sorted_indices: Tensor[batch_size,]\n",
    "        \"\"\"\n",
    "        # Encoding\n",
    "        _, h_state, c_state = self.encoder(\n",
    "            input_sequences=src_sequences,\n",
    "            sequence_lengths=src_lengths\n",
    "        )\n",
    "        # h_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        # c_state: [n_layers * 2, batch_size, hidden_size]\n",
    "        \n",
    "        # Sort the batch (dest) by decreasing lengths\n",
    "        sorted_dest_lengths, sorted_indices = torch.sort(dest_lengths, dim=0, descending=True)\n",
    "        sorted_dest_sequences = dest_sequences[:, sorted_indices]\n",
    "        \n",
    "        # Init hidden and memory states\n",
    "        h_state = self.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        c_state = self.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "        h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "        \n",
    "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>\n",
    "        # So, decoding lengths are actual lengths - 1\n",
    "        sorted_decode_lengths = (sorted_dest_lengths - 1).tolist()\n",
    "        \n",
    "        # Decoding\n",
    "        batch_size, last = dest_sequences.size(1), None\n",
    "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
    "        for t in range(max(sorted_decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
    "            if last is not None:\n",
    "                if random.random() < tf_ratio:\n",
    "                    in_ = last[:batch_size_t]\n",
    "                else:\n",
    "                    in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            else:\n",
    "                in_ = sorted_dest_sequences[t, :batch_size_t]\n",
    "            # in_ [batch_size,]\n",
    "            logit, h_state, c_state = self.decoder(\n",
    "                in_, \n",
    "                h_state[:, :batch_size_t, :].contiguous(),\n",
    "                c_state[:, :batch_size_t, :].contiguous()\n",
    "            )\n",
    "            # logit: [batch_size, vocab_size]\n",
    "            # h_state: [num_layers, batch_size, hidden_size]\n",
    "            # c_state: [num_layers, batch_size, hidden_size]\n",
    "            logits[t, :batch_size_t, :] = logit\n",
    "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
    "        \n",
    "        return logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_seq2seq():\n",
    "    batch_size = 128\n",
    "    train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=batch_size,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True)\n",
    "    encoder = EncoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(FR.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    decoder = DecoderLSTM(\n",
    "        embedding_size=300,\n",
    "        vocab_size=len(EN.vocab),\n",
    "        hidden_size=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.25,\n",
    "        recurrent_dropout=0.25\n",
    "    )\n",
    "    model = SeqToSeqLSTM(encoder, decoder, device='cpu')\n",
    "    for data in train_iterator:\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(\n",
    "                src_sequences=data.src[0], \n",
    "                src_lengths=data.src[1],\n",
    "                dest_sequences=data.dest[0],\n",
    "                dest_lengths=data.dest[1],\n",
    "                tf_ratio=0.\n",
    "            )\n",
    "        assert logits.size() == torch.Size([\n",
    "            max(sorted_decode_lengths),\n",
    "            batch_size,\n",
    "            len(EN.vocab)\n",
    "        ]), logits.size()\n",
    "        assert sorted_dest_sequences.size() == torch.Size([\n",
    "            data.dest[0].shape[0],\n",
    "            batch_size\n",
    "        ]), sorted_dest_sequences.size()\n",
    "        assert len(sorted_decode_lengths) == batch_size, len(sorted_decode_lengths)\n",
    "        assert sorted_indices.size() == torch.Size([\n",
    "            batch_size,\n",
    "        ]), sorted_indices.size()\n",
    "        break\n",
    "        \n",
    "test_seq2seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, loader, epoch, grad_clip, tf_ratio, device):\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, data in pbar:\n",
    "        # Forward prop.\n",
    "        logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "            model(*data.src, *data.dest, tf_ratio=tf_ratio)\n",
    "        # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "        sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "        # Remove paddings\n",
    "        logits = nn.utils.rnn.pack_padded_sequence(\n",
    "            logits,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "            sorted_dest_sequences,\n",
    "            sorted_decode_lengths\n",
    "        ).data\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, sorted_dest_sequences)\n",
    "        # Back prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            torch_utils.clip_gradient(optimizer, grad_clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track metrics\n",
    "        loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "        acc_tracker.update(\n",
    "            torch_utils.accuracy(logits, sorted_dest_sequences, 1),\n",
    "            sum(sorted_decode_lengths)\n",
    "        )\n",
    "        # Update progressbar description\n",
    "        pbar.set_description(f'Epoch: {epoch + 1:03d} - loss: {loss_tracker.average:.3f} - acc: {acc_tracker.average:.3f}%')\n",
    "    return loss_tracker.average, acc_tracker.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, loader, field, epoch, device):\n",
    "    references, hypotheses = [], []\n",
    "    loss_tracker, acc_tracker = utils.AverageMeter(), utils.AverageMeter()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar: \n",
    "            # Forward prop.\n",
    "            logits, sorted_dest_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "                model(*data.src, *data.dest, tf_ratio=0.)\n",
    "            # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "            sorted_dest_sequences = sorted_dest_sequences[1:, :]\n",
    "            # Remove paddings\n",
    "            logits_copy = logits.clone()\n",
    "            logits = nn.utils.rnn.pack_padded_sequence(\n",
    "                logits,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            sorted_dest_sequences = nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_dest_sequences,\n",
    "                sorted_decode_lengths\n",
    "            ).data\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, sorted_dest_sequences)\n",
    "            # Track metrics\n",
    "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "            acc_tracker.update(\n",
    "                torch_utils.accuracy(logits, sorted_dest_sequences, 1),\n",
    "                sum(sorted_decode_lengths)\n",
    "            )\n",
    "            # Update references\n",
    "            target_sequences = data.dest[0].t()[sorted_indices]\n",
    "            for j in range(target_sequences.size(0)):\n",
    "                target_sequence = target_sequences[j].tolist()\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in target_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "            # Update hypotheses\n",
    "            _, preds = torch.max(logits_copy, dim=2)\n",
    "            preds = preds.t().tolist()\n",
    "            for j, p in enumerate(preds):\n",
    "                hypotheses.append([\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in preds[j][:sorted_decode_lengths[j]] # Remove padding\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ])\n",
    "            assert len(references) == len(hypotheses)\n",
    "            # Update progressbar description\n",
    "            pbar.set_description(f'Epoch: {epoch + 1:03d} - val_loss: {loss_tracker.average:.3f} - val_acc: {acc_tracker.average:.3f}%')\n",
    "        # Calculate BLEU-4 score\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "        # Display some examples\n",
    "        for i in np.random.choice(len(loader), 3):\n",
    "            src, dest = ' '.join(references[i][0]), ' '.join(hypotheses[i])\n",
    "            display(HTML(f'<span style=\"color:blue\"><b>Ground truth translation:</b> {src}</span>'))\n",
    "            display(HTML(f'<span style=\"color:red\"><b>Predicted translation:</b> {dest}</span>'))\n",
    "            print('='*100)\n",
    "    return loss_tracker.average, acc_tracker.average, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, valid_loader, field, n_epochs, grad_clip, tf_ratio, last_improv, model_name, device):\n",
    "    history, best_bleu = {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_loss': [],\n",
    "        'bleu4': []\n",
    "    }, 0.\n",
    "    for epoch in range(n_epochs):\n",
    "         # Stop training if no improvment since last 4 epochs\n",
    "        if last_improv == 4:\n",
    "            print('Training Finished - The model has stopped improving since last 4 epochs')\n",
    "            break\n",
    "        # Decay LR if no improvment\n",
    "        if last_improv > 0:\n",
    "            torch_utils.adjust_lr(optimizer=optimizer,\n",
    "                                  shrink_factor=0.9,\n",
    "                                  verbose=True)\n",
    "        # Train step\n",
    "        loss, acc = train_step(model=model,\n",
    "                               optimizer=optimizer,\n",
    "                               criterion=criterion,\n",
    "                               loader=train_loader,\n",
    "                               epoch=epoch,\n",
    "                               grad_clip=grad_clip, \n",
    "                               tf_ratio=tf_ratio,\n",
    "                               device=device)\n",
    "        # Validation step\n",
    "        val_loss, val_acc, bleu4 = validate(model=model,\n",
    "                                            criterion=criterion,\n",
    "                                            loader=valid_loader,\n",
    "                                            field=field,\n",
    "                                            epoch=epoch,\n",
    "                                            device=device)\n",
    "        # Update history dict\n",
    "        history['acc'].append(acc)\n",
    "        history['loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['bleu4'].append(bleu4)\n",
    "        # Print BLEU score\n",
    "        text = f'BLEU-4: {bleu4*100:.3f}%'\n",
    "        if bleu4 > best_bleu:\n",
    "            best_bleu, last_improv = bleu4, 0\n",
    "        else:\n",
    "            last_improv += 1\n",
    "            text += f' - Last improvement since {last_improv} epoch(s)'\n",
    "        print(text)\n",
    "        # Decrease teacher forcing rate\n",
    "        tf_ratio = torch_utils.adjust_tf(tf_ratio,\n",
    "                                         shrink_factor=0.8,\n",
    "                                         verbose=False)\n",
    "        # Save checkpoint\n",
    "        torch_utils.save_checkpoint(model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    data_name=model_name,\n",
    "                                    epoch=epoch,\n",
    "                                    last_improv=last_improv,\n",
    "                                    bleu4=bleu4,\n",
    "                                    is_best=bleu4 >= best_bleu)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word vectors\n",
    "spacy_fr = spacy.load('fr_core_news_lg') # CBOW trained word vectors\n",
    "spacy_en = spacy.load('en_core_web_lg') # GloVe trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11832/11832 [01:54<00:00, 103.79it/s]\n",
      "100%|██████████| 8781/8781 [01:15<00:00, 115.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "fr_embeddings = torch_utils.load_embeddings(nlp=spacy_fr, field=FR)\n",
    "en_embeddings = torch_utils.load_embeddings(nlp=spacy_en, field=EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq-lstm'\n",
    "N_LAYERS = 1\n",
    "HIDDEN_SIZE = 128\n",
    "EMBEDDING_SIZE = 300\n",
    "ENC_DROPOUT = 0.\n",
    "ENC_RECURRENT_DROPOUT = 0.\n",
    "DEC_DROPOUT = 0.\n",
    "DEC_RECURRENT_DROPOUT = 0.\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "GRAD_CLIP = 1.0\n",
    "TF_RATIO = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 1,791,171\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLSTM(\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    vocab_size=len(FR.vocab),\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=ENC_DROPOUT,\n",
    "    recurrent_dropout=ENC_RECURRENT_DROPOUT\n",
    ")\n",
    "encoder.load_pretrained_embeddings(fr_embeddings)\n",
    "encoder.fine_tuning_embeddings(fine_tune=False)\n",
    "decoder = DecoderLSTM(\n",
    "    embedding_size=EMBEDDING_SIZE,\n",
    "    vocab_size=len(EN.vocab),\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DEC_DROPOUT,\n",
    "    recurrent_dropout=DEC_RECURRENT_DROPOUT\n",
    ")\n",
    "decoder.load_pretrained_embeddings(en_embeddings)\n",
    "decoder.fine_tuning_embeddings(fine_tune=False)\n",
    "seq2seq = SeqToSeqLSTM(encoder=encoder, decoder=decoder, device=DEVICE)\n",
    "# seq2seq.apply(torch_utils.xavier_init_weights)\n",
    "seq2seq.to(DEVICE)\n",
    "optimizer = optim.RMSprop(params=seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f'Number of parameters of the model: {torch_utils.count_parameters(seq2seq):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator =  \\\n",
    "        BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              sort_key=lambda x: len(x.src),\n",
    "                              sort_within_batch=True,\n",
    "                              device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - loss: 5.604 - acc: 1.032%: 100%|██████████| 2773/2773 [02:05<00:00, 22.05it/s]\n",
      "Epoch: 001 - val_loss: 5.599 - val_acc: 1.017%: 100%|██████████| 347/347 [00:09<00:00, 36.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> we have abandoned that route <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is the <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> lastly i should like to talk about article <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is the <eos> <eos> <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> this is absolutely selfevident <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 0.000% - Last improvement since 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2773 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 - loss: 5.435 - acc: 1.121%: 100%|██████████| 2773/2773 [02:05<00:00, 22.03it/s]\n",
      "Epoch: 002 - val_loss: 4.778 - val_acc: 1.587%: 100%|██████████| 347/347 [00:10<00:00, 34.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> this measure will boost europes <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is be <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> five out of more than seventy <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the of of the <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 3.230%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003 - loss: 5.142 - acc: 1.317%: 100%|██████████| 2773/2773 [02:07<00:00, 21.83it/s]\n",
      "Epoch: 003 - val_loss: 4.475 - val_acc: 1.785%: 100%|██████████| 347/347 [00:09<00:00, 36.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> let us hear them <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the us not that <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> what is actually the ideal situation <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the not <eos> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> that derogation expires in december <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the <eos> the <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 4.592%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004 - loss: 4.890 - acc: 1.480%: 100%|██████████| 2773/2773 [02:06<00:00, 21.84it/s]\n",
      "Epoch: 004 - val_loss: 4.293 - val_acc: 1.895%: 100%|██████████| 347/347 [00:09<00:00, 36.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> so that is absolutely clear <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the what is not important <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> both of these tracks are essential <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the the the are are <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> i want transparency at a high level <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the have to <eos> the few level <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 5.164%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005 - loss: 4.685 - acc: 1.616%: 100%|██████████| 2773/2773 [02:07<00:00, 21.75it/s]\n",
      "Epoch: 005 - val_loss: 4.169 - val_acc: 1.981%: 100%|██████████| 347/347 [00:09<00:00, 36.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> some countries have clearly demonstrated this <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the of have been been <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the third is national taxation <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is point the <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> that is the greatest and most important challenge <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the the <eos> <eos> important <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 5.917%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006 - loss: 4.508 - acc: 1.734%: 100%|██████████| 2773/2773 [02:06<00:00, 21.87it/s]\n",
      "Epoch: 006 - val_loss: 4.077 - val_acc: 2.056%: 100%|██████████| 347/347 [00:09<00:00, 36.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> there is a lack of innovation <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is no a of <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> thank you very much mr <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the you very much commissioner president <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> we still have a long way to go <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the are have a lot way <eos> do <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 6.919%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007 - loss: 4.353 - acc: 1.835%: 100%|██████████| 2773/2773 [02:07<00:00, 21.78it/s]\n",
      "Epoch: 007 - val_loss: 4.007 - val_acc: 2.100%: 100%|██████████| 347/347 [00:09<00:00, 36.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the choice is yours <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is not <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> various members will now speak <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the amendments have be <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> reconstruction is not enough <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the of the a <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 7.100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008 - loss: 4.230 - acc: 1.918%: 100%|██████████| 2773/2773 [02:06<00:00, 21.94it/s]\n",
      "Epoch: 008 - val_loss: 3.952 - val_acc: 2.142%: 100%|██████████| 347/347 [00:09<00:00, 37.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> there were five <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is two points <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> i do not think so <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the would not think that <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> that is not how matters should proceed <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the the we <eos> be <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 7.574%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009 - loss: 4.120 - acc: 1.993%: 100%|██████████| 2773/2773 [02:06<00:00, 21.87it/s]\n",
      "Epoch: 009 - val_loss: 3.911 - val_acc: 2.169%: 100%|██████████| 347/347 [00:10<00:00, 34.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> it is now time to act <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is a a <eos> do <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> this programme must be continued <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is be <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> this treaty has to be ratified <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is is been be <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 7.947%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010 - loss: 4.032 - acc: 2.052%: 100%|██████████| 2773/2773 [02:07<00:00, 21.78it/s]\n",
      "Epoch: 010 - val_loss: 3.874 - val_acc: 2.205%: 100%|██████████| 347/347 [00:09<00:00, 36.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> on the contrary they occupy an important place <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the the contrary it are the <unk> <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the law must be respected <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the vote is be respected <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> let me try to contribute to this <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the us make to make a the <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.213%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011 - loss: 3.948 - acc: 2.111%: 100%|██████████| 2773/2773 [02:07<00:00, 21.82it/s]\n",
      "Epoch: 011 - val_loss: 3.851 - val_acc: 2.220%: 100%|██████████| 347/347 [00:09<00:00, 36.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> thank you very much mrs theato <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the you very much commissioner <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> what is likely to happen <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the to be <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the joint debate is closed <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the sitting debate is closed <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.265%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012 - loss: 3.879 - acc: 2.160%: 100%|██████████| 2773/2773 [02:07<00:00, 21.75it/s]\n",
      "Epoch: 012 - val_loss: 3.821 - val_acc: 2.239%: 100%|██████████| 347/347 [00:09<00:00, 37.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> that is not how matters should proceed <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is the the we <eos> be <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> is there any opposition <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the it any other to</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the commission is the enemy of the <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the vote is not same <eos> the <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.421%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013 - loss: 3.823 - acc: 2.197%: 100%|██████████| 2773/2773 [02:06<00:00, 21.90it/s]\n",
      "Epoch: 013 - val_loss: 3.819 - val_acc: 2.242%: 100%|██████████| 347/347 [00:09<00:00, 36.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> parliament agreed to accept the oral amendment <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the adopted to the the oral amendment <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> competition is an economic necessity <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is a important issue <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2773 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.336% - Last improvement since 1 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000810\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014 - loss: 3.765 - acc: 2.234%: 100%|██████████| 2773/2773 [02:06<00:00, 21.95it/s]\n",
      "Epoch: 014 - val_loss: 3.794 - val_acc: 2.262%: 100%|██████████| 347/347 [00:09<00:00, 36.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> this was important for our assessment <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is a <eos> us citizens <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> it unreservedly condemns <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the is support the <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> the house rose to applaud mrs fontaine <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the vote rose and the the <unk> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.624%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015 - loss: 3.734 - acc: 2.258%: 100%|██████████| 2773/2773 [02:06<00:00, 21.87it/s]\n",
      "Epoch: 015 - val_loss: 3.784 - val_acc: 2.272%: 100%|██████████| 347/347 [00:09<00:00, 36.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> we did our homework <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the are not work to</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> composition of committees see minutes <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the of parliament see minutes <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"><b>Ground truth translation:</b> they are the big losers <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:red\"><b>Predicted translation:</b> the are not right <eos> <eos></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLEU-4: 8.712%\n"
     ]
    }
   ],
   "source": [
    "history = train(model=seq2seq,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=train_iterator,\n",
    "                valid_loader=valid_iterator,\n",
    "                field=EN,\n",
    "                n_epochs=N_EPOCHS,\n",
    "                grad_clip=GRAD_CLIP,\n",
    "                tf_ratio=TF_RATIO,\n",
    "                last_improv=0,\n",
    "                model_name=MODEL_NAME,\n",
    "                device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAFNCAYAAADLm0PlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3iUZdbH8e9JIQkJIRBIQpNQpYTeO2LBAtgQUeyvYkOsa1td2NVVd3XtgoKiuKLIorgWRCwEROnSe68JEEogJIGU8/4xEzaEJKTM5Jkk53Ndc83kqb8k8MzJPfdz36KqGGOMMcYYY0rPz+kAxhhjjDHGVBRWXBtjjDHGGOMhVlwbY4wxxhjjIVZcG2OMMcYY4yFWXBtjjDHGGOMhVlwbY4wxxhjjIVZcG5MPEblNROYXsv57Ebm1LDMZY4ypOERERaRpAetGiMjsss5kPMOKa+PTRGSHiFzkdI68VPUyVZ18ru0Ku3gaY0xRiUi8iBwRkSCns3iLuPxLRA65H9OLsE+8iKSLSIqIJIvIPBFpk2v9WBH5pIB9d4hImnvfnMfbhe1X1Gu6iEwqzfVfVaeo6iVFOM9HIvJ8Sc5hvMeKa2N8lIgEOJ3BGOM8EYkF+gAKDCnjc5fldegS4CagHVAXeK+I+41S1TCgJhAP/LsY5xysqmG5HqOKEzg/ItIbaFLa45QFEfF3OkNFZMW1KbdE5C4R2SIih0XkaxGp614uIvKaiBwQkWMislpE4tzrLheRdSJyXET2ishj5zjHK+7Wou0iclmu5fEicqf7dVMRmetuNUkSkc/dy+e5N1/pbhG5vrDc7nUqIveLyGZgs4i8IyL/ypPpaxF5uPQ/QWNMOXELsBD4CDijO5qIhLhbe3e6r0HzRSTEva63iPwuIkdFZLeI3OZefvr65f76jG5wea9D7mVvuI9xTESWiUifXNv7i8jTIrLVfW1dJiINSnD9ygDSgERVPamqPxbnh6SqWcBUoFVx9vMk9x8jbwEPFHGXi0Rks/t39I6IiPs4p38nBb2nichIYATwuPs95hv39i3dv+OjIrJWRE7/QeZu6R4vIjNF5ATwiIjsz11ki8g1IrLSMz+RysmKa1MuicgA4EVgGFAH2Inrogqu1o++QHOgunubQ+51HwB3q2o1IA74pZDTdAM2ArWAfwIf5Fz48ngOmA3UAOrjurCiqn3d69u5W0Q+P0fuHFe5z90KmAzcICJ+7u+7FnAR8GkhuY0xFcstwBT3Y6CIROda9wrQCeiJq+X2cSBbRBoC3+O6HtUG2gMrinHO3NchgCXuY9TEdf35j4gEu9c9AtwAXA6EA3cAqRT/+rXBffz3c/YpDhGpgqvYXFjcfT3oYWCeqq4q4vaDgC5AW1zvCwPz2Sbf9zRVnYDr38Q/3e8xg0UkEPgG13tSFK4if4qInJ/reDcCfweq4fr3cch9jhw3Ax8XMb/JhxXXprwaAUxS1T9U9STwFNBDXB+fZuC6aLQARFXXq2qCe78MoJWIhKvqEVX9o5Bz7FTVie7WkMm4iuHofLbLABoCdVU1XVULvBHyHLlzvKiqh1U1TVUXA8nAhe51w4F4Vd1fyDmMMRWEuLoYNASmqeoyYCuu4gh3AXoH8KCq7lXVLFX93X1tuRH4SVU/U9UMVT2kqsUprk9fhwBU9RP3MTJV9V9AEJBTsN0JPKOqG9VlpXvbIl+/3EXhD8B9uBoq3s9VlM8XkcGFZH1TRI4Cx4FRwF+L8X1+5W7hzXncVYx9zyAiDYC7gb8UY7eXVPWoqu4C5uD6Ayavwt7T8uoOhLmPe0pVfwG+xfXHT47/qupvqpqtqum43t9ucn8PNXEV+NaAUwpWXJvyqi6uVl8AVDUF11/f9dwXk7eBd4ADIjJBRMLdm16Lq3Vlp7srR49CzpGY6/ip7pdh+Wz3OCDAYvdHcHeUJHeubXbn2ef0hc/9XJz+hMaY8u1WYLaqJrm//pT/dQ2pBQTjKrjzalDA8qI64zokIo+JyHp315OjuFpQaxXhXEW9fg0AqqjqJ8D1QCNcBXY4rqKysEaL0aoaAYTgagmeLiJtC/3u/ucqVY3I9ZjoXp4JBObe0P0HAECGiPSR/90Euda9/HXgb6qaXMRzQ673GVyt/We9x5zjPS2vusBuVc3OtWwnhb/HfAIMFpFQXK3ivxZSvJsisOLalFf7cLXmAOC+KEQCewFU9U1V7YTrI83mwJ/cy5eo6pW4Pi77CphW2iCqmqiqd6lqXVytFuOk4DvEC82dc8g8+3wCXCki7YCW7tzGmArO3Xd6GNBPRBJFJBFXt4N27utBEpBO/jfP7S5gOcAJoGqur2Py2eb0dcjdv/pxd5Ya7kI2GVejwrnOVdTrVwDuYtbdmjoEV1eJJcBUVT1SwH7/C+xqif0V2MKZ3RxKYhcQm2dZI1xF915V/TXXTZCt3esvBF7O9bsCWCAiN5YyS4HvaZz9frEPaJCnW815FPIeo6p7gQXANbi6hFgDTilZcW3Kg0ARCc71CAA+A24XkfbiGprqBWCRqu4QkS4i0s3dynAC15tPtohUEdfYodVVNQM4BmQXeNYiEpHrRKS++8sjuC5cOcfdDzTOtXmBuQs6vqruwfUG82/gi5yPaY0xFd5VQBaugqq9+9ES+BW4xd06OQl4VUTqiuvGwh7ua8sUXDfLDRORABGJFJGcLgcrgGtEpKq7IeD/zpGjGq6i8iAQICJ/wdW3Osf7wHMi0sx9811bEYmEYl2/5gPBIvI39x8Vfri6STTH1aJbJO5PI1sBa3Mt9svzHlKU4QxnAS1E5GYRCXR3l3jB/T1kFrBPc1wjneT8rgAGAzOKmj8/Bb2nuVfnfY9ZhOvn9bg7d393hrz39uT1Ma4/oNoAX5Ymr7Hi2pQPM3HdQZ7zGKuqPwHPAl8ACbhaTYa7tw8HJuIqdHfi6nbxsnvdzcAOETkG3IOrD3RpdQEWiUgK8DWu/o/b3OvGApPdffmGnSN3YSbjuuhZi4IxlcetwIequsv9CVmiqibi6iIwwt3Q8BiwGlcBexj4B+Dn7sN7OfCoe/kKXIUfwGvAKVyF2WRchXhhfsBVbG7CdU1N58yuBa/i+hRwNq5Giw9wddHIcc7rl7srxSW4+gzvw9XNJBLoiqtBorC+0G/ndNFwn+MZVf0+1/obOPM9JHcXlm/kzHGuZ7jzHAAuw/Vp5AFgDXAUuLeQ7+FAnt8TQJIHGkQKe0/7ANd9REdF5CtVPYWrmL4M1ycb43D9IbbhHOeYgetT1Rm5ukGaEhLVvJ8oGGN8jYj0xfXxakO1/7TGmHLErl/lg4hsxTWa1k9OZynvrOXaGB/n/ijwQeB9e2MyxpQndv0qH0TkWlxdGgsbntYUkRXXxvgwEWmJ66PIOrjuRDfGmHLBrl/lg4jEA+OB+/OMMmJKyLqFGGOMMcYY4yHWcm2MMcYYY4yHWHFtjDHGGGOMhwQ4HcCTatWqpbGxscXa58SJE4SGhnonkAf4cj5fzgaWrzR8ORv4dr6SZlu2bFmSqtb2QiSfVZJrNlTM339Z8eV8vpwNfDufL2cD387nlWu2qlaYR6dOnbS45syZU+x9ypIv5/PlbKqWrzR8OZuqb+craTZgqfrAdbQsHyW5ZqtWzN9/WfHlfL6cTdW38/lyNlXfzueNa7Z1CzHGGGOMMcZDrLg2xhhjjDHGQ6y4NsYYY4wxxkMq1A2NxhhjyreMjAz27NlDenp6gdtUr16d9evXl2GqovNmtuDgYOrXr09gYKBXjm+M8Qwrro0xxviMPXv2UK1aNWJjYxGRfLc5fvw41apVK+NkReOtbKrKoUOH2LNnD40aNfL48Y0xnmPdQowxxviM9PR0IiMjCyysKysRITIystAWfWOMb7Di2hhjjE+xwjp/9nMxpnyw4toYY4xxO3r0KOPGjSv2fpdffjlHjx71QiJjTHljxbUxxhjjVlBxnZmZWeh+M2fOJCIiwluxjDHlSKUurk+czOT77RlkZ6vTUYwxxviAJ598kq1bt9K+fXu6dOlCnz59GDJkCK1atQLgqquuolOnTrRu3ZoJEyac3i82NpakpCR27txJy5Ytueuuu2jdujWXXHIJaWlpTn07xph8pGaksvnIZubunsvcY3PJys7y6PEr9Wghy37+D7dv/ztvffseDw7p5XQcY4wxDnvppZdYs2YNK1asID4+niuuuII1a9acHqFj0qRJ1KxZk7S0NLp06cK1115LZGTkGcfYvHkzn332GRMnTmTYsGF88cUX3HTTTU58O8ZUSqkZqSScSGBvyl72puxlX8q+M56PnjyzC9fdaXcTExrjsfNX6uK6T4u6yOLdPL/wVybXqsetPWOdjmSMMcbtr9+sZd2+Y2ctz8rKwt/fv0THbFU3nDGDWxd5+65du54x9N2bb77JjBkzANi9ezebN28+q7hu1KgR7du3B6BTp07s2LGjRFmNMflLz0xn34l97EtxPfak7Dn9em/KXg6nHz5j+yp+VagbVpd6YfVoFdmKemH1qBdWj7phddmxagfRVaM9mq9SF9cS0waAK2MO8/g3a4kOD+LSuDoOpzLGGOMrQkNDT7+Oj4/np59+YsGCBVStWpX+/fvnOzReUFDQ6df+/v7WLcQYD9iXso//bPoP3277lsQTiWesC/ALoG6oq3i+oMEFZxTP9cLqERkSiZ/k3xP6sP9hj4/EU6mLa6rW5GSVSK6pd5TPAiJ4cOoKptwZROfYmk4nM8aYSq+gFmZvTiJTrVo1jh8/nu+65ORkatSoQdWqVdmwYQMLFy70SgZjjEu2ZvPb3t+YtnEac/fMRUToU68PQ5sNpW5YXepXq0/d0LrUrlq7wOLZCZW7uAZSwmKJPLCW92/twtDxv3Pnx0v54t6eNKkd5nQ0Y4wxZSwyMpJevXoRFxdHSEgI0dH/+7j40ksv5d1336Vly5acf/75dO/e3cGkxlRcR9KP8NWWr5i2cRp7UvYQGRzJXW3vYmizodQJ8/0eBlZch8USuedragbBR7d35Zrxv3HrpMV8eV9PoqoFOx3PGGNMGfv000/zXR4UFMT333+f77qcftVBQUGsWbPm9PLHHnvM4/mMqYhUldVJq/l84+fM2j6LU9mn6BTdiQc7PsiF511IoH+g0xGLrNIX1ydCYyE7A5I2cV5MHJNu68LwCQu546MlTB3Zg7CgSv8jMsYYY4zxitSMVL7f/j2fb/yc9YfXUzWgKlc3u5rrz7+eZjWaOR2vRCp95ZgSFut6sX8txMTRtn4E74zoyJ2Tl3LflD/44NbOBPr7Tj8eY4wxxhhvSc1IJTUzlcjgSI/f6Jfb9uTtTNs4jf9u+S/HM47TrEYznun2DIOaDCI0MPTcB/Bhlb64TgupB/5BsH81cD0AF5wfxYtXt+HxL1bx1JereXloW6/+AzPGGGOMKWuqyu7ju1lxcAUrD6xk5cGVbD66mWzNPj18XZ3QOmc81w2re/omwgC/4pWRmdmZxO+OZ+rGqSxKWESAXwAXN7yY4ecPp0NUhwpTa1X64lr9/CGqBSSuOWP5sC4N2Jecxus/baZuRAiPXNzcoYTGGGOMMaWXmpHK2kNrWXlw5eli+sjJIwCEBobSplYbRrYdSURQBAkpCew7sY+ElATm7J5z1tjR/uJPdNVo6oTVoW5o3dOFd+5ivIp/FQCSM5MZv2I80zdN50DaAeqE1mF0h9Fc3exqaoXUKvOfg7d5tbgWkR3AcSALyFTVznnW9wf+C2x3L/pSVf/mXncp8AbgD7yvqi95LWh0G9g8+6zFD17YjISj6bz582bqVA/mhq7neS2CMcYYY4ynqCp7Uvaw8uBKVhxYwaqDq9h0ZBNZ6prqOzY8lr71+9Iuqh3tarejSfUm+PsVPDlTWmYaCScSzii6c56X7F/Cge0HyNbsM/apFVKL2iG12Xh4I9l7s+lVrxfPnv8sfer1KfRc5V1ZtFxfoKpJhaz/VVUH5V4gIv7AO8DFwB5giYh8rarrvJIwJg5WfAIpByAsKncOnr86jv3H03nmqzVEhwcxoIVnZ/ExxhhjjCmttMw01ia5W6Xdj5zW5qoBVWlTqw13xN1B+6j2tK3VlojgiGIdPyQghMbVG9O4euN812dkZ7D/xH4STiS4Zkt0F96JJxK5IPwCHrnwEc4LrxyNlL7aLaQrsEVVtwGIyFTgSsA7xXW0e6KCxNXQ9MIzVgX6+/HOjR0ZPmEh909ZztSR3WnXoHj/II0xxlRMYWFhpKSksG/fPkaPHs2HH3541jb9+/fnlVdeoXPnzvkcwZiCZWs2x08dJ/lkMkdPHj39OJJ+5IxlGxI2kPBpApmaCUDD8Ib0rtebdrVdrdJNI5p6vaU40C+Q+tXqU79a/bPWxcfHV5rCGrxfXCswW0QUeE9VJ+SzTQ8RWQnsAx5T1bVAPWB3rm32AN28ljI6zvW8f+1ZxTVAaFAAk27rwjXjf+OOj5bw5X09aRhZvu9kNcYY4zl169Zl+vTpBc7uaEyOrOws1h1ax8G0gySfTObIySMcPXnU9dpdNB856XpOPpl8uhtHXv7iT/Wg6kQERRDiF8JtcbfRrnY72tZuS81gm2naSd4urnur6l4RiQJ+FJENqjov1/o/gIaqmiIilwNfAcUa1FBERgIjAaKjo4mPjy9WwJSUFOIXr6J7UCRHV/3Mhoy2BW57f2t4fuEphr0zlz93DyG8ivfvak1JSSn291RWfDkbWL7S8OVs4Nv5fDmbObcnn3ySBg0acP/99wMwduxYAgICmDNnDkeOHCEjI4Pnn3+eK6+88oz9duzYwaBBg1iwYAFpaWncfvvtrFy5khYtWpCWlubEt2J8zK5ju/hqy1d8vfVr9qfuP2NdFb8qRARFEBEcQURQBE0jmlIjqMbp4rlGcK7XQTWoHlydsMCw01N+x8fH079jfwe+K5MfrxbXqrrX/XxARGbg6u4xL9f6Y7lezxSRcSJSC9gLNMh1qPruZfmdYwIwAaBz587av3//YmWMj4+nf//+sLcTMcf2EXOO/ZvFHeHGiQuZtLkKn93VnZAq3v2Y5XQ+H+TL2cDylYYvZwPfzufL2cy5XX/99Tz00EOni+tp06bxww8/MHr0aMLDw0lKSqJ79+4MGTKkwGHDxo8fT9WqVVm/fj2rVq2iY8eOZfktGB+SmpHKjzt/ZMaWGSzbvww/8aNn3Z482vlRGoY3dBXUQRGEBIRUmGHojBeLaxEJBfxU9bj79SXA3/JsEwPsV1UVka6AH3AIOAo0E5FGuIrq4cCN3soKuLqGbJ0DmacgoEqBm3VqWIM3b+jAvZ8s44HPlvPuTR0JsElmjDHG875/0nUvTB4hWZngX8K3r5g2cFnBg0916NCBAwcOsG/fPg4ePEiNGjWIiYnh4YcfZt68efj5+bF37172799PTExMvseYN28eo0ePBqBt27a0bVvwJ6Km4lFVVh5cyYwtM5i1fRapmak0DG/Igx0fZHDjwUSH2sAIFZ03W66jgRnuv8QCgE9VdZaI3AOgqu8CQ4F7RSQTSAOGq6oCmSIyCvgB11B8k9x9sb2YtrV7GvSNrotvIQa2jmHskNb85b9rGfvNWp67Ms7+4jTGVHoi8jBwJ677bVYDt6tqurOpiu+6665j+vTpJCYmcv311zNlyhQOHjzIsmXLCAwMJDY2lvT0cvdtGS87mHqQr7d+zVdbvmLHsR2EBIQwMHYgVze9ukJNkGLOzWvFtXukj3b5LH831+u3gbcL2H8mMNNb+c6SU1DvX3vO4hrglh6x7Duazrtzt1Knegj3X9DUywGNMcZ3iUg9YDTQSlXTRGQark8dPyrxQQtoYU47fpxq1aqV+LDncv3113PXXXeRlJTE3LlzmTZtGlFRUQQGBjJnzhx27txZ6P59+/bl008/ZcCAAaxZs4ZVq1Z5LatxVkZWBnP3zGXGlhn8tvc3sjSLjlEduSPuDgbGDqRqYFWnIxoH+OpQfGWvZhMICHZ9BNlueJF2eXzg+SQmp/HyDxupUz2YazqePfyMMcZUIgFAiIhkAFVxjQJV7rRu3Zrjx49Tr1496tSpw4gRIxg8eDBt2rShc+fOtGjRotD97733Xm6//XZatmxJy5Yt6dSpUxklN2Vl05FNzNg8g++2fceRk0eIConi9rjbubLJlcRWj3U6nnGYFdc5/AOgdgvYv+bc27r5+Qn/HNqOgykneXz6KmpXC6JPs9peDGmMMb7JPTLUK8AuXN38Zqvq2VPflhOrV/+vr3etWrVYsGBBvtulpKQAEBsby5o1azh+/DghISFMnTq1THKaspOalcrUDVOZsWUG6w6tI8AvgAsaXMBVTa+iZ92eBPhZSWVc7F9CbjFxsOmHYu1SJcCP8Td1Yti7C7j3kz/4/O7utK5b3UsBjTHGN4lIDVyTfTXCdVP6f0TkJlX9JM92hQ6fWr169XOOFZ2VleWz40l7O1t6enqphnr05aEifTXbgYwDzEqexfITy8nck0ndwLpcW+NaOod2JowwsrdkM3/LfEcz+urPLocv5/NGNiuuc4tuA8s/geP7oVrR7+YNDw7ko9u7cs243xj58TJ+frQfwYHeHaLPGGN8zEXAdlU9CCAiXwI9gTOK63MNn7p+/fpz9qc+7uU+16Xh7WzBwcF06NChxPv78lCRvpbtYOpB3l35Ll/s+oIq/lXoEdaDUf1H0bJmS5+7OdHXfnZ5+XI+b2SzMeRyy5kGff/ZQz+dS0z1YF4Z1o69R9P4dNEuDwczxhiftwvoLiJVxVV5XAisdziTMcV2/NRx3vzjTa6YcQVfbv6Soc2HMvOamQyLHEaryFY+V1gb32Mt17mdLq7XQtOLir17zya16NE4knHxW7mh63len2DGGGN8haouEpHpuGbezQSW426hNqY8OJl1kqkbpjJx9USSTyZzWexljOowivPCz3M6milnrLjOrWpNCK8HiUW/qTGvRy9pztB3F/DvhTsY2beJB8MZY4xvU9UxwBincxhTHFnZWXyz7RvGrRhHwokEetTpwYOdHqR1ZGuno5lyyorrvKLjXC3XJdQ5tiZ9m9fm3bnbuLFbQ8KC7EdsjDHG+BpVZe6eubzxxxtsObqF1pGt+Vuvv9G9Tneno5lyzvpc5xUT55qlMfNkiQ/xyMXNOXziFJN/3+G5XMYYY8qEv78/7du3p127dnTs2JHff/8dgB07dhAXF3fW9rfddhuNGjWiffv29OrVi549ewIwduxYXnnllTO2jY2NJSkpqcBzL1myhICAAKZPn+7B78jktfzAcm6ddSsP/PIAGdkZvNLvFT674jMrrI1HWLNqXtGtITsTDm6EOm1LdIj2DSK4qGUUE+Zt4+YeDQkPDvRwSGOMMd4SEhLCihUrAPjhhx946qmnmDt3bqH7vPzyywwdOrRUo4VkZWXxxBNPcMkll5Rof3NuW45s4Y3lbxC/O57aIbV5tvuzXN3sagL97H3aeI61XOcVnWsa9FJ46KLmJKdlMGn+dg+EMsYY44Rjx45Ro0aNMjnXW2+9xbXXXktUVFSZnK8ySUhJ4Jn5z3DtN9eyNHEpozuM5turv2XY+cOssDYeZy3XedVs7JoGvRgzNeYnrl51Lm0dwwe/bue2nrFEVK3ioYDGGGO8KS0tjfbt25Oenk5CQgK//PLLOff505/+xPPPP092djZt2rRhypQpxTrn3r17mTFjBnPmzGHJkiUljW7yOJp+lImrJzJ1g2vGzJtb3sydbe4kIjjC4WSmIrPiOi//AIhqCYnFH+s6r4cvbs4P6xKZ+Os2/jSwhQfCGWNM5fGPxf9gw+ENZy3PysrC379kQ522qNmCJ7o+Ueg2ubuFLFiwgFtuuYU1awpvcMmvW0hB4yHnt/yhhx7iH//4B35+9oGyJ6RmpDJl/RQmrZlEamYqQ5oM4b5291EnrI7T0UwlYMV1fqLjYONMUIVSDBZ/fkw1BrWty4e/7eCOXo2IDAvyYEhjjDHe1qNHD5KSkjh48GCx942MjCQhIeGMZcePHyciIoJ33nmHiRMnAjBz5kyWLl3K8OHDAUhKSmLmzJkEBARw1VVXlf6bqGQWJyzm2d+eZd+JffRv0J8HOzxI0xpNnY5lKhErrvMTHQfL/w0p+6FaTKkO9eCFzfhu1T4mzNvGU5e39FBAY4yp+ApqYS7L6c83bNhAVlYWkZGRpKamFmvfvn37MmLECJ588kmqVavGl19+Sbt27fD39+f+++/n/vvvP73t9u3/uz/ntttuY9CgQVZYF1NaZhqvL3udTzd8SsPwhnx06Ud0iu7kdCxTCVlxnZ8Y91BL+9eUurhuGhXGVe3rMXnBDv6vTyOiqgWXPp8xxhivyelzDa6xkCdPnny6G8rGjRupX7/+6W1fe+014Mw+135+fixevJi2bdsyatQoevfujYgQFRXF+++/X/bfUCWw4sAKnvntGXYe28mIliN4sOODhASEOB3LVFJWXOcnZxr0xDUlmgY9r9EXNuO/K/cxPn4rYwbbjE/GGOPLsrKy8l0eGxtLRkbGWcuvu+6606/ztqrffffd3H333cU6/0cffVSs7SuzU1mneGfFO3y09iNiqsbwwSUf0LVOV6djmUrO7pzIT0gNCK9f6hFDcsTWCmVox/pMWbSLhOQ0jxzTGGOMqczWHVrH9d9ez6Q1k7i66dV8MeQLK6yNT7DiuiAxpZsGPa9RA5qiqrwzZ4vHjmmMMcZUNhnZGYxfMZ4R340g+WQy4y4cx9ieYwmrEuZ0NGMAK64LFt0akjaVahr03BrUrMqwzg34fMlu9hwp3k0xxhhjjHHNsDjiuxGMWzmOgY0GMuPKGfSp38fpWMacwYrrgkTHuadBP3uM1ZIaNaApIsLbv1jrtTHGFERVnY7gkyrzzyUrO4sP13zIsG+HkXgikVf7v8pLfV6ielB1p6MZcxYrrgsS45lp0HOrUz2EG7uex3+W7WHnoRMeO64xxlQUwcHBHDp0qFIXkvlRVQ4dOkRwcOUbcWrXsV3cNus2Xl32Kn3r92XGlTO4uOHFTscypkA2WkhBajaGgBDXiCEedN8FTZi6ZBdv/LyZV4e19+ixjTGmvKtfvz579uwpdNKW9PR0ny0yvZktODj4jGEAK7pszZV3leAAACAASURBVObzjZ/z2rLXCJAAXuj9AoMaDypw5ktjfIUV1wXx83dNg+6hEUNyRFUL5ubuDflg/nbuv6ApTWrbDRjGGJMjMDCQRo0aFbpNfHw8HTp0KKNExePL2cqThJQEnv39WRYlLKJX3V6M7TmWmNDSzTthTFnxarcQEdkhIqtFZIWILM1n/QgRWeXe5ncRaVfUfctEdGtXce3hjyfv6deE4EB/3vhps0ePa4wxxpRnqsqMzTO4+uurWX1wNWN6jGH8ReOtsDblSln0ub5AVduraud81m0H+qlqG+A5YEIx9vW+mDaQegiOJ3r0sJFhQdzWM5ZvVu1jY+Jxjx7bGGOMKY+SM5MZ9cso/vL7X2hZsyVfDPmCoc2HWjcQU+442i1EVX/P9eVCwLc6k0XnTIO+FsLrePTQI/s25uMFO3n9p02Mv6mTR49tjDHGlAcns06y4sAKFiUsYkrCFLIkiye6PMGNLW/ET2zMBVM+ebu4VmC2iCjwnqrmbZnO7f+A70u4r3dEt3I9718NzUo/DXpuEVWrcEfvRrz582bW7kumdV0bTsgYY0zFlpmdydpDa1mUsIjFCYtZfmA5p7JP4S/+NA1qysuXvkyj6oX3uTfG13m7uO6tqntFJAr4UUQ2qOq8vBuJyAW4iuveJdh3JDASIDo6mvj4+GIFTElJKXSf7kG1SV71C+szPX+DyvkoVQPgmakLeLBj/neXnyufk3w5G1i+0vDlbODb+Xw5mzFlLVuz2Xxks6uYTlzM0v1LOZHhGor2/BrnM7zFcLrV6UbHqI4s/X2pFdamQvBqca2qe93PB0RkBtAVOKNAFpG2wPvAZap6qDj7utdPwN1Xu3Pnztq/f/9iZYyPj6fQffZ1JvjIDqKLedyi2u6/mVdmb6JGk/a0axBR/HwO8uVsYPlKw5ezgW/n8+VsxnibqrL7+G4WJixkceJiliQu4XD6YQAahjfkikZX0LVOV7rGdKVGcA2H0xrjHV4rrkUkFPBT1ePu15cAf8uzzXnAl8DNqrqpOPuWmejWsHk2ZKRDoOfHLr2tVyM+mL+dV3/cxOQ7unr8+MYYY4w37T+xn8WJi1mUsIhFiYtIPOEaBCCqahS96/Wma0xXutXpZiN+mErDmy3X0cAM912+AcCnqjpLRO4BUNV3gb8AkcA493aZ7pFB8t3Xi1kLFhMHmgVJG6FOu3NvX0xhQQHc068JL36/gWU7D9OpYU2Pn8MYY4zxpGOnjjFuxTh+2/sbO47tACAiKIIuMV24M+5OutXpRsPwhjbSh6mUvFZcq+o24Kxq1F1U57y+E7izqPs6ImfEkMQ1XimuAW7u0ZCJv27j1R83MeXO7l45hzHGGOMJqspff/8rP+/6mZ51ezK0+VC61elG8xrNbYQPY7AZGs8tZxp0D8/UmFvVKgHc278pz327joXbDtG9caTXzmWMMcaUxnfbv2P2ztmM7jCau9re5XQcY3yO/Yl5Ln7+riH5vFhcA4zodh7R4UG8OnsT6uEZIY0xxhhPSDyRyAsLX6B97fbcHne703GM8UlWXBdFdGtXtxAvFr3Bgf6MuqApi3ccZv6WJK+dxxhjjCmJbM3mmfnPkKmZvND7BQL87MNvY/JjxXVRRLeBtMNwPMGrpxnWpQF1qwfzL2u9NsYY42OmrJ/CosRFPNHlCRqEN3A6jjE+y4rroohu7Xrev9arpwkK8OeBC5uxYvdR4jce9Oq5jDHGmKLacmQLry97nf71+3NNs2ucjmOMT7PiuihyiuvE1V4/1dBO9TmvZlVe/dFar40xxjgvIyuDp+Y/RViVMMb0HGPD6xlzDlZcF0VIBFQ/z+st1wCB/n6MvrAZq/cmM3vdfq+fzxhjjCnMuJXj2HB4A2N6jKFWSC2n4xjj86y4Lqro1l4fMSTHVe3r0rhWKK/9uIlsa702xhjjkD/2/8GkNZO4ptk1DDhvgNNxjCkXrLguqpg4SNrsmgbdywL8/XjwomZsSDzO0v1ZXj+fMcYYk9eJjBM8Pf9p6oTW4fEujzsdx5hyw4rroop2T4N+cEOZnG5Q27o0jw5j+qZTpGdYgW2MMaZs/XPJP0k4kcCLfV4kNDDU6TjGlBtWXBdVzjToZdQ1xN9PeHZQKw6kKh/M314m5zTGGGMAftn1C19u/pI74u6gQ1QHp+MYU65YcV1UNRtBYFXXZDJlpE+z2nSK9uftX7aw72hamZ3XGGNM5XUo7RB/XfBXWtRswX3t7nM6jjHljhXXReXnD1Ety6zlOscNLaqQrcrfZ64v0/MaY4ypfFSVsQvGknIqhRd7v0igf6DTkYwpd6y4Lo7oOFdxXYYjeNQK8eO+/k35blUCv2+1adGNMcZ4z4wtM4jfHc9DnR6iaY2mTscxplyy4ro4YtpA2hGvT4Oe1939GtOgZghjv15LRlZ2mZ7bGGNM5bD72G5eWvwS3WK6MaLlCKfjGFNuWXFdHKdnaizbriHBgf48e0UrNu1P4d8LdpbpuY0xlYuI+IlIBxG5QkQGiEiU05mM92VlZ/H0/KcJkACe7/08fmLlgTElZf97iiOnuN7v/WnQ87q4VTT9mtfmtR83cfD4yTI/vzGmYhORJiIyAdgCvATcANwH/CQiC0XkdhGruCqqD9d+yIqDK3i6+9PEhMY4HceYcs0ulMURXB0iymYa9LxEhDGDW5GemcU/Z5XNWNvGmErleeAToImqDlTVm1R1qKq2BYYA1YGbHU1ovGL9ofW8s/wdBsYO5IpGVzgdx5hyz4rr4oqOK/NuITka1w7j/3o35j/L9vDHriOOZDDGVEyqeoOqzlM9+45tVT2gqq+r6mQnshnvSc9M56lfn6JGcA2e7f4sIuJ0JGPKPSuuiys6Dg5thgxnxp1+YEBTosODGPPftWRll92oJcaYykVEmorIJyLyhYj0cDqP8Y43/niDrclbea7Xc1QPqu50HGMqBCuuiyu6NWh2mU2DnldoUABPX96S1XuTmbZ0tyMZjDEVj4gE51n0HPAU8BAwvuwTGW9bmLCQT9Z/wg0tbqBXvV5OxzGmwrDiurhi2rieHeoaAjCkXV26NqrJP2dt4GjqKcdyGGMqlG9E5JZcX2cAsUBDIKsoBxCRCBGZLiIbRGS9tXj7rmOnjvHM/GeIDY/l4U4POx3HmArFiuviquGeBt2BmxpziAh/HdKa5LQMXv1xk2M5jDEVyqVAuIjMEpG+wGPAQOBqoKiDHr8BzFLVFkA7wKaW9VEvLHqBQ2mHeKnPS4QEhDgdx5gKxYrr4vLzg6hWZT4Nel4t64Rzc/eGfLJwJ+v2HXM0izGm/FPVLFV9G7ge1+ggbwAfquqjqnrOfnAiUh3oC3zgPt4pVT3qzcymZGZtn8V3277j7nZ307pWa6fjGFPheLW4FpEdIrJaRFaIyNJ81ouIvCkiW0RklYh0zLXuVhHZ7H7c6s2cxRYTB4mry3Qa9Pw8cvH5RFStwpiv15DPDf7GGFNkItJNRKbj6l/9EfAM8HcR+ZeIRBThEI2Ag8CHIrJcRN4XkVDvJTYlcTTzKM8tfI62tdpyZ5s7nY5jTIUUUAbnuEBVkwpYdxnQzP3ohuui3k1EagJjgM6AAstE5GtV9Y3x56LjYNlHcGwfVK/nWIzqVQN5fOD5PPnlav67Yh9XdXAuizGm3HsPuBwIw9Vi3QsYLiL9gM9xdREpTADQEXhAVReJyBvAk8CzuTcSkZHASIDo6Gji4+OLHTQlJaVE+5UFX86WrdlMPjCZ9Mx0rqxyJfPnzXc60hl8+WcHvp3Pl7OBb+fzRrayKK4LcyXwsXtc1YXum2HqAP2BH1X1MICI/IirP+BnjiXNLTrO9bx/jaPFNcCwzg34bPEuXpi5notaRRMW5PSv1BhTTmXiuoExFDh9p7SqzgXmFmH/PcAeVV3k/no6ruL6DKo6AZgA0LlzZ+3fv3+xg8bHx1OS/cqCL2f7dP2nbNm1hWe7P8uw84c5HecsvvyzA9/O58vZwLfzeSObt/tcKzBbRJa5WyvyqgfkHk9uj3tZQct9Q3Qr13Ni2U+DnpefnzB2SGsOHD/JWz9vdjqOMab8uhG4FhgA3HKObc+iqonAbhE5373oQmCd5+KZ0vhj/x+8uuxVWoW04rrm1zkdx5gKzdvNnL1Vda+IRAE/isgGVZ3nyROU9iPGkn4c0C04iuOr57Auu3Ox9y2OoubrUy+A93/dRsPsBOqGlc19qr78MQ9YvtLw5Wzg2/l8Ods5bFbVRwvbQEQkvxkcc3kAmCIiVYBtwO2eDGhKZuPhjYz6eRR1QutwU/hNNgujMV7m1eJaVfe6nw+IyAygK5C7uN4LNMj1dX33sr24uobkXh5fwDlK9RFjiT8OSOhCyKHNRHn5Y46i5ovrfJILXonn+/2hfHxF1zK5ePryxzxg+UrDl7OBb+fz5WznMEdEvgD+q6q7cha6C+XewK3AHFw3O+ZLVVfgulfG+Ihdx3Zx9493UzWwKhMunsDGpRudjmRMhee1Jk4RCRWRajmvgUuAvOPXfQ3c4h41pDuQrKoJwA/AJSJSQ0RquPf9wVtZSyQmDg5tcWwa9LxqhQXxyMXN+XVzErPX7Xc6jjGm/LkU12Qxn4nIPhFZJyLbgM3ADcDrqvqRkwFN8RxIPcDIH0eSpVlMuHgCdcLqOB3JmErBmy3X0cAMdwtqAPCpqs4SkXsAVPVdYCauu9O3AKm4P0JU1cMi8hywxH2sv+Xc3OgzcqZBP7Ae6nU89/Zl4ObuDZm6eDfPfbuOfs1rExzo73QkY0w5oarpwDhgnIgEArWANBurunxKPpnM3T/ezZH0I0waOInGEY2djmRMpeG14lpVt+GaoSvv8ndzvVbg/gL2nwRM8la+Uss9YoiPFNcB/n6MHdKaGyYu5N25W3noouZORzLGlEOqmgEkOJ3DlExqRir3/XwfO4/tZPxF422iGGPKmM3QWFI1GkFgqKPToOenR5NIBrWtw/j4rew+nOp0HGOMMWXoVNYpHo5/mDVJa3i538t0q9PN6UjGVDpWXJeUn59rSL5EZ6dBz8+fr2iJnwjPf2ejYBljTGWRlZ3FU78+xe/7fmdsj7FceN6FTkcyplKy4ro0ouNgv/PToOdVp3oIowY05Ye1+5m36aDTcYwx5ZSIDHE6gykaVeX5Rc8ze+dsHuv8GFc3u9rpSMZUWlZcl0Z0a0hPhmN7nU5yljv7NCI2sipjv1nLqcxsp+MYY3yciFyT53EtMCHna6fzmcK9ufxNpm+azp1t7uTW1rc6HceYSs2K69KIaeN69sGuIUEB/owZ3JptB0/w4W/bnY5jjPF9nwN3AIOAwe7n0FyvjY+avHYy769+n6HNhzK6w2in4xhT6VlxXRpR7mnQ9/tecQ1wQYsoLmoZxZs/b2b/sXSn4xhjfFtPIARYoqq3q+rtQJL79R0OZzMFmLF5Bq8sfYVLGl7CM92esdkXjfEBVlyXRnA4RDT02eIa4NlBrcjIVl6cud7pKMYYH6aqS4CLgSoiMkdEugK+dUOJOcPPO39m7IKx9KjTgxf7vIi/n81tYIwvsOK6tGLa+GS3kBwNI0O5u29jvlqxj8XbfWseHmOMb1HVbFV9AxgBPOZ0HlOwRQmL+NO8PxFXK47XL3idKv5VnI5kjHGz4rq0olvD4a1wynfHlL6vf1PqVg9mzNdrycq2hihjTOFUdZ+qDgN6OZ3FnG1N0hpG/zKahuENGXfhOKoGVnU6kjEmFyuuSys6zjUN+kHf7XYRUsWfZwa1Yn3CMbu50RhTHN85HcCcaVvyNu796V5qBNfgvYvfo3pQdacjGWPysOK6tGLc06D7cNcQgMviYrioZTT/mLWBNXuTnY5jjCkf7O44H5KQksDI2SPxF38mXDyBqKpRTkcyxuTDiuvSioiFKmE+Nw16XiLCy0PbEhkaxAOfLSflZKbTkYwxvm+i0wGMy+H0w4z8cSSpGam8d/F7nBd+ntORjDEFsOK6tPz8XEPy+fCIITlqhFbh9eHt2XnoBGP+69t/DBhjypaI1MzzqAGMdzqXgZRTKdzz4z0knkjk7Qvf5vya5zsdyRhTCCuuPSG6tau49rFp0PPTvXEkowY044s/9vDVct+bWdIY45hlwFL38zLgD+CAiPwkIrEO5qrUTmadZPSc0Ww+spl/9f8XHaM7Oh3JGHMOVlx7Qkycaxr05D1OJymS0QOa0jW2Jn+esZodSSecjmOM8QGq2khVG7ufcx61gXHAu07nq4wyszN5bO5jLElcwnO9n6Nv/b5ORzLGFIEV154Q7Z4GvRx0DQEI8Pfj9eHtCfD3Y/TU5ZzKzHY6kjHGR6nql4DdOVfGTmWd4un5TxO/O56nuj7FoMY2A70x5YUV154Q7dvToOenbkQI/xzallV7knn5hw1OxzHG+CgRCcPeK8pUUloSd/xwB99v/54HOz7IjS1vdDqSMaYYApwOUCEEVYMasT4/HF9eA1vHcHP3hkz8dTs9m9bigvOtccqYykpEHslncQ1gCPB2GceptNYdWsfoX0aTfDKZV/q9wsDYgU5HMsYUk7VGeEp0XLlquc7x5yta0iKmGo9NW8mBY+lOxzHGOKdankcYkAjcpKo2JF8ZmLV9Frd+fysiwseXfWyFtTHllLVce0p0HGz4zjUNepXyMxVtcKA/b93QgcFvz+eRaSv5+I6u+PnZvBHGVDaq+teC1olIgKra4Phekq3ZvL38bSaunkiHqA682v9VaoXUcjqWMaaErOXaU2LiAIUDvjsNekGaRVdjzODWzN+SxLvztjodxxjjABGZn+v1v/OsXlzGcSqNExkneGjOQ0xcPZFrml3D+5e8b4W1MeWcFdeeEt3a9VwOu4YADO/SgCva1OFfszfxx64jTscxxpS90Fyv4/Kss4+zvGD38d3cNPMm5u2Zx5Ndn2Rsj7FU8a/idCxjTClZce0pp6dBL5/FtYjwwjVtiAkPZvRny0lOy3A6kjGmbGkBr/P72pTS4oTF3PDdDRxIPcD4i8YzouUIROxvGGMqAiuuPcXPz9V6Xc5GDMmtekggb97QgYTkdJ6esRotBzNOGmM8JkJErhaRa92vr3E/rgWqOx2uIpm6YSojfxxJZHAkn17xKT3q9nA6kjHGg7x+Q6OI+OOaUnevqg7Ks+414AL3l1WBKFWNcK/LAla71+1S1SHezlpqMW1hxRRIPQxVazqdpkQ6NazBIxc35+UfNtKnaS2Gdz3P6UjGmLIxF9ewezmvB+daN6/s41Q8GVkZvLT4JaZtmkbf+n15qc9LVKtSzelYxhgPK4vRQh4E1gPheVeo6sM5r0XkAaBDrtVpqtre+/E8qPPtsGQiLBwPA/7sdJoSu7dfE37fmsTYb9bSqWENmkXbxd+Yik5Vby9onbv12pTC4fTDPBr/KEv3L+WOuDsY3WE0/n7+TscyxniBV7uFiEh94Arg/SJsfgPwmTfzeF10a2g5GBa9C2nl96ZAPz/htWHtCa0SwAOfLSc9I8vpSMYYZ73mdIDybOPhjdz43Y2sOriKF/u8yMOdHrbC2pgKzNt9rl8HHgeyC9tIRBoCjYBfci0OFpGlIrJQRK7yYkbP6vs4nDwGi95zOkmpRIUH88qwdmxIPM4LM8vf8ILGGI+yO+1K6OedP3Pz9zeTkZXB5MsmM6jxoHPvZIwp17zWLUREBgEHVHWZiPQ/x+bDgemqmruJtKGq7hWRxsAvIrJaVc8ahFlERgIjAaKjo4mPjy9WzpSUlGLvcy5xkd2oPv9NFma2ISsg9Nw7FMIb+YpKgIGxAXy8YCfV0xPpFH3mPxcnsxWF5Ss5X84Gvp3Pl7OVgt3dXEyqynur3uOdFe/QplYbXr/gdaKqRjkdyxhTBrzZ57oXMERELgeCgXAR+URVb8pn2+HA/bkXqOpe9/M2EYnH1R/7rOJaVScAEwA6d+6s/fv3L1bI+Ph4irvPOTWPgAn96BO4Dvr9qVSH8kq+YujZO5trx//OxxtSuWFgN+pGhPhMtnOxfCXny9nAt/P5crbCiMhq8i+iBYgu4zjlWmpGKs/+9iyzd85mcOPBjOk5hiD/IKdjGWPKSJG6hYhIExEJcr/uLyKjRSSisH1U9SlVra+qsbiK51/yK6xFpAVQA1iQa1mNXOerhatQX1fE78l5ddtD80thwduQfszpNKVSJcCPt27oQGZWNg9NXUFmVqE9fIwx5dcgXCOE5H0MApo7mKtcOZx5mFtn3cpPu37i0U6P8vfef7fC2phKpqh9rr8AskSkKa5W4gbApyU5oYj8TURyD6s3HJiqZw6q3BJYKiIrgTnAS6pafoprgH6PQ/pR1+gh5VxsrVCevzqOxTsO89YvW5yOY4zxAlXdmfcBnMA1FOpOp/OVB2uT1vJywsvsOb6Htwe8zW1xt9nEMMZUQkXtFpKtqpkicjXwlqq+JSLLi3oSVY0H4t2v/5Jn3dh8tv8daFPU4/ukep2g6cXw+9vQ9W4ICnM6Ualc3aE+v25O4q1fNtOjSSTdG0c6HckY40Ei0h14CTgMPAf8G6gF+InILao6y8l8vi5bsxnz+xgCJIDJV0ymcfXGTkcyxjikqC3XGSJyA3Ar8K17WaB3IlUg/Z6AtMOwpCgjEfq+566Mo2FkKA9NXcGRE6ecjmOM8ay3gRdwDYn6C3CnqsYAfYEXnQxWHvy08yc2HtnIkIghVlgbU8kVtbi+HegB/F1Vt4tII1ytGqYwDbpAkwHw+1tw6oTTaUotNCiAt27owKETJ/nT9FU2PboxFUuAqs5W1f8Aiaq6EEBVNzicy+dlZWcxbsU4GldvTKfQTk7HMcY4rEjFtaquU9XRqvqZiNQAqqnqP7ycrWLo9ySkJsHSSU4n8Yi4etV58rKW/LR+Pz/vynQ6jjHGc3LfrZyWZ539JV2IWTtmsTV5K/e2vxc/8fb0EcYYX1fU0ULiRSRcRGoCfwATReRV70arIM7rBo36wW9vwqlUp9N4xB29YhnQIoqpG06xcvdRp+MYYzyjnYgcE5HjQFv365yvy/c9MF6UmZ3J+JXjaV6jOZc0vMTpOMYYH1DUP7Grq+ox4BrgY1XtBlzkvVgVTP8n4cQBWPaR00k8QkR45bp2RAQLd368lH1H8zZyGWPKG1X1V9VwVa2mqgHu1zlf2z02Bfh227fsPLaT+9rfZ63Wxhig6MV1gIjUAYbxvxsaTVE17AmxfeC31yGjYhSiNUOr8HDHYNJOZXHn5KWcOGldRIwxlUtGdgbvrnyXVpGtGNBggNNxjDE+oqjF9d+AH4CtqrrEPSX5Zu/FqoD6PQEp++GPj51O4jH1qvnx9o0d2JB4jAenriAr27plGmMqj6+2fMXelL3c3/5+G8/aGHNaUW9o/I+qtlXVe91fb1PVa70brYKJ7Q3n9YT5r0FGutNpPKb/+VGMGdyan9bv55+zbFABY0zlcCrrFBNWTaBt7bb0qdfH6TjGGB9S1Bsa64vIDBE54H58ISL1vR2uQhGB/k/A8QRYXrFGMby1Zyy39GjIe/O28fmSXU7HMcZ4gIhUy/W6qZNZfNH0TdNJPJHIqPajrNXaGHOGonYL+RD4GqjrfnzjXmaKo1E/aNDN1XqdedLpNB71l0Gt6NOsFn+esYYFWw85HccYU3rzReQrERmGq1ugcUvPTOf91e/TKboT3et0dzqOMcbHFLW4rq2qH6pqpvvxEVDbi7kqJhFX3+tje2HFFKfTeFSAvx/vjOhIo1qh3PPJMrYnlf9Jc4ypTESkqogE5Hytqu1wFdWfAU86FswHfb7xcw6mHbRWa2NMvopaXB8SkZtExN/9uAmw5smSaDIA6nWGX1+FzIo1hXh4cCAf3NoFfz/h/z5awtHUivX9GVPB/QLUyvlCRK4G7gUGArc5lMnnpGakMmnNJLrX6U7nmM5OxzHG+KCiFtd34BqGLxFIAIZiF9uSEXGNe528G1Z+5nQajzsvsirv3dyJPUfSuPeTP8jIyj73TsYYXxCiqokAIjISeBq4UFV/AqKLehB3A8xyEamQw7Z+uuFTDqcfZlSHUU5HMcb4qKKOFrJTVYeoam1VjVLVqwAbLaSkml4EdTvAr/+CrAyn03hcl9iavHRtGxZsO8SzX61B1YboM6YcOCQiY0TkfeBF4BJVPeie46BKMY7zILDeKwkdlnIqhY/WfkSfen1oV7ud03GMMT6qNNNJPeKxFJWNCPR7Eo7uhFWfO53GK67pWJ9RFzRl6pLdfDB/u9NxjDHndh2QBWwCRgKzRWQS8DvwUlEO4B5F6grgfW+FdNK/1/+b5JPJ3N/hfqejGGN8WMC5NymQ3cVRGs0HQp12MO8VaDsc/Evzq/BNj1zcnG1JKfx95npiI0O5qFWRP1k2xpQxVT0EPJ/ztYgsAHoB/1DVjUU8zOvA40C1c21Y3iSfTObfa//NgAYDaB3Z2uk4xhgfVpqKzj7rL42ckUOm3gir/wPtb3A6kcf5+Qn/uq49e44sYPTU5Uy/pyet6oY7HcsYUwSqug/4T1G3F5FBwAFVXSYi/QvZbiSulnGio6OJj48vdraUlJQS7Vca3x79luMZx+ma2bXQczuRrTh8OZ8vZwPfzufL2cC383kjW6HFtYgcJ/8iWoAQjyapjM6/HKLbwLyXoe0w8PN3OpHHhVTx5/1bOjPk7d+4c/ISvrq/F1HhwU7HMsZ4Xi9giIhcDgQD4SLyiarelHsjVZ0ATADo3Lmz9u/fv9gnio+PpyT7ldSR9CM88cUTDIwdyIh+IwrdtqyzFZcv5/PlbODb+Xw5G/h2Pm9kK7TPtapWU9XwfB7VVLXi9WMoayLQ73E4vBXWfOF0Gq+JCg/m/Vs7cyQ1g7s+Xkp6RpbTkYwxHqaqT6lqfVWNBYYDv+QtrMurD9d+SHpWOve1u8/pKMaYcqA0NzQaT2gxCKJauVqvsytu0RlXrzqvD2/Pqr3JPDptJdnZ1qvIGF8kIg+ISA2nRZnakAAAIABJREFUc/iKpLQkpm6YyuWNLqdxRGOn4xhjygErrp3m5+dqvU7aBOu+cjqNVw1sHcOTl7bgu9UJvP7TJqfjGGPyFw0sEZFpInKplGAKQlWNV9VBXshW5j5Y/QGnsk5xT7t7nI5ijCknrLj2BS2vhNotYO7LkF2xJ10Z2bcxwzrX581ftvDV8r1OxzHG5KGqzwDNgA9wTRa2WUReEJEmjgZzwP4T+5m2cRqDmwymYXhDp+MYY8oJK659gZ8f9P0THFwP6792Oo1XiQjPX9WGbv/f3n3HR1Xl/x9/fWYmvXdCEhIgdAgCoatg77hWsBes61p2dYvufnW/rr/9WnZXV1fXtvbeF7soxgIWkJLQa4BQU0hCejJzfn/cCQSkM5N7k3yej8d9zJ07dzJvJuTkkzPnntMzkd+9Vcic4gq7IymldmOslZ82+7cWIAF4S0TutzVYO3uq6Cl8xse1edfaHUUp1YFoce0Ug86C5L7w1f2dvvc61OPi8YtH0D0+nGtf/In1FXV2R1JK+YnIzSLyE3A/MBMYYoy5HhhBF1qZd2PNRt5e8TZn9TmLzJhMu+MopTqQoBfXIuIWkXki8sEeHrtcREpFZL5/u6rNY5eJyAr/dlmwc9rO5bZ6r7cugmUf2p0m6BKiQvnP5SNp9vq48rnZVDd0vmXgleqgEoGzjTEnGWPeNMY0AxhjfECnGEd9IJ4sfBJBuCbvGrujKKU6mPboub4ZWLKPx183xhzh354GEJFE4C5gNDAKuKtLXL0+6GxI7A1f3Qem88+m0Tslmn9fPII1ZbXc+Mo8Wrydu8deqQ7iY2DHeC0RiRWR0QDGmH215Z3G+ur1vLfyPc7rex7dorrZHUcp1cEEtbgWkUzgNODpg3zqScB0Y0yFMWYbMB04OdD5HMftsXqvNxfBso/tTtMuxucm85dfDOar5aXc/cFiTBf4o0Iph/s3UNPmfo3/WJfxeOHjeFwerhpy1f5PVkqp3QS75/oh4HfAvrokzxGRQhF5S0Sy/McygPVtzinxH+v8hpwHCT3hq3u7RO81wAWjenD1UT154bu1PDhdp+hTymZi2vyV6x8O0mUWDVtdtZoPVn/AlH5TSIlMsTuOUqoDClqDKSKnA1uNMT+JyMS9nPY+8KoxplFErgWeB449yNe5BrgGIC0t7aDXh3fievfdUk+n/7JHKHzn79SE9XdcvlaBfO/GRhqWZXp4eMZKStavZVLv0MP+mk783rbl5HxOzgbOzufkbAdotYjcxM7e6l8Cq23M064en/84Ye4wrhxypd1RlFIdVDB7I8YDk0TkVCAciBWRl9ouh2uMKW9z/tNYV6cDbAAmtnksEyjY04sYY54EngTIz883B7s+vCPXu/eOh0emkVf+IRV9Rjgvn1+g37sJEwy3vbmAd+ZtYECfXK4++vBWQ3Pk97YNJ+dzcjZwdj4nZztA1wEPA38CDPAF/g6Mzm7FthV8UvwJU4dMJTE80e44SqkOKmjDQowxtxtjMo0xOcAUYEbbwhpARNLb3J3EzgsfPwVOFJEE/4WMJ/qPdQ3uEDjqVtg4l8SKeXanaTdul/DAuXmcNiSd//fREp6fVWx3JKW6HGPMVmPMFGNMqjEmzRhzoTFmq9252sNj8x8jKiSKywddbncUpVQH1u7j6ETkbmCOMWYacJOITMJapKACazUwjDEVIvIXYLb/aXcbY7rWaiNDL4Cv/0buyqeg/gqI6PyTpQB43C4emnIETV4fd01bRKjHxQWjetgdS6kuQ0TCganAIKxPHQEwxnTqcRJLypfw+brPuX7o9cSFxdkdRynVgbXLIjLGmAJjzOn+/Tv9hXVr7/YgY8xQY8wxxpilbZ7zjDEm17892x45HcUTCmc/SXjDVnhrKvi8didqNyFuF/+6cBgT+6Vwx7tFvP1Tid2RlOpKXgS6Yc3a9BXWsLzttiZqB4/Of5TY0FguGXiJ3VGUUh2crtDoZNljWdHnWlj1BUy/0+407SrM4+bxi0cwrncSv31rAe8v2Gh3JKW6ilxjzP8AtcaY57GmUx1tc6agKiwt5KuSr7h80OXEhMbYHUcp1cFpce1wm7qfCKOuge/+BfNftTtOuwoPcfPUpfnkZydyy+vz+WThZrsjKdUVtC6XWikig4E4INXGPEH36PxHSQhL4KIBF9kdRSnVCWhx3RGc9FfIOQrevwnWz97/+Z1IZKiHZ64YSV5mHDe+OpcZS7fYHUmpzu5J/4XkfwKmAYuB++yNFDxzt8xl1sZZXDn4SiJDIu2Oo5TqBLS47gjcIXD+CxCTDq9fBNVda4hEdJiH564YRf9usVz30ly+WVFqdySlOiURcQHVxphtxpivjTG9/LOGPGF3tmB5dP6jJEckM7n/ZLujKKU6CS2uO4rIRLjgNWiqhdcuguZ6uxO1q7iIEF64chS9kqO4+oU5fL+6fP9PUkodFP9qjL+zO0d7mbd1Hj9u/pGrhlxFhCfC7jhKqU5Ci+uOJG0gnP0kbJwL027qMsujt0qICuWlq0aTmRDJlc/N5qe1XWt2RqXayecicpuIZIlIYutmd6hg+G7jd7jExS9yf2F3FKVUJ6LFdUfT/zQ45k9Q9AbMetjuNO0uOTqMV64aTWpMGJc/M5sF6yvtjqRUZzMZuAH4GvjJv82xNVGQFJYW0ju+N1EhUXZHUUp1Ilpcd0RH3wYDfwHT74Lln9mdpt2lxobzytVjiIsM4dJnfmTRxiq7IynVaRhjeu5h62V3rkAzxlBUVkRecp7dUZRSnYwW1x2RCPziMeg2GN6eCqXL7U7U7rrHR/Dq1WOICnVzyX9+ZPmWTr/GhVLtQkQu3dNmd65AW1u9luqmavJStLhWSgWWFtcdVWgUTHkV3KHw6hSo32Z3onaXlRjJy1ePweMSLnzqB1aX1tgdSanOYGSb7Sjgz8AkOwMFQ1FZEQBDkofYnEQp1dlocd2RxWfB5Jegcp21RLq3xe5E7a5nchSvXD0aYwwXPvUDa8tr7Y6kVIdmjLmxzXY1MByItjtXoC0oXUCkJ5JecZ1uxItSymZaXHd02WPhtL9bS6R/fpfdaWyRmxrDS1eNpqHFy4VP/UDJtjq7IynVmdQCPe0OEWhFZUUMTh6M2+W2O4pSqpPR4rozGHFZl10ivdWA9FhevHI01Q3NXPT0D2yuarA7klIdkoi8LyLT/NsHwDLgXbtzBVJDSwPLK5breGulVFB47A6gAuSkv0LpUmuJ9KRcyBppd6J2NyQzjuevHMUlT//AhU9/z82Du9Y84EoFyN/a7LcAa40xJXaFCYalFUtpMS063lopFRTac91ZuEPgvOchtnuXXCK91fAeCTx7xSg2VTbw1x/qWblVL3JU6iCtA34wxnxljJkJlItIjr2RAquwtBBAe66VUkGhxXVnEplozSDSRZdIbzWqZyIvTh1FXYvhrMdmUrBsq92RlOpI3gR8be57/cc6jcKyQtKj0kmOSLY7ilKqE9LiurPp4kukt8rPSeSusRFkxEdw5XOzefqb1Zgu+l4odZA8xpim1jv+/VAb8wRcUWmRDglRSgWNFtedUf/T4Niuu0R6q+QIF29fP44TBqZxz4dL+O1bhTS2eO2OpZTTlYrIjnmtReRMoMzGPAFVVl/GxtqNOiREKRU0Wlx3VkfdBoPO6rJLpLeKCvPw74tGcNNxfXjrpxIufOoHSrc32h1LKSe7DrhDRNaJyDrg98C1NmcKmKJSa/EYLa6VUsGixXVnJQJnPgrdhnTZJdJbuVzCb07oy6MXDmfRxiom/etbFm6osjuWUo5kjFlljBkDDAQGGmPGGWNW2p0rUArLCvGIhwGJA+yOopTqpLS47sxCo2DKK+AJ67JLpLd1Wl46b103DoBzH5/Fh4WbbE6klPOIyF9FJN4YU2OMqRGRBBG5x+5cgVJUWkSfhD6Ee8LtjqKU6qS0uO7s4rPg/Be79BLpbQ3OiGPar45kYHosN7wyl39MX47Ppxc6KtXGKcaYytY7xphtwKk25gkYr8/LwvKFOiREKRVUWlx3BW2XSH/7Smuqvi4sJSaMV68Zw7kjMnn4ixX88uW51DZ27T86lGrDLSJhrXdEJAII28f5HcaaqjXUNtdqca2UCiotrruKEZfBiffA4mnwzMlQ1akWXDtoYR43D5ybx59OG8Bnizdzzr9nUbKtzu5YSjnBy8AXIjJVRKYC04EXbM4UEIVl1uIxOg2fUiqYgl5ci4hbROaJyAd7eOw3IrJYRApF5AsRyW7zmFdE5vu3acHO2SWMuxEufB0q1sCTx8D6H+1OZCsR4aqjevHsFaPYUFnPmf+ayeziCrtjKWUrY8x9wD3AAP/2F/+xDq+wtJCY0BiyY7P3f7JSSh2i9ui5vhlYspfH5gH5xpg84C3g/jaP1RtjjvBvk/b8dHXQ+p4EV31uXez43Gkw/xW7E9luQt8U3rthPHERIVz41Pe89uM6uyMpZStjzCfGmNuMMbcBtSLyqN2ZAqGorIi85Dxcoh/aKqWCJ6gtjIhkAqcBT+/pcWPMl8aY1s/ivwcyg5lH+aX2h6tnQNZoeO96+OxP4Ovai6v0Tonm3V+OZ0yvJP7wThF/nraIFq9v/09UqhMSkWEicr+IFAN/AZbaHOmw1TXXsbJyJUNSdEiIUiq4gv3n+0PA74ADqVKmAh+3uR8uInNE5HsR+UVQ0nVlkYlwybsw8iqY9Yg1VV9D1577OS4yhGcvH8nUI3vy3KxirnhuNlV1zXbHUqpdiEhfEblLRJYCjwDrATHGHGOMecTmeIdtUfkifMan462VUkHnCdYXFpHTga3GmJ9EZOJ+zr0YyAcmtDmcbYzZICK9gBkiUmSMWbWH514DXAOQlpZGQUHBQeWsqak56Oe0p6DnizqD7n085K58ivqHx7Fw8J+oj0x3RrbDdKj5jooGMziU5xeVceLfpnPz8HC6Rwf+71Anv39OzgbOzufkbPuxFPgGOL110RgR+bW9kQKnsFQvZlRKtY+gFdfAeGCSiJwKhAOxIvKSMebitieJyPHAH4EJxpgd61IbYzb4b1eLSAEwDPhZcW2MeRJ4EiA/P99MnDjxoEIWFBRwsM9pT+2TbyKsOY2oNy5ldOEf4PwXoNeE/T6rM793E4FTiyu47qWf+L/ZzTx84TCO6ZcayHiOfv+cnA2cnc/J2fbjbGAK8KWIfAK8Boi9kQKnqKyIrJgsEsIT7I6ilOrkgjYsxBhzuzEm0xiTg9Vgz9hDYT0MeAKYZIzZ2uZ4Qus8qyKSjFWoLw5WVgX0PNoahx3TDV48C358yu5EtsvPSeS/vzqSrMRIpj43m0e/XKkLzqhOyxjznjFmCtAf+BK4BUgVkX+LyIn2pjs8xhgKSwt1fmulVLsIZs/1HonI3cAcY8w04AEgGnhTRADW+WcGGQA8ISI+rD8A7jXGaHEdbIm9YOp0eOdq+Og22LoYTrkf3CF2J7NNRnwEb10/lt+/XcQDny7ju1Xl/GPyUFJjdOlk1TkZY2qBV4BXRCQBOA/4PfCZrcEOw5a6LZTWl+qQEKWcwBjwNkNLA3iboKVxt/1G8DZCS5P/eNt9/zm+FmsiBuP17/vv+/z3jReftwVvSzNebws+bwu+lmZ8Xi8+bzM+bwvG58V4W8jZXkVj/vuERScG7J/YLsW1MaYAKPDv39nm+PF7OX8WoK2gHcJjYcor8MXdMPMhKF1uDROJSrI7mW0iQz08POUIxvdO4s/vL+LUf37Dg5OP4Kg+KXZHUyqo/Euf7xh611G1jrfOS9aea9UBtBaf3ibwNe/c9/r3fa33W3ack1g+B5Zs9xefTTsLUm9rsdq0223jbuc17fqYz2vlwBzCLT87Pq6hFr5jZ7EcQF5c+HDhxUULbrymzX7rcbNz39rctPif14Kb6LpGwqIDl6nde65VB+Bywwn/C6kDYdqN8NQx1uIzqQPsTmYbEWHKqB4Mz07gV6/M5dJnfuS6Cb35zQl9CXHrnLlKOVlRWREhrhD6JfazO4rqLHxeaNxubU010FgDjdX+/e3++9uhaftu99vcti2Y2xbTvpaDjpMHULSfk9yh4A4DT9vb3Y6FRoI7AVweEP8lFyKA7HLrQ2jxGVp80OIzNHv9tz5o8Rqa/fvN/v1tjY1IaAy1Hg+1Xje1XjfbW9zUtLio83loNCE0EUITHhrx7xsPjYTSiIdmQvCERhASFm5tIWGEhngI8YQQFuohLMRNmMdFeIibcI+bsBAX4R434SGuncfbnBMW4iLM//iyuT8xPCntoN/zfdHiWu3d0MmQ1BteuxCePh7OeRr6nWJ3Klv1TYvhvzccyd0fLOLfBav4YXU5D18wjMyESLujKaX2orC0kAFJAwh1h9odRbWXliargG2u9291Vq9pc93O+20fa97XY9btqKoymN3i/7p1+88A4AmH0GgIi4GwaAiLheg0CO1lPeb2WAWuK8QagukO8d/3H2895grZy33rvLnzixg+asxuxXOYdU7rrey8Prmh2UtVfTOVdc1U1jVRWd9MVV0zlfVNVNU3U13fQk1jC9sbWqhttPZ3bA0t1Dcf2NoY4SEuosM8uH3NpMTEEB3mIToshOgwN9Hh1n5SuIeoUDfR4SFEh3mICfcQHeYhqs1+RIgblys411eXLnfhCXAnmRbXat8y8+HqL60C+9UL4Pi7YPwtu/yQdjURoW7+7+w8xvVO5vZ3ijj1n99w/7l5nDz4wKYwVEq1n2ZfM4vLF3Nu33PtjqIOlM9nFbANVVZvcEMVNFS32a/6+WO732+pP/jXdYdCSASERO52GwHhcWz3xRGZ2ctfKPu3HYXzXu4H+ZqlxhYvFbVNFEk9DbUZVLYWzPX1VNVV+/ebqKxr3llM1zfR0Lz35UfcLiEm3Cpso0Kt2+ToULKTIncpfFsL4T3uh4UQGebe8cmuNYvSUUF9L5xEi2u1f3EZcMXH8N8b4PM/w9YlcMbDdqey3RlDu5OXGceNr87jupfmcunYbO44dQDhIW67oynV7kQkC3gBSMMadfmkMeaf9qaCldtW0uBt0IsZ25PP+/PC9wC2MZVb4PtG6znsZ2YmT7jVCxweC+Fx1n5cZpv7cRAaZQ1zaFskeyL2XkC79t12LykoIC3I02w2tfioqG2ivLaR8pomKmqbKKtptI7VNFFe20RFbaN1W9PE9sY2Q0hm/bDL1wr1uEiIDCE+IpS4yBB6JEaSlxlCXEQI8ZGh/lvr8fjIkB33o8M8SBfuQAsELa7VgQmNhHOfscZhf3kPlK8ktMev7E5lu+ykKN66bhz3f7KUp79dw+zibfzrwmH0TgnglRFKdQwtwK3GmLkiEgP8JCLT7Z7pqajMGoiqy54fBp8Pakth+0aobt02wPYt0FD580K5sXr/XzPMXwS3bvFZVJJEt+x+/mOxbc5pUzC33veEBf/fHQAtXh8VdU27FMpWkdzov28db31se8Oex1t7XEJCVChJUaEkRYcyNCGexKhQkqNDSYwKY+Oa5Rw5atguxbJ29NhHi2t14ERgwm8htT+8cy0jSm+FntHQt0NPgXvYQj0u/nT6QMblJnHrGws445FvufvMwZw7ItPuaEq1G2PMJmCTf3+7iCwBMrB5jYLC0kISwxPJjNafxz3yNsP2zVbBvHvxXL3Jf3yTdaFdWy4PRHeDiAR/cZy9a7G8181fNO+hl3hpQQHdHL4Ak89nqKpv3tGzXF7bRHlN444iubzW2i/39zZvq2ve49dxCSRGhe0olgd1jyU5OoxE/33ruHU/OSqM2Ih99yYX1K9mTK+uO6uX02hxrQ7egDNgag4tL0wh7JXzYMAkOPlea/hIF3Zs/zQ+vvlobn5tHre9uYBZK8v4yy8GExWmP2aqaxGRHKxVdX/Y95nBV1RWxJDkIV3zY26fD2q3QuV6qFwLVevJXTEbNj+1s3iu2cLPhmB4IiC2u7Vlj4PYdIjN2HkspjtEpYCr88yUZIyhuqGFLdUNbKpqYEuVdbu5up7NVQ1srm5kY0UdNZ99jHcvi4klRIb4i+Mw+nWLISkqbEfv8o5COTqUpKgw4iJCgnaBnrKf/tZXh6bbEObkP8QEzwL4+gFYNQOO+SOMusa6ermL6hYXzitXj+HhL1bwyIwVzF9fySMXDmNQ9zi7oynVLkQkGngbuMUY87PxASJyDXANQFpaGgUFBQf9GjU1NQf0vDpfHaurVjOAAYf0OofiQLMFgvi8hDZVEN6w1b+VEt6whbDGUv/+Vlxm12EGqe5IaipTaAxLoil6MI1JE2kMS2qzJdPiifr5Ret1/m1zFVAFLAn4vydY753PGKqbDJUNhooGw7ZGw7bW/QYf2/zHGvcwAUZsKCSEu0gIEwbF+0iKCiUmVIgNFWLDhJhQISYUYkIE945iudG/bd/lbkM5lGBtgdae/+8OhZPzBSNb162C1GEzrhA4+jYYfA589Fv49HZY8Aqc/pA1y0gX5XYJvz6hL2N6JXHL6/M469FZ/PG0AVw6Nrtr9p6pLkNEQrAK65eNMe/s6RxjzI5FafLz883EQxgGYM08sP/nzdo4C9bDpFGTGNd93EG/zqE40GwHxNsMVev9Pc/rdttfB1UbrBXq2opKhfgs6D4a4rIgvsfOLS6LWd/NYeLEiTjxqpBDfe+qG5rZsK2eDdvq2Vhl3W6orLd6nqsa2FLdQMtuvc0el5AWG05abBi9MiLoFhdOt9hw69a/nxobRphn5/CVgH5vA8zJ2cDZ+YKRTYtrdfgSe8JFb8KSafDx7605sfOvhOPuhIh4u9PZZmzvJD666Shue3MBd01bxMyVZdx/bh7xkTrXrup8xPrL8T/AEmPMP+zOA1BUal3MODh5sM1J9qOhCspWQNlyayv1325bs9uCIgIx6VahnDUahvTYtYCOy7RmvehEfD7D1u2NbKi0CuaNlTuL59b9XWbMAELdLrrHW0Xy6J6JpMWFkx4XTlqsddstLpzkqDAdlqGCRotrFRgiMPBM6HUMFPwf/PA4LHkfTvorDDm3y86LnRQdxn8uG8kzM9dw3ydLOe3hb3n4giMYkZ1odzSlAm08cAlQJCLz/cfuMMZ8ZFegorIiesX1IjY01q4IOxljXRzYWkCXLYfSZVZRXbN553kuDyT2hpR+1vUtib12Fs+xGdYCIZ2IMYYt1Y2sKavlq5Jm5n62jA2VDWyorGNjZQObqupp9u7a6xwb7iEjIZLMhAhG90wkIyGC7vERZPi35GgtnJW9tLhWgRUeCyf/HwydAu/fAu9cBfNehNP+Acm5dqezhcslXHVUL0bmJHLjq/M4/4nv+c0JfRmwv3lclepAjDHfAo6paIwxFJYWcnTm0e36uuJrhq1L/QX0sjY90iushVFahcVCcl/ofSyk9LX2k/tCQk7QFx5pb8YYymqaKC6vZU1pLWvKaykuq2VNWS1ry+t2We3PJStJiw2ne3wER2TFc+qQdDISIsiMtwro7vHhxIR3rvdHdT5aXKvgSB8KV30OPz0Ln98N/x4LR/4Gjvw1hITbnc4WQ7Pi+eCmI7njnSIe+HQZWTEuonMqGNVTe7GVCrSSmhK2NW4jLyUvuC/k88LGebBiOqycztEb5sHXbVa/i820iudhF0NyH38R3Q+iUzvdJ3rbaptY4y+gi8ut4rm4vJbisjpq2gzd8LiEHomR5CRHMa53Mj2Trf3NK4r4xUkTd6zqp1RHpcW1Ch6XG0ZeBf3PgM/+CF/dC0VvwGl/t3pruqDY8BAeuWAYpwxO53/emcf5T3zHpKHduf3U/qTHda6xkkrZqXW8dVBWZqzZas2QtGK6dVtfAeKCjBGs63E22fknWUV0Ui6EOfHSwUPX4vVRXF7H8i3bWbGlhjVlNawpr6O4rJaq+p1zOrsEMhOsonlEjwRykqPo6d8y4iPw7KGALtjg0sJadQpaXKvgi0mDc56GIy6CD2+FF8+Cweda47Fj0uxO1+5EhNPy0vGULmWRL4PHv1rF9MVb+NWxuUw9sqeuqqVUABSVFRHuDqdPQp/D/2LeFtgwB1Z+bhXUm/xDyqNSoO9JkHu81WEQmciaggKy8yYe/mvazOszrK+wimhrq2H5lu2sLq2lyWv1zItA97gIcpIjOT0vfUfxnJMcRVZCJKEeLZRV16TFtWo/vY+B62fBzIfgm7/Dis+sGUXyr9zjal2dXZhb+M1xfTlvRCb/78MlPPDpMl6fvZ7/OX0gxw9I1Wn7lDoMhaWFDEwaiMd1iL/mtm+GlV/Ayumw6ktrmW9xQeYoOPZPkHsCdMvr8AupGGPYUFnPii01LNtRSG9n5dYaGpp3Dm/JiI+gX7cYJvRLoV9aDH3TYuidEk1EaNdru5XaHy2uVfsKCYeJf7B6rj+6FT66Dea/bM2N3f0Iu9PZIisxkscvGcG3K8r48/uLuPqFOUzom8KdZwykd0rn+khZqfbQ5G1iScUSLhpw0YE/ydsM63+0eqdXTofN1rASortB/9Ohz/HQa6K13HcHtbW6gYVlXlZ+s3pHMb1ya80u46G7xYbTJy2ai0dn0zcthr7dYshNjSZaV5pV6oDpT4uyR3IuXPIeLHwbPrkdnjoG8qdaFzx20WXUj+yTzMc3H8WL363lwc+Xc9KDX3PlkT258dhcvTpeqYOwrGIZzb7m/Y+3bmmEwjesT9FWF0BjNYgbeoyxPlXLPQG6DelwFx4aYyjZVs+ijVUs3FDNwo1VLNpYTen2Rv8ZS0iODqVvWgznjsikT1o0/dJi6JMaQ1yktjVKHS4trpV9RKw5sHOPhxl/gTnPwE/PWdP4jb+lS07dF+J2ceWRPZl0RHf+9ukynvpmNe/M3cAfTunP2cMydO5WpQ5AYVkhwL5nCtm+GV6/GEpmQ0x3a57+PidYvdPhce2SMxB8PsOa8loWbaxm0YYqFvoL6taLC90uoU9qNBP6pjCoeywNm1dz/klHkhQdZnNypTovLa6V/SLirRlExt1nJayCAAAePUlEQVQEsx6x5sWe9xIMnGT1ZHcfZnfCdpccHca95+Rxwage/Pn9Rdz25gJe+n4t/ztpEEOzuu6ql0odiMLSQlIjUukW1W3PJ2z4CV672BpHfe6zMOisDtE73eL1sbK0xuqN3lDFoo1VLN5YTW2TNU90qMdF/24xnDokncEZsQzuHke/bjG7XCRdULBWC2ulgkyLa+UcCdlw2t9gwu/g+3/D7Kdh8X+tVR+P+g3kHNUhfgEG0tCseN6+bhzvztvAvZ8s5cxHZ3J+fia/Pak/KTH6C1KpPSkqK2JIyl6GhBS+CdN+BVGpMPUza9iHA3l9hiWbqinaUMXCDVUs3FjN0k3VNLZYFxlGhroZmB7LeflZDOoey+CMOHJTo3UqO6UcQItr5TzRqXD8XXDkLdZQke8eg+fPgIx8q8jue0qHv0L/YLhcwjkjMjlxUBr/mrGSZ2au4eOizdxyQl8uHZutv0yVamNbwzbWb1/POX3O2fUBnxe+uNuarSh7PJz/AkQl2xNyD+qaWpi/vpI5xduYXVzBvHWVOy40jA33MDgjjkvHZjM4I45B3ePomRyFW4eJKeVIWlwr5wqPs4aFjL7OmlFk5sPw2oWQ0t8akz3k3E63TPC+xISHcPupAzh/ZBZ3v7+Yv3ywmFd/XMddZwzkqD4pdsdTyhGKyqxZPnYZb91QBW9fDSs+tab+PPk+8ITalNBSVtPInOJtzCmuYPbabSzaUEWLzyAC/dJiOGtYBvk5CQzLSiArMUKn5lSqA9HiWjlfSIS10uPwy2HRu/Dtg/DedfDlX2HcjdaywqGRdqdsN71TonnuipHMWLqVuz9YzCX/+ZETB6Zxx6kDyEmOsjueUrYqLC3EJS4GJQ2yDpSvglenQMVq69qOkVe1eyZjDMXldcwurmBOcQVzirexuqwWsMZJH5EVz7UTepGfk8jwHgnERXSdTgOlOiMtrlXH4fZA3nlWj/WKz+Cbf8DHv4Wv7oMx18HIq62LI7sAEeG4AWkc2SeZp79Zw2NfruSEB7/isrE53HhcH/3lrLqsorIicuNziQyJtJYmf/Nya3q9S96Dnke1S4Zmr4/FG6v9xfQ25qytoKymCYD4yBDysxOZPDKL/JxEBmfEEubRhViU6kyCXlyLiBuYA2wwxpy+22NhwAvACKAcmGyMKfY/djswFfACNxljPg12VtVBiFhLDvc9CdbOsorsGffAt/+E/Ctg7A0Qs5dZAjqZMI+bG47J5bz8TP7+6XL+M3MNb88t4Zbj+3Lh6B46Hlt1KT7jo6isiBOzT7Su1fjsj5AyAC54BRJygve6PsPCjVV8tayUj36qp/iLz6hvtmbw6JEYydF9UxiZk8jInAR6JUfrlJpKdXLt0XN9M7AEiN3DY1OBbcaYXBGZAtwHTBaRgcAUYBDQHfhcRPoaY7ztkFd1JNnjrG1ToXWh0nf/gh+egCMuJMKdb3e6dpMaE8595+Zx2bgc7vlwMXdNW8QL3xXzx9MGcEw/XUpddQ1rq9eyvWk7eSWFsPgLa2XFs56AsMCvdFq6vZFvVpTy1fJSvllRRkWt1TOdHeti8sgsRuYkkp+TQFpseMBfWynlbEEtrkUkEzgN+H/Ab/ZwypnAn/37bwH/EqsKOBN4zRjTCKwRkZXAKOC7YOZVHVh6Hpz7DBzzR5j1MMx/mdHeZ2Hjc9aiNIPOhshEu1MG3cDusbx81Wi+WLKVv360hCufm8NRfZL542kD6N9tT3/fKtV5FK7/FoC8FV/DhN/DhD8EbGahZq+PuWu38dVyq6BetLEagOToUCb0TWFC3xSO7JPMwjnfMXHioIC8plKqYwp2z/VDwO+AmL08ngGsBzDGtIhIFZDkP/59m/NK/Md+RkSuAa4BSEtLo6Cg4KAC1tTUHPRz2pOT8zk2W8xZhI6aSPz6z+ixbSbRH96K76PfU540ks3djqEicTjGZf+Y5GC+fx7gjuGGL9eF8t6qMk556BsmZHo4q08ocWH778V27PfWz8n5nJytU9s4j6KZ9xIVCj3PfBIGn33YX3J9RR1fryjlq2WlzFpVTk1jC26XMCI7gd+e1I8JfVMYmB6rwzyUUrsIWnEtIqcDW40xP4nIxGC9jjHmSeBJgPz8fDNx4sG9VEFBAQf7nPbk5HxOzgZQUJDAwAmPweYiXIWvk1L4BikLv4OIRBh8Dgy9ADKG27YwTXu8f8cDv61r4uEvVvLCd8XM3trIL4/JZeqRPXdZtc2ObIfDyfmcnK3TKnoL/nsDhekpDE4ejPsQC+v6Ji/frynna3/v9OpSa0aPjPgIzhjanQl9UxiXm0RsuP1/nCulnCuYPdfjgUkicioQDsSKyEvGmIvbnLMByAJKRMQDxGFd2Nh6vFWm/5hSB0fEGjKSngfH/y+s/hIWvGotsT77KUjqYw0byZsM8Vn7/3odUHxkKHeeMZCLx/Tg/z5eygOfLuOVH9bx+1P6c0Zeuo7HVh2Xzwcz/gLf/oOGHmNZ4dnM5RljD/jpLV4fq8tqdxTTP6ypoKnFR5jHxZheSVw0OpsJfVPonRKlPydKqQMWtOLaGHM7cDuAv+f6tt0Ka4BpwGVYY6nPBWYYY4yITANeEZF/YF3Q2Af4MVhZVRfh9kCfE6ytocpaWn3Ba9Yv5xl/sZZXH3oBDJwEYXsbydRx9UqJ5qlL85m1sox7PlzCTa/O49mZa/if0wcyvEeC3fGUOjgN1fDO1bD8ExhxOUtGXETL9KnkJe9cPMbnM2zd3kjJtjrWb6tjfUU96yvqKNlWz/ptdWyqasDrMwDkpkZzyZhsju6bwuieifv8ZEcppfal3ee5FpG7gTnGmGnAf4AX/RcsVmDNEIIxZpGIvAEsBlqAG3SmEBVQ4XEw/FJr21YMhW9YPdr//SV8eCsMOAOGToZex4Crc/2SHZebzPs3Hsnbc0t44NNlnP3YLCYN7c7vTu5HZkLXWYxHdVwRdZvg6eMx5SupPe5eVmVP4bVFLwLwwewQnv38R0oq6iiprKepxbfLc1NjwshKjGREdgJZCZFkJ0UytneS/t9XSgVMuxTXxpgCoMC/f2eb4w3AeXt5zv/DmmVEqeBKyIEJv4Ojfwsls60ie+HbUPQGRHezFq4ZegGkdZ4ZANwu4fz8LE4bks4TX63iia9X88mizVx1ZE9+eUyu3fGU2qPymkY+fO9Vzlp5B9Xi4mbvHXz5YQ9gFuEZ3+MOj2fGojqyEqF/egwnDEwjMzGSrIQIMhMiyUyI0B5ppVTQ6QqNSrUSgaxR1nbyvbD8U2vYyPf/hlmPQGIv6H2steUcBeEdf2q7qDAPvzmxH1NG9eCBT5fxWMEq3phTwik9DGOavVqIKEcJKV/ChSt+zVrJ4KmMv5KT1ps7EyLJSozkr0UPMjRlJA9dfaLdMZVSXZwW10rtiSfMGns9cBLUlsGid2Hl5zD/VZj9NLg8kDkKcv3FdvoRHXr4SPf4CB6cfASX+xeheXHxNj6+bwaXj8vh4jHZxEeG2h1RKWKy8uCMf7CxMo17jz91x/HSulLKZm9hWNpQG9MppZRFi2ul9icqGUZdbW0tjbD+R1g1A1Z9YS27PuMeiEiwxme39mzH7XFadscbmhXPG9eO5fF3ZvBDdQx/+2w5jxWsYsrIHkw9qicZ8RF2R1RdmLhckH8F3t3mES8sKwRgaIoW10op+2lxrdTB8IRBz6Os7fi7rF7tVV/6i+0ZsOgd67yU/jsL7ezxENpxLpYSEQYkubn+nFEs2VTNU1+v5oXvinnhu2ImDe3ONRN66WqPylGKSovwiIf+if3tjqKUUlpcK3VYopKtCx7zzgNjYOtiq8he+QXM/g98/xi4Q6HHWKvQzj0O0gbbtnDNwRqQHss/Jh/BrSf145lv1/Dqj+t4Z94GJvZL4boJvRndM1Hn/1W2Kyorom9iX8I94XZHUUopLa6VChgRa0aRtEEw7kZoroe1s3b2an9+l7VFpULvY+jWmArlWdaFkg4vUDPiI/if0wdy47G5vPT9Wp6bVcyUJ79naFY81x3dixMHdcOtS0ArG3h9XhaWLeSM3mfYHUUppQAtrpUKnpAIq6c69zjrfvXGnUNIVn5O/7pyWPYIxKRD9jhr+Ej2eEjp59hiOz4ylF8d24erjurF23NLeOrr1Vz/8lxykiK5+uhenDM8U2cYUe1qVdUq6lrqdLy1UsoxtLhWqr3EdodhF1mbMfz40YuMSm2GtTOheKY1tzZAZNKuxXbaIMfNRBIe4uai0dlMGdmDzxZt5vGvVvHHdxfy4PTlXDG+JxePziYuMsTumKoLKCotAmBI8hCbkyillEWLa6XsIEJdVA8YORFGTrXGa1estoaRrJ1pbUvet84Nj7PGbGePg+wjIT0P3M4oXN0u4ZQh6Zw8uBvfr67gia9X8cCny3j0y5VcMKoHU4/sSXedYUQFUVFZEbGhsWTHZtsdRSmlAC2ulXIGEUjqbW3DL7GOVa7ftdhe/ol1PCQKeozeWWxnDLdmMbGRiDC2dxJjeyftmGHk+VnFPD/LmmHksnE55GXG6cWPKuAKywoZkjxE/28ppRxDi2ulnCo+C+Inw9DJ1v3tW/yFtr/gnnGPddwTDt2HWWO1k/pAcl9IzoX4bFuGk7SdYeQ/36zhtdnWDCO5qdGcMzyTs4Zl0C1OZ3VQh6+2uZaV21ZyfI/j7Y6ilFI7aHGtVEcRkwaDz7Y2gLoKf6E9CzbMgcXToL5i5/nuMGsmkuQ+/q2vdZvUp12Wbs+Ij+DOMwZyywl9+LBwE2//VMJ9nyzlgU+XMj43mXNHZHLiwG5EhDprPLnqOBaVLcJgdLy1UspRtLhWqqOKTIQBp1tbq9pyKF8BZSugbDmUr7Tm3l76IRjvzvOiu+0sutv2dsf1AJcroDFjw0O4YFQPLhjVg+KyWt6ZW8Lbczdw82vziQnzcOqQdM4ZkcnInAT9aF8dlNaVGbW4Vko5iRbXSnUmUUnW1mPMrsdbmmBbsb/gbi2+V8DCd6Chcud5nnBI7M0AkiCkELofAd3yICI+IPFykqP4zYn9uOX4vvywpoK355bwfuFGXp+znh6JkZw9PINzhmeSldhxVrRU9ikqLaJHTA/iwwPz/1MppQJBi2ulugJPKKT0tba2jIG6cqvobu3tLltB3Lq5MP3rnecl9LQK7fShkO6/jUw85Dgu184LIP930iA+WbiZt+eW8M8vVvDQ5ysY1TORc4dncmpeOtFh2kypnzPGUFhWyOj00XZHUUqpXehvLaW6MhFrCfeoZGv2Eb/vCwqYOHIwbJoPmxbAxvmw4SdY9O7O58b32Flodz8C0odZveYHKSrMwzkjMjlnRCYbKut51z9s5HdvF3LXtEWcPLgbZw/PYFzvZF0FUu2wuXYzZfVl5CXn2R1FKaV2ocW1UmrPopIh93hra1VXYRXbmxZYhffG+bBk2s7HYzP9hXabojs69YBfMiM+gl8d24cbjsll7rpKa9jIgo28O28D6XHh/GKYNWxEqdbx1nkpWlwrpZxFi2ul1IGLTITex1hbq/pK2FxoFdqtRffSD3Y+HpMOUSng8lhTA7o8u+6L+2ePicvNCJebER4Pd49ws76yieVb6yj+tpGPv/VQH96N5uY6xo0ZT1RMXPu/D8p2RaVFhLpC6ZfQz+4oSim1Cy2ulVKHJyIeeh5tba0aqmFzkX9YSSE0VoOvpc3mheYm67b1/u6PG+uYx9dCT18LPX1eTHgLpqUJV4sPZj4OM6EiNB132kBie+QhqQMgdYA1+0mIzqXdmRWWFdI/qT8hDlmtVCmlWmlxrZQKvPBYyBlvbQEkgHhb+P6T10iOdrNy4Wx8WxbTa+1yItd/RQgt/hNd1kWYrcV26gBIGQBJudbFnapD8xovi8sXc17f8+yOopRSP6PFtVKqY3F7aIjKJHfCRHInXMD2hmbeX7CJO35cTfXGZQxyb+Ck1G2MitpCUukyZNnHO+f4dnmsAjul/86iO6mPNdwlPF57uzuIjU0bafQ26nhrpZQjaXGtlOrQYsJDuHB0Dy4c3YMlm4bz+uz13DF/A5Ubm8lMiGDK2FTO79lAav0aKF0CW5dYY8MX/xcwu34xT7hVZEfEQ0TCzv0DudXCvN0UNxUDuniMUsqZtLhWSnUaA9Jj+fOkQfzhlP58tngLr89ex99mrOXvAhP6ZjM5/0iOm5BGqMcFTXVQtgwqVkP9NuvCzIbKXW+rS2DLIut+Y/W+X9xfmOeFpMHEr/d9rjosxY3FJIYnkhGdYXcUpZT6GS2ulVKdTniIm0lDuzNpaHfWldfx5k/reXNOCde/PJekqFDOHp7B5JFZ5HYfBt2HHdgX9bZYBXb9tp3Fd9t9/21taRWHvryOOhDFjcXkdctDROc9V0o5T9CKaxEJB74Gwvyv85Yx5q7dznkQaJ3TKxJINcbE+x/zAkX+x9YZYyYFK6tSqvPqkRTJrf4l179eXsprs9fx7MxinvpmDSOyEzhneCYjcxLolRK970Vq3B5rbPZ+VqZcVVBAVoD/DWqnqsYqtrZsZXLKZLujKKXUHgWz57oRONYYUyMiIcC3IvKxMeb71hOMMb9u3ReRG4G2XUj1xpgjgphPKdWFuF3CMf1TOaZ/KqXbG3lnbgmvz1nPHe9af8NHhboZnBHH0Kx48jLjyMuIJysxQntHHWZR2SJAx1srpZwraMW1McYANf67If7N7P0ZXADctY/HlVIqIFJiwrh2Qm+uOboXK7fWsKCkisKSShaUVPHczGKavD4AEiJDGJIZz9DMOPL8t6mxeuHi3ojIycA/ATfwtDHm3kC/RmFZIYIwOHlwoL+0UkoFRFDHXIuIG/gJyAUeNcb8sJfzsoGewIw2h8NFZA7QAtxrjHlvL8+9BrgGIC0tjYKCgoPKWFNTc9DPaU9OzufkbKD5DoeTs0Hg8yUDx8ZZW8uAcEq2+1hT5WNNtY81m8r5dkUpPn/XQEKYkBPnomeci15xLnJi3USH7uzddvp7Fyz+9v5R4ASgBJgtItOMMYsD+TqFpYWkhaQRExoTyC+rlFIBE9Ti2hjjBY4QkXjgXREZbIxZuIdTp2CNyfa2OZZtjNkgIr2AGSJSZIxZtYfXeBJ4EiA/P99MnDjxoDIWFBRwsM9pT07O5+RsoPkOh5OzQfvnq2/ysmhjFQtKqigqqaSwpIp3VtTueDw7KZK8zHjyMuLwNa3hWge/d0E0ClhpjFkNICKvAWcCASuujTEUlRXRP7R/oL6kUkoFXLvMFmKMqRSRL4GTgb0V1zfs9pwN/tvVIlKANR77Z8W1UkoFW0Som/ycRPJzdl7MWFXfzMINVSwoqaRwfRVz127j/QUbSYsUrj3bxrD2yQDWt7lfAoze/aTD+bSxtLmUysZKunm6OfbTAad/cuHkfE7OBs7O5+Rs4Ox8wcgWzNlCUoBmf2EdgfVR4X17OK8/kAB81+ZYAlBnjGkUkWRgPHB/sLIqpdTBiosIYXxuMuNzk3ccK93eyEdffmtjKuc7nE8bvT4veZV5LJ+33LGfrOinPofOydnA2fmcnA2cnS8Y2YLZc50OPO8fh+cC3jDGfCAidwNzjDHT/OdNAV7zXwDZagDwhIj4/M+9N9Dj9pRSKtBSYsLIjnXbHcMuG2CXWQgz/ccCxu1y0y+xH5vcmwL5ZZVSKqCCOVtIIbtOrdd6/M7d7v95D+fMAnSeJaWU6jhmA31EpCdWUT0FuNDeSEop1f50hUallFKHzRjTIiK/Aj7FmorvGWPMIptjKaVUu9PiWimlVEAYYz4CPrI7h1JK2clldwCllFJKKaU6Cy2ulVJKKaWUChAtrpVSSimllAoQLa6VUkoppZQKEC2ulVJKKaWUChAtrpVSSimllAoQLa6VUkoppZQKENl11fGOTURKgbUH+bRkoCwIcQLFyfmcnA003+FwcjZwdr5DzZZtjEkJdBgnO8Q2Gzrn97+9ODmfk7OBs/M5ORs4O1/A2+xOVVwfChGZY4zJtzvH3jg5n5OzgeY7HE7OBs7O5+RsnYWT32MnZwNn53NyNnB2PidnA2fnC0Y2HRailFJKKaVUgGhxrZRSSimlVIBocQ1P2h1gP5ycz8nZQPMdDidnA2fnc3K2zsLJ77GTs4Gz8zk5Gzg7n5OzgbPzBTxblx9zrZRSSimlVKBoz7VSSimllFIB0qWLaxE5WUSWichKEfmD3XlaiUiWiHwpIotFZJGI3Gx3pj0REbeIzBORD+zOsjsRiReRt0RkqYgsEZGxdmdqJSK/9n9fF4rIqyISbnOeZ0Rkq4gsbHMsUUSmi8gK/22Cg7I94P++ForIuyISb0e2veVr89itImJEJNmObJ2RU9ts6BjttrbZh0bb7IDkc0S73V5tdpctrkXEDTwKnAIMBC4QkYH2ptqhBbjVGDMQGAPc4KBsbd0MLLE7xF78E/jEGNMfGIpDcopIBnATkG+MGQy4gSn2puI54OTdjv0B+MIY0wf4wn/fDs/x82zTgcHGmDxgOXB7e4dq4zl+ng8RyQJOBNa1d6DOyuFtNnSMdlvb7IOkbfYheQ7nttvP0Q5tdpctroFRwEpjzGpjTBPwGnCmzZkAMMZsMsbM9e9vx2pkMuxNtSsRyQROA562O8vuRCQOOBr4D4AxpskYU2lvql14gAgR8QCRwEY7wxhjvgYqdjt8JvC8f/954BftGspvT9mMMZ8ZY1r8d78HMts92M4se3rvAB4EfgfoRS2B49g2G5zfbmubfVi0zT4ITm6326vN7srFdQawvs39EhzUELYSkRxgGPCDvUl+5iGs/4g+u4PsQU+gFHjW/xHo0yISZXcoAGPMBuBvWH8dbwKqjDGf2Ztqj9KMMZv8+5uBNDvD7MOVwMd2h2hLRM4ENhhjFtidpZPpEG02OLbd1jb7EGibHRSOareD0WZ35eLa8UQkGngbuMUYU213nlYicjqw1Rjzk91Z9sIDDAf+bYwZBtRi70dkO/jHwZ2J9cukOxAlIhfbm2rfjDWlkON6YEXkj1gfxb9sd5ZWIhIJ3AHcaXcWZQ8nttvaZh86bbMDy2ntdrDa7K5cXG8Astrcz/QfcwQRCcFqoF82xrxjd57djAcmiUgx1kezx4rIS/ZG2kUJUGKMae01egur4XaC44E1xphSY0wz8A4wzuZMe7JFRNIB/Ldbbc6zCxG5HDgduMg4az7R3li/hBf4fz4ygbki0s3WVJ2Do9tscHS7rW32odM2O0Ac2m4Hpc3uysX1bKCPiPQUkVCsCxSm2ZwJABERrLFnS4wx/7A7z+6MMbcbYzKNMTlY79sMY4xj/pI3xmwG1otIP/+h44DFNkZqax0wRkQi/d/n43DIhTu7mQZc5t+/DPivjVl2ISInY328PckYU2d3nraMMUXGmFRjTI7/56MEGO7/P6kOj2PbbHB2u61t9mHRNjsAnNpuB6vN7rLFtX9g/a+AT7F+UN4wxiyyN9UO44FLsHoX5vu3U+0O1cHcCLwsIoXAEcBfbc4DgL9n5i1gLlCE9TNo68pVIvIq8B3QT0RKRGQqcC9wgoiswOq5uddB2f4FxADT/T8bj9uRbR/5VBA4vM0GbbcPl7bZB8jJbfY+8jmi3W6vNltXaFRKKaWUUipAumzPtVJKKaWUUoGmxbVSSimllFIBosW1UkoppZRSAaLFtVJKKaWUUgGixbVSSimllFIBosW16nJExNtmqqz5IhKwlcBEJEdEFgbq6ymlVFenbbbqaDx2B1DKBvXGmCPsDqGUUuqAaJutOhTtuVbKT0SKReR+ESkSkR9FJNd/PEdEZohIoYh8ISI9/MfTRORdEVng31qXxHWLyFMiskhEPhORCNv+UUop1Ulpm62cSotr1RVF7PYR4+Q2j1UZY4ZgrSb1kP/YI8Dzxpg84GXgYf/xh4GvjDFDgeFA62pxfYBHjTGDgErgnCD/e5RSqjPTNlt1KLpCo+pyRKTGGBO9h+PFwLHGmNUiEgJsNsYkiUgZkG6MafYf32SMSRaRUiDTGNPY5mvkANONMX38938PhBhj7gn+v0wppTofbbNVR6M910rtyuxl/2A0ttn3otc2KKVUsGibrRxHi2uldjW5ze13/v1ZwBT//kXAN/79L4DrAUTELSJx7RVSKaUUoG22ciD960x1RREiMr/N/U+MMa1TOyWISCFWT8YF/mM3As+KyG+BUuAK//GbgSdFZCpWb8f1wKagp1dKqa5F22zVoeiYa6X8/OP38o0xZXZnUUoptW/aZiun0mEhSimllFJKBYj2XCullFJKKRUg2nOtlFJKKaVUgGhxrZRSSimlVIBoca2UUkoppVSAaHGtlFJKKaVUgGhxrZRSSimlVIBoca2UUkoppVSA/H8rH52BFJTfFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[1].plot(history['acc'], label='train')\n",
    "axes[1].plot(history['val_acc'], label='valid')\n",
    "axes[1].plot(np.array(history['bleu4']) * 100., label='BLEU-4')\n",
    "axes[1].set_title('Accuracy & BLEU-4 history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy & BLEU-4 (%)')\n",
    "axes[1].grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load(f'./checkpoint/BEST_{MODEL_NAME}.pt').get('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    id_ = 0\n",
    "    \n",
    "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
    "        self.__id = self.__class__.id_\n",
    "        self.__token = token\n",
    "        self.__states = states\n",
    "        self.__logp = logp\n",
    "        self.__parent_id = None if parent is None else parent.id\n",
    "        self.__eos = eos\n",
    "        self.__level = 0 if parent is None else parent.level + 1\n",
    "        self.__logps = logp if parent is None else parent.logps + logp\n",
    "        self.__class__.id_ += 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Node[id={self.__id}, ' + \\\n",
    "                    f'logp={self.__logp}, ' + \\\n",
    "                    f'logps={self.__logps}, ' + \\\n",
    "                    f'parent_id={self.__parent_id}, ' + \\\n",
    "                    f'level={self.__level}]'\n",
    "    \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.__id\n",
    "    \n",
    "    @id.setter\n",
    "    def id(self, id_):\n",
    "        self.__id = id_\n",
    "    \n",
    "    @property\n",
    "    def token(self):\n",
    "        return self.__token\n",
    "    \n",
    "    @token.setter\n",
    "    def token(self, token):\n",
    "        self.__token = token\n",
    "    \n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.__states\n",
    "    \n",
    "    @states.setter\n",
    "    def states(self, states):\n",
    "        self.__states = states\n",
    "      \n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self.__eos\n",
    "    \n",
    "    @eos.setter\n",
    "    def eos(self, eos):\n",
    "        self.__eos = eos\n",
    "    \n",
    "    @property\n",
    "    def logps(self):\n",
    "        return self.__logps\n",
    "    \n",
    "    @logps.setter\n",
    "    def logps(self, logps):\n",
    "        self.__logps = logps\n",
    "        \n",
    "    @property\n",
    "    def level(self):\n",
    "        return self.__level\n",
    "    \n",
    "    @level.setter\n",
    "    def level(self, level):\n",
    "        self.__level = level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, beam_size, field, max_len, device):\n",
    "    references, hypotheses = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar:\n",
    "            (src_sequences, src_lengths) = data.src[0], data.src[1]\n",
    "            (dest_sequences, dest_lengths) = data.dest[0], data.dest[1]\n",
    "            \n",
    "            batch_size = src_sequences.shape[1]\n",
    "            for j in range(batch_size): # We evaluate sentence by sentence\n",
    "                src_sequence = src_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                dest_sequence = dest_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                src_length, dest_length = src_lengths[j, None], dest_lengths[j, None] # [1,]\n",
    "                \n",
    "                # Encoding\n",
    "                _, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                    sequence_lengths=src_length)\n",
    "                \n",
    "                # Init hidden and memory states\n",
    "                h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                c_state = model.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                \n",
    "                # Decoding\n",
    "                tree = [[Node(\n",
    "                    token=torch.LongTensor([\n",
    "                        field.vocab.stoi[field.init_token]\n",
    "                    ]).to(device),\n",
    "                    states=(h_state, c_state)\n",
    "                ) for _ in range(beam_size)]]\n",
    "                print(tree)\n",
    "                \n",
    "                for _ in range(max_len):\n",
    "                    next_nodes = []\n",
    "                    for node in tree[-1]:\n",
    "                        # Skip eos token\n",
    "                        if node.eos:\n",
    "                            continue\n",
    "                        # Decode\n",
    "                        logit, h_state, c_state = model.decoder(\n",
    "                            input_word_index=node.token, \n",
    "                            h_state=node.states[0].contiguous(),\n",
    "                            c_state=node.states[1].contiguous()\n",
    "                        )\n",
    "                        # logit: [1, vocab_size]\n",
    "                        # h_state: [n_layers, 1, hidden_size]\n",
    "                        # c_state: [n_layers, 1, hidden_size]\n",
    "\n",
    "                        # Get scores\n",
    "                        logp = F.log_softmax(logit, dim=1).squeeze(dim=0) # [vocab_size]\n",
    "\n",
    "                        # Get top k tokens & logps\n",
    "                        topk_logps, topk_tokens = torch.topk(logp, beam_size)\n",
    "\n",
    "                        for k in range(beam_size):\n",
    "                            next_nodes.append(Node(\n",
    "                                token=topk_tokens[k, None],\n",
    "                                states=(h_state, c_state),\n",
    "                                logp=topk_logps[k, None],\n",
    "                                parent=node,\n",
    "                                eos=topk_tokens[k].cpu().item() == field.vocab[field.eos_token]\n",
    "                            ))\n",
    "\n",
    "                    \n",
    "                    # Sort next_nodes to get the best\n",
    "                    next_nodes = sorted(next_nodes,\n",
    "                                        key=lambda node: node.logps,\n",
    "                                        reverse=True)\n",
    "                    # Update the tree\n",
    "                    tree.append(next_nodes[:beam_size])\n",
    "                \n",
    "                # Find the best path of the tree\n",
    "                # best = [tree[-1][0]]\n",
    "                # for nodes in reversed(tree):\n",
    "                #    for node in nodes:\n",
    "                #        \n",
    "                #    best.append(nodes[0])\n",
    "                break\n",
    "            break\n",
    "    \n",
    "    return tree, src_sequence, dest_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/347 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<__main__.Node object at 0x7f69527e33c8>, <__main__.Node object at 0x7f69527e32e8>, <__main__.Node object at 0x7f69527e3438>]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tree, _, _ = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=3,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Node[id=0, logp=0.0, logps=0.0, parent_id=None, level=0]',\n",
       "  'Node[id=1, logp=0.0, logps=0.0, parent_id=None, level=0]',\n",
       "  'Node[id=2, logp=0.0, logps=0.0, parent_id=None, level=0]'],\n",
       " [\"Node[id=3, logp=tensor([-2.0521], device='cuda:0'), logps=tensor([-2.0521], device='cuda:0'), parent_id=0, level=1]\",\n",
       "  \"Node[id=6, logp=tensor([-2.0521], device='cuda:0'), logps=tensor([-2.0521], device='cuda:0'), parent_id=1, level=1]\",\n",
       "  \"Node[id=9, logp=tensor([-2.0521], device='cuda:0'), logps=tensor([-2.0521], device='cuda:0'), parent_id=2, level=1]\"],\n",
       " [\"Node[id=12, logp=tensor([-2.2469], device='cuda:0'), logps=tensor([-4.2990], device='cuda:0'), parent_id=3, level=2]\",\n",
       "  \"Node[id=15, logp=tensor([-2.2469], device='cuda:0'), logps=tensor([-4.2990], device='cuda:0'), parent_id=6, level=2]\",\n",
       "  \"Node[id=18, logp=tensor([-2.2469], device='cuda:0'), logps=tensor([-4.2990], device='cuda:0'), parent_id=9, level=2]\"],\n",
       " [\"Node[id=21, logp=tensor([-0.0953], device='cuda:0'), logps=tensor([-4.3943], device='cuda:0'), parent_id=12, level=3]\",\n",
       "  \"Node[id=24, logp=tensor([-0.0953], device='cuda:0'), logps=tensor([-4.3943], device='cuda:0'), parent_id=15, level=3]\",\n",
       "  \"Node[id=27, logp=tensor([-0.0953], device='cuda:0'), logps=tensor([-4.3943], device='cuda:0'), parent_id=18, level=3]\"],\n",
       " [\"Node[id=30, logp=tensor([-0.1369], device='cuda:0'), logps=tensor([-4.5311], device='cuda:0'), parent_id=21, level=4]\",\n",
       "  \"Node[id=33, logp=tensor([-0.1369], device='cuda:0'), logps=tensor([-4.5311], device='cuda:0'), parent_id=24, level=4]\",\n",
       "  \"Node[id=36, logp=tensor([-0.1369], device='cuda:0'), logps=tensor([-4.5311], device='cuda:0'), parent_id=27, level=4]\"],\n",
       " [\"Node[id=39, logp=tensor([-0.0307], device='cuda:0'), logps=tensor([-4.5619], device='cuda:0'), parent_id=30, level=5]\",\n",
       "  \"Node[id=42, logp=tensor([-0.0307], device='cuda:0'), logps=tensor([-4.5619], device='cuda:0'), parent_id=33, level=5]\",\n",
       "  \"Node[id=45, logp=tensor([-0.0307], device='cuda:0'), logps=tensor([-4.5619], device='cuda:0'), parent_id=36, level=5]\"],\n",
       " [\"Node[id=48, logp=tensor([-0.5234], device='cuda:0'), logps=tensor([-5.0853], device='cuda:0'), parent_id=39, level=6]\",\n",
       "  \"Node[id=51, logp=tensor([-0.5234], device='cuda:0'), logps=tensor([-5.0853], device='cuda:0'), parent_id=42, level=6]\",\n",
       "  \"Node[id=54, logp=tensor([-0.5234], device='cuda:0'), logps=tensor([-5.0853], device='cuda:0'), parent_id=45, level=6]\"],\n",
       " [\"Node[id=57, logp=tensor([-0.0030], device='cuda:0'), logps=tensor([-5.0882], device='cuda:0'), parent_id=48, level=7]\",\n",
       "  \"Node[id=60, logp=tensor([-0.0030], device='cuda:0'), logps=tensor([-5.0882], device='cuda:0'), parent_id=51, level=7]\",\n",
       "  \"Node[id=63, logp=tensor([-0.0030], device='cuda:0'), logps=tensor([-5.0882], device='cuda:0'), parent_id=54, level=7]\"],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*map(lambda nodes: [*map(Node.__str__, nodes)], tree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*map(lambda node: (node.logps, node.token), tree[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, beam_size, field, max_len, device):\n",
    "    references, hypotheses = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, data in pbar:\n",
    "            (src_sequences, src_lengths) = data.src[0], data.src[1]\n",
    "            (dest_sequences, dest_lengths) = data.dest[0], data.dest[1]\n",
    "            \n",
    "            batch_size = src_sequences.shape[1]\n",
    "            for j in range(batch_size): # We evaluate sentence by sentence\n",
    "                src_sequence = src_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                dest_sequence = dest_sequences[:, j].unsqueeze(1) # [seq_len, 1]\n",
    "                src_length, dest_length = src_lengths[j, None], dest_lengths[j, None] # [1,]\n",
    "                \n",
    "                k = beam_size\n",
    "                # Top k previous token indices at each step\n",
    "                topk_prev_tokens = torch.LongTensor([\n",
    "                    [field.vocab.stoi[field.init_token]]\n",
    "                ] * k).to(device)  # [k, 1]\n",
    "                # Top k sequences\n",
    "                topk_sequences = topk_prev_tokens  # [k, 1]\n",
    "                # Top k sequences' logps\n",
    "                topk_logps = torch.zeros(k, 1).to(device)  # [k, 1]\n",
    "                # Complete sequences and logps\n",
    "                complete_sequences, complete_sequence_logps = [], []\n",
    "                \n",
    "                # Encoding\n",
    "                _, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                    sequence_lengths=src_length)\n",
    "                # h_state: [n_layers * 2, 1, hidden_size]\n",
    "                # c_state: [n_layers * 2, 1, hidden_size]\n",
    "                \n",
    "                # Init hidden and memory states\n",
    "                h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                c_state = model.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "                h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "                h_state = h_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "                c_state = c_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "                \n",
    "                # Decoding\n",
    "                step = 1\n",
    "                while True:\n",
    "                    logit, h_state, c_state = model.decoder(\n",
    "                        input_word_index=topk_prev_tokens.squeeze(1), \n",
    "                        h_state=h_state.contiguous(),\n",
    "                        c_state=c_state.contiguous()\n",
    "                    )\n",
    "                    # logit: [k, vocab_size]\n",
    "                    # h_state: [n_layers, k, hidden_size]\n",
    "                    # c_state: [n_layers, k, hidden_size]\n",
    "                    \n",
    "                    # Get scores\n",
    "                    logp = F.log_softmax(logit, dim=1) # [k, vocab_size]\n",
    "                    # Extend\n",
    "                    logp = topk_logps.expand_as(logp) + logp  # [k, vocab_size]\n",
    "                    \n",
    "                    # At the 1st step, the score is 0\n",
    "                    if step == 1:\n",
    "                        topk_logps, topk_tokens = logp[0].topk(k, 0, True, True)  # [k,]\n",
    "                    else:\n",
    "                        # Unroll and find top logp, and their unrolled indices\n",
    "                        topk_logps, topk_tokens = logp.view(-1).topk(k, 0, True, True)  # [k,]\n",
    "                    \n",
    "                    # Convert unrolled indices to actual indices of logp\n",
    "                    prev_tokens = topk_tokens // model.decoder.vocab_size  # [k,]\n",
    "                    next_tokens = topk_tokens % model.decoder.vocab_size  # [k,]\n",
    "                    \n",
    "                    # Add new indices to topk_sequences\n",
    "                    topk_sequences = torch.cat((\n",
    "                        topk_sequences[prev_tokens],\n",
    "                        next_tokens.unsqueeze(1)\n",
    "                    ), dim=1) # [k, step + 1]\n",
    "                    \n",
    "                    # Get the complete and incomplete sequences\n",
    "                    incomplete_indices = [\n",
    "                        indice for indice, next_token in enumerate(next_tokens) \n",
    "                        if next_token != field.vocab.stoi[field.eos_token]\n",
    "                    ]\n",
    "                    complete_indices = list(set(range(len(next_tokens))) - set(incomplete_indices))\n",
    "                    \n",
    "                    # Set aside complete sequences\n",
    "                    if len(complete_indices) > 0:\n",
    "                        complete_sequences.extend(topk_sequences[complete_indices].tolist())\n",
    "                        complete_sequence_logps.extend(topk_logps[complete_indices])\n",
    "                        \n",
    "                    # Reduce beam length accordingly\n",
    "                    k -= len(complete_indices)\n",
    "                    \n",
    "                    # Proceed with incomplete sequences\n",
    "                    if k == 0:\n",
    "                        break\n",
    "                        \n",
    "                    topk_sequences = topk_sequences[incomplete_indices]\n",
    "                    h_state = h_state[:, prev_tokens[incomplete_indices], :]\n",
    "                    c_state = c_state[:, prev_tokens[incomplete_indices], :]\n",
    "                    topk_logps = topk_logps[incomplete_indices].unsqueeze(1)\n",
    "                    topk_prev_tokens = next_tokens[incomplete_indices].unsqueeze(1)\n",
    "                    \n",
    "                    # Break if things have been going on too long\n",
    "                    if step > max_len:\n",
    "                        if len(complete_indices) == 0:\n",
    "                            complete_sequences.extend(topk_sequences.tolist())\n",
    "                            complete_sequence_logps.extend(topk_logps[incomplete_indices])\n",
    "                        break\n",
    "\n",
    "                    # Update step\n",
    "                    step += 1\n",
    "                    \n",
    "                i = complete_sequence_logps.index(max(complete_sequence_logps))\n",
    "                pred_sequence = complete_sequences[i]\n",
    "                \n",
    "                # Update references\n",
    "                reference = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in dest_sequence \n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.eos_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                references.append([reference])\n",
    "                \n",
    "                # Update hypotheses\n",
    "                hypothese = [\n",
    "                    field.vocab.itos[indice] \n",
    "                    for indice in pred_sequence\n",
    "                    if indice not in (\n",
    "                        field.vocab.stoi[field.init_token],\n",
    "                        field.vocab.stoi[field.eos_token],\n",
    "                        field.vocab.stoi[field.pad_token]\n",
    "                    )\n",
    "                ]\n",
    "                hypotheses.append(hypothese)\n",
    "                \n",
    "                assert len(references) == len(hypotheses)\n",
    "            \n",
    "        # Calculate BLEU-4 score\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    return hypotheses, references, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [05:06<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 1.842% with beam_size=1\n"
     ]
    }
   ],
   "source": [
    "_, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "                       loader=test_iterator,\n",
    "                       beam_size=1,\n",
    "                       field=EN,\n",
    "                       max_len=MAX_LENGTH,\n",
    "                       device=DEVICE)\n",
    "print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "#                        loader=test_iterator,\n",
    "#                        beam_size=5,\n",
    "#                        field=EN,\n",
    "#                        max_len=MAX_LENGTH,\n",
    "#                        device=DEVICE)\n",
    "# print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, bleu4 = evaluate(seq2seq.to(DEVICE),\n",
    "#                        loader=test_iterator,\n",
    "#                        beam_size=10,\n",
    "#                        field=EN,\n",
    "#                        max_len=MAX_LENGTH,\n",
    "#                        device=DEVICE)\n",
    "# print(f'BLEU-4: {bleu4*100:.3f}% with beam_size=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
    "    if isinstance(sentences, list):\n",
    "        sentences = [*map(src_field.preprocess, sentences)]\n",
    "        targets = None\n",
    "    if isinstance(sentences, Dataset):\n",
    "        targets = [*map(lambda example: ' '.join(example.dest), sentences.examples)]\n",
    "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
    "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        translated_sentences = []\n",
    "        pbar = tqdm.tqdm(enumerate(data), total=len(data))\n",
    "        for i, (src_sequence, src_length) in pbar:\n",
    "            src_sequence, src_length = src_sequence.to(DEVICE), src_length.to(DEVICE)\n",
    "            k = beam_size\n",
    "            # Top k previous token indices at each step\n",
    "            topk_prev_tokens = torch.LongTensor([\n",
    "                [dest_field.vocab.stoi[dest_field.init_token]]\n",
    "            ] * k).to(device)  # [k, 1]\n",
    "            # Top k sequences\n",
    "            topk_sequences = topk_prev_tokens  # [k, 1]\n",
    "            # Top k sequences' logps\n",
    "            topk_logps = torch.zeros(k, 1).to(device)  # [k, 1]\n",
    "            # Complete sequences and logps\n",
    "            complete_sequences, complete_sequence_logps = [], []\n",
    "\n",
    "            # Encoding\n",
    "            _, h_state, c_state = model.encoder(input_sequences=src_sequence,\n",
    "                                                sequence_lengths=src_length)\n",
    "            # h_state: [n_layers * 2, 1, hidden_size]\n",
    "            # c_state: [n_layers * 2, 1, hidden_size]\n",
    "\n",
    "            # Init hidden and memory states\n",
    "            h_state = model.init_h0(h_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "            c_state = model.init_c0(c_state.permute(1, 2, 0)) # [batch_size, hidden_size, n_layers]\n",
    "            h_state = h_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "            c_state = c_state.permute(2, 0, 1) # [n_layers, batch_size, hidden_size]\n",
    "            h_state = h_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "            c_state = c_state.expand(-1, k, -1) # # [n_layers, k, hidden_size]\n",
    "\n",
    "            # Decoding\n",
    "            step = 1\n",
    "            while True:\n",
    "                logit, h_state, c_state = model.decoder(\n",
    "                    input_word_index=topk_prev_tokens.squeeze(1), \n",
    "                    h_state=h_state.contiguous(),\n",
    "                    c_state=c_state.contiguous()\n",
    "                )\n",
    "                # logit: [k, vocab_size]\n",
    "                # h_state: [n_layers, k, hidden_size]\n",
    "                # c_state: [n_layers, k, hidden_size]\n",
    "\n",
    "                # Get scores\n",
    "                logp = F.log_softmax(logit, dim=1) # [k, vocab_size]\n",
    "                # Extend\n",
    "                logp = topk_logps.expand_as(logp) + logp  # [k, vocab_size]\n",
    "\n",
    "                # At the 1st step, the score is 0\n",
    "                if step == 1:\n",
    "                    topk_logps, topk_tokens = logp[0].topk(k, 0, True, True)  # [k,]\n",
    "                else:\n",
    "                    # Unroll and find top logp, and their unrolled indices\n",
    "                    topk_logps, topk_tokens = logp.view(-1).topk(k, 0, True, True)  # [k,]\n",
    "\n",
    "                # Convert unrolled indices to actual indices of logp\n",
    "                prev_tokens = topk_tokens // model.decoder.vocab_size  # [k,]\n",
    "                next_tokens = topk_tokens % model.decoder.vocab_size  # [k,]\n",
    "\n",
    "                # Add new indices to topk_sequences\n",
    "                topk_sequences = torch.cat((\n",
    "                    topk_sequences[prev_tokens],\n",
    "                    next_tokens.unsqueeze(1)\n",
    "                ), dim=1) # [k, step + 1]\n",
    "\n",
    "                # Get the complete and incomplete sequences\n",
    "                incomplete_indices = [\n",
    "                    indice for indice, next_token in enumerate(next_tokens) \n",
    "                    if next_token != dest_field.vocab.stoi[dest_field.eos_token]\n",
    "                ]\n",
    "                complete_indices = list(set(range(len(next_tokens))) - set(incomplete_indices))\n",
    "\n",
    "                # Set aside complete sequences\n",
    "                if len(complete_indices) > 0:\n",
    "                    complete_sequences.extend(topk_sequences[complete_indices].tolist())\n",
    "                    complete_sequence_logps.extend(topk_logps[complete_indices])\n",
    "\n",
    "                # Reduce beam length accordingly\n",
    "                k -= len(complete_indices)\n",
    "\n",
    "                # Proceed with incomplete sequences\n",
    "                if k == 0:\n",
    "                    break\n",
    "\n",
    "                topk_sequences = topk_sequences[incomplete_indices]\n",
    "                h_state = h_state[:, prev_tokens[incomplete_indices], :]\n",
    "                c_state = c_state[:, prev_tokens[incomplete_indices], :]\n",
    "                topk_logps = topk_logps[incomplete_indices].unsqueeze(1)\n",
    "                topk_prev_tokens = next_tokens[incomplete_indices].unsqueeze(1)\n",
    "\n",
    "                # Break if things have been going on too long\n",
    "                if step > max_len:\n",
    "                    if len(complete_indices) == 0:\n",
    "                        complete_sequences.extend(topk_sequences.tolist())\n",
    "                        complete_sequence_logps.extend(topk_logps[incomplete_indices])\n",
    "                    break\n",
    "\n",
    "                # Update step\n",
    "                step += 1\n",
    "\n",
    "            idx = complete_sequence_logps.index(max(complete_sequence_logps))\n",
    "            pred_sequence = complete_sequences[idx]\n",
    "            \n",
    "            translated_sentences.append(\n",
    "                ' '.join([\n",
    "                    dest_field.vocab.itos[token]\n",
    "                    for token in pred_sequence \n",
    "                    if token not in {\n",
    "                        dest_field.vocab.stoi[dest_field.init_token],\n",
    "                        dest_field.vocab.stoi[dest_field.eos_token],\n",
    "                        dest_field.vocab.stoi[dest_field.pad_token]\n",
    "                    }\n",
    "                ])\n",
    "            )\n",
    "    sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
    "    return sentences, translated_sentences, targets\n",
    "\n",
    "sentences, translated_sentences, dest_sentences = translate(sentences=test_data,\n",
    "                                                            model=seq2seq,\n",
    "                                                            beam_size=1,\n",
    "                                                            src_field=FR,\n",
    "                                                            dest_field=EN,\n",
    "                                                            max_len=MAX_LENGTH,\n",
    "                                                            device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.choice(len(test_data.examples), 20)\n",
    "print(indexes)\n",
    "print()\n",
    "for i in indexes:\n",
    "    display(HTML(f'<span style=\"color:blue\"><b>Source:</b> {sentences[i]}</span>'))\n",
    "    display(HTML(f'<span style=\"color:green\"><b>Ground truth translation:</b> {dest_sentences[i]}</span>'))\n",
    "    display(HTML(f'<span style=\"color:red\"><b>Predicted translation:</b> {translated_sentences[i]}</span>'))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
